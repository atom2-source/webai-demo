/*! For license information please see 773.00c87c83.chunk.js.LICENSE.txt */
"use strict";(self.webpackChunkwebai_demo=self.webpackChunkwebai_demo||[]).push([[773],{1773:(t,e,s)=>{s.r(e),s.d(e,{Abs:()=>h.Abs,Acos:()=>h.Acos,Acosh:()=>h.Acosh,AdadeltaOptimizer:()=>h.AdadeltaOptimizer,AdagradOptimizer:()=>h.AdagradOptimizer,AdamOptimizer:()=>h.AdamOptimizer,AdamaxOptimizer:()=>h.AdamaxOptimizer,Add:()=>h.Add,AddN:()=>h.AddN,All:()=>h.All,Any:()=>h.Any,ArgMax:()=>h.ArgMax,ArgMin:()=>h.ArgMin,Asin:()=>h.Asin,Asinh:()=>h.Asinh,Atan:()=>h.Atan,Atan2:()=>h.Atan2,Atanh:()=>h.Atanh,AvgPool:()=>h.AvgPool,AvgPool3D:()=>h.AvgPool3D,AvgPool3DGrad:()=>h.AvgPool3DGrad,AvgPoolGrad:()=>h.AvgPoolGrad,BatchMatMul:()=>h.BatchMatMul,BatchToSpaceND:()=>h.BatchToSpaceND,Bincount:()=>h.Bincount,BitwiseAnd:()=>h.BitwiseAnd,BroadcastArgs:()=>h.BroadcastArgs,BroadcastTo:()=>h.BroadcastTo,Callback:()=>op,CallbackList:()=>Oa,Cast:()=>h.Cast,Ceil:()=>h.Ceil,ClipByValue:()=>h.ClipByValue,Complex:()=>h.Complex,ComplexAbs:()=>h.ComplexAbs,Concat:()=>h.Concat,Conv2D:()=>h.Conv2D,Conv2DBackpropFilter:()=>h.Conv2DBackpropFilter,Conv2DBackpropInput:()=>h.Conv2DBackpropInput,Conv3D:()=>h.Conv3D,Conv3DBackpropFilterV2:()=>h.Conv3DBackpropFilterV2,Conv3DBackpropInputV2:()=>h.Conv3DBackpropInputV2,Cos:()=>h.Cos,Cosh:()=>h.Cosh,CropAndResize:()=>h.CropAndResize,Cumprod:()=>h.Cumprod,Cumsum:()=>h.Cumsum,CustomCallback:()=>Pa,DataStorage:()=>h.DataStorage,DenseBincount:()=>h.DenseBincount,DepthToSpace:()=>h.DepthToSpace,DepthwiseConv2dNative:()=>h.DepthwiseConv2dNative,DepthwiseConv2dNativeBackpropFilter:()=>h.DepthwiseConv2dNativeBackpropFilter,DepthwiseConv2dNativeBackpropInput:()=>h.DepthwiseConv2dNativeBackpropInput,Diag:()=>h.Diag,Dilation2D:()=>h.Dilation2D,Dilation2DBackpropFilter:()=>h.Dilation2DBackpropFilter,Dilation2DBackpropInput:()=>h.Dilation2DBackpropInput,Draw:()=>h.Draw,ENV:()=>h.ENV,EarlyStopping:()=>hp,Einsum:()=>h.Einsum,Elu:()=>h.Elu,EluGrad:()=>h.EluGrad,Environment:()=>h.Environment,Equal:()=>h.Equal,Erf:()=>h.Erf,Exp:()=>h.Exp,ExpandDims:()=>h.ExpandDims,Expm1:()=>h.Expm1,FFT:()=>h.FFT,Fill:()=>h.Fill,FlipLeftRight:()=>h.FlipLeftRight,Floor:()=>h.Floor,FloorDiv:()=>h.FloorDiv,FromPixels:()=>h.FromPixels,FusedBatchNorm:()=>h.FusedBatchNorm,FusedConv2D:()=>h.FusedConv2D,FusedDepthwiseConv2D:()=>h.FusedDepthwiseConv2D,GPGPUContext:()=>zd.GPGPUContext,GatherNd:()=>h.GatherNd,GatherV2:()=>h.GatherV2,GraphModel:()=>dp.GraphModel,Greater:()=>h.Greater,GreaterEqual:()=>h.GreaterEqual,History:()=>Ba,IFFT:()=>h.IFFT,Identity:()=>h.Identity,Imag:()=>h.Imag,InputSpec:()=>Ur,IsFinite:()=>h.IsFinite,IsInf:()=>h.IsInf,IsNan:()=>h.IsNan,KernelBackend:()=>h.KernelBackend,LRN:()=>h.LRN,LRNGrad:()=>h.LRNGrad,LayerVariable:()=>Br,LayersModel:()=>Go,LeakyRelu:()=>h.LeakyRelu,Less:()=>h.Less,LessEqual:()=>h.LessEqual,LinSpace:()=>h.LinSpace,Log:()=>h.Log,Log1p:()=>h.Log1p,LogSoftmax:()=>h.LogSoftmax,LogicalAnd:()=>h.LogicalAnd,LogicalNot:()=>h.LogicalNot,LogicalOr:()=>h.LogicalOr,LogicalXor:()=>h.LogicalXor,LowerBound:()=>h.LowerBound,MathBackendCPU:()=>Nd.MathBackendCPU,MathBackendWebGL:()=>zd.MathBackendWebGL,MatrixBandPart:()=>h.MatrixBandPart,Max:()=>h.Max,MaxPool:()=>h.MaxPool,MaxPool3D:()=>h.MaxPool3D,MaxPool3DGrad:()=>h.MaxPool3DGrad,MaxPoolGrad:()=>h.MaxPoolGrad,MaxPoolWithArgmax:()=>h.MaxPoolWithArgmax,Maximum:()=>h.Maximum,Mean:()=>h.Mean,Min:()=>h.Min,Minimum:()=>h.Minimum,MirrorPad:()=>h.MirrorPad,Mod:()=>h.Mod,MomentumOptimizer:()=>h.MomentumOptimizer,Multinomial:()=>h.Multinomial,Multiply:()=>h.Multiply,Neg:()=>h.Neg,NonMaxSuppressionV3:()=>h.NonMaxSuppressionV3,NonMaxSuppressionV4:()=>h.NonMaxSuppressionV4,NonMaxSuppressionV5:()=>h.NonMaxSuppressionV5,NotEqual:()=>h.NotEqual,OP_SCOPE_SUFFIX:()=>h.OP_SCOPE_SUFFIX,OneHot:()=>h.OneHot,OnesLike:()=>h.OnesLike,Optimizer:()=>h.Optimizer,OptimizerConstructors:()=>h.OptimizerConstructors,Pack:()=>h.Pack,PadV2:()=>h.PadV2,Pool:()=>h.Pool,Pow:()=>h.Pow,Prelu:()=>h.Prelu,Prod:()=>h.Prod,RMSPropOptimizer:()=>h.RMSPropOptimizer,RNN:()=>su,RaggedGather:()=>h.RaggedGather,RaggedRange:()=>h.RaggedRange,RaggedTensorToTensor:()=>h.RaggedTensorToTensor,Range:()=>h.Range,Rank:()=>h.Rank,Real:()=>h.Real,RealDiv:()=>h.RealDiv,Reciprocal:()=>h.Reciprocal,Reduction:()=>h.Reduction,Relu:()=>h.Relu,Relu6:()=>h.Relu6,Reshape:()=>h.Reshape,ResizeBilinear:()=>h.ResizeBilinear,ResizeBilinearGrad:()=>h.ResizeBilinearGrad,ResizeNearestNeighbor:()=>h.ResizeNearestNeighbor,ResizeNearestNeighborGrad:()=>h.ResizeNearestNeighborGrad,Reverse:()=>h.Reverse,RotateWithOffset:()=>h.RotateWithOffset,Round:()=>h.Round,Rsqrt:()=>h.Rsqrt,SGDOptimizer:()=>h.SGDOptimizer,ScatterNd:()=>h.ScatterNd,SearchSorted:()=>h.SearchSorted,Select:()=>h.Select,Selu:()=>h.Selu,Sequential:()=>Zo,Sigmoid:()=>h.Sigmoid,Sign:()=>h.Sign,Sin:()=>h.Sin,Sinh:()=>h.Sinh,Slice:()=>h.Slice,Softmax:()=>h.Softmax,Softplus:()=>h.Softplus,SpaceToBatchND:()=>h.SpaceToBatchND,SparseFillEmptyRows:()=>h.SparseFillEmptyRows,SparseReshape:()=>h.SparseReshape,SparseSegmentMean:()=>h.SparseSegmentMean,SparseSegmentSum:()=>h.SparseSegmentSum,SparseToDense:()=>h.SparseToDense,SplitV:()=>h.SplitV,Sqrt:()=>h.Sqrt,Square:()=>h.Square,SquaredDifference:()=>h.SquaredDifference,StaticRegexReplace:()=>h.StaticRegexReplace,Step:()=>h.Step,StridedSlice:()=>h.StridedSlice,StringNGrams:()=>h.StringNGrams,StringSplit:()=>h.StringSplit,StringToHashBucketFast:()=>h.StringToHashBucketFast,Sub:()=>h.Sub,Sum:()=>h.Sum,SymbolicTensor:()=>jr,Tan:()=>h.Tan,Tanh:()=>h.Tanh,Tensor:()=>h.Tensor,TensorBuffer:()=>h.TensorBuffer,TensorScatterUpdate:()=>h.TensorScatterUpdate,Tile:()=>h.Tile,TopK:()=>h.TopK,Transform:()=>h.Transform,Transpose:()=>h.Transpose,Unique:()=>h.Unique,Unpack:()=>h.Unpack,UnsortedSegmentSum:()=>h.UnsortedSegmentSum,UpperBound:()=>h.UpperBound,Variable:()=>h.Variable,ZerosLike:()=>h.ZerosLike,_FusedMatMul:()=>h._FusedMatMul,abs:()=>h.abs,acos:()=>h.acos,acosh:()=>h.acosh,add:()=>h.add,addN:()=>h.addN,all:()=>h.all,any:()=>h.any,argMax:()=>h.argMax,argMin:()=>h.argMin,asin:()=>h.asin,asinh:()=>h.asinh,atan:()=>h.atan,atan2:()=>h.atan2,atanh:()=>h.atanh,avgPool:()=>h.avgPool,avgPool3d:()=>h.avgPool3d,backend:()=>h.backend,backend_util:()=>h.backend_util,basicLSTMCell:()=>h.basicLSTMCell,batchNorm:()=>h.batchNorm,batchNorm2d:()=>h.batchNorm2d,batchNorm3d:()=>h.batchNorm3d,batchNorm4d:()=>h.batchNorm4d,batchToSpaceND:()=>h.batchToSpaceND,bincount:()=>h.bincount,bitwiseAnd:()=>h.bitwiseAnd,booleanMaskAsync:()=>h.booleanMaskAsync,broadcastArgs:()=>h.broadcastArgs,broadcastTo:()=>h.broadcastTo,broadcast_util:()=>h.broadcast_util,browser:()=>h.browser,buffer:()=>h.buffer,callbacks:()=>cp,cast:()=>h.cast,ceil:()=>h.ceil,clipByValue:()=>h.clipByValue,clone:()=>h.clone,complex:()=>h.complex,concat:()=>h.concat,concat1d:()=>h.concat1d,concat2d:()=>h.concat2d,concat3d:()=>h.concat3d,concat4d:()=>h.concat4d,constraints:()=>n,conv1d:()=>h.conv1d,conv2d:()=>h.conv2d,conv2dTranspose:()=>h.conv2dTranspose,conv3d:()=>h.conv3d,conv3dTranspose:()=>h.conv3dTranspose,copyRegisteredKernels:()=>h.copyRegisteredKernels,cos:()=>h.cos,cosh:()=>h.cosh,cosineWindow:()=>h.cosineWindow,cumprod:()=>h.cumprod,cumsum:()=>h.cumsum,customGrad:()=>h.customGrad,data:()=>u,denseBincount:()=>h.denseBincount,deprecationWarn:()=>h.deprecationWarn,depthToSpace:()=>h.depthToSpace,depthwiseConv2d:()=>h.depthwiseConv2d,deregisterOp:()=>dp.deregisterOp,device_util:()=>h.device_util,diag:()=>h.diag,dilation2d:()=>h.dilation2d,disableDeprecationWarnings:()=>h.disableDeprecationWarnings,dispose:()=>h.dispose,disposeVariables:()=>h.disposeVariables,div:()=>h.div,divNoNan:()=>h.divNoNan,dot:()=>h.dot,dropout:()=>h.dropout,einsum:()=>h.einsum,elu:()=>h.elu,enableDebugMode:()=>h.enableDebugMode,enableProdMode:()=>h.enableProdMode,enclosingPowerOfTwo:()=>h.enclosingPowerOfTwo,engine:()=>h.engine,ensureShape:()=>h.ensureShape,env:()=>h.env,equal:()=>h.equal,erf:()=>h.erf,euclideanNorm:()=>h.euclideanNorm,exp:()=>h.exp,expandDims:()=>h.expandDims,expm1:()=>h.expm1,eye:()=>h.eye,fft:()=>h.fft,fill:()=>h.fill,findBackend:()=>h.findBackend,findBackendFactory:()=>h.findBackendFactory,floor:()=>h.floor,floorDiv:()=>h.floorDiv,forceHalfFloat:()=>zd.forceHalfFloat,fused:()=>h.fused,gather:()=>h.gather,gatherND:()=>h.gatherND,gather_util:()=>h.gather_util,getBackend:()=>h.getBackend,getGradient:()=>h.getGradient,getKernel:()=>h.getKernel,getKernelsForBackend:()=>h.getKernelsForBackend,gpgpu_util:()=>zd.gpgpu_util,grad:()=>h.grad,grads:()=>h.grads,greater:()=>h.greater,greaterEqual:()=>h.greaterEqual,ifft:()=>h.ifft,imag:()=>h.imag,image:()=>h.image,inTopKAsync:()=>h.inTopKAsync,initializers:()=>i,input:()=>Qo,io:()=>h.io,irfft:()=>h.irfft,isFinite:()=>h.isFinite,isInf:()=>h.isInf,isNaN:()=>h.isNaN,keep:()=>h.keep,kernel_impls:()=>h.kernel_impls,layers:()=>r,leakyRelu:()=>h.leakyRelu,less:()=>h.less,lessEqual:()=>h.lessEqual,linalg:()=>h.linalg,linspace:()=>h.linspace,loadGraphModel:()=>dp.loadGraphModel,loadGraphModelSync:()=>dp.loadGraphModelSync,loadLayersModel:()=>Jo,localResponseNormalization:()=>h.localResponseNormalization,log:()=>h.log,log1p:()=>h.log1p,logSigmoid:()=>h.logSigmoid,logSoftmax:()=>h.logSoftmax,logSumExp:()=>h.logSumExp,logicalAnd:()=>h.logicalAnd,logicalNot:()=>h.logicalNot,logicalOr:()=>h.logicalOr,logicalXor:()=>h.logicalXor,losses:()=>h.losses,lowerBound:()=>h.lowerBound,matMul:()=>h.matMul,math:()=>h.math,max:()=>h.max,maxPool:()=>h.maxPool,maxPool3d:()=>h.maxPool3d,maxPoolWithArgmax:()=>h.maxPoolWithArgmax,maximum:()=>h.maximum,mean:()=>h.mean,memory:()=>h.memory,meshgrid:()=>h.meshgrid,metrics:()=>a,min:()=>h.min,minimum:()=>h.minimum,mirrorPad:()=>h.mirrorPad,mod:()=>h.mod,model:()=>Yo,models:()=>o,moments:()=>h.moments,movingAverage:()=>h.movingAverage,mul:()=>h.mul,multiRNNCell:()=>h.multiRNNCell,multinomial:()=>h.multinomial,neg:()=>h.neg,nextFrame:()=>h.nextFrame,norm:()=>h.norm,notEqual:()=>h.notEqual,oneHot:()=>h.oneHot,ones:()=>h.ones,onesLike:()=>h.onesLike,op:()=>h.op,outerProduct:()=>h.outerProduct,pad:()=>h.pad,pad1d:()=>h.pad1d,pad2d:()=>h.pad2d,pad3d:()=>h.pad3d,pad4d:()=>h.pad4d,pool:()=>h.pool,pow:()=>h.pow,prelu:()=>h.prelu,print:()=>h.print,prod:()=>h.prod,profile:()=>h.profile,raggedGather:()=>h.raggedGather,raggedRange:()=>h.raggedRange,raggedTensorToTensor:()=>h.raggedTensorToTensor,rand:()=>h.rand,randomGamma:()=>h.randomGamma,randomNormal:()=>h.randomNormal,randomStandardNormal:()=>h.randomStandardNormal,randomUniform:()=>h.randomUniform,randomUniformInt:()=>h.randomUniformInt,range:()=>h.range,ready:()=>h.ready,real:()=>h.real,reciprocal:()=>h.reciprocal,registerBackend:()=>h.registerBackend,registerCallbackConstructor:()=>tl,registerGradient:()=>h.registerGradient,registerKernel:()=>h.registerKernel,registerOp:()=>dp.registerOp,regularizers:()=>l,relu:()=>h.relu,relu6:()=>h.relu6,removeBackend:()=>h.removeBackend,reshape:()=>h.reshape,reverse:()=>h.reverse,reverse1d:()=>h.reverse1d,reverse2d:()=>h.reverse2d,reverse3d:()=>h.reverse3d,reverse4d:()=>h.reverse4d,rfft:()=>h.rfft,round:()=>h.round,rsqrt:()=>h.rsqrt,scalar:()=>h.scalar,scatterND:()=>h.scatterND,scatter_util:()=>h.scatter_util,searchSorted:()=>h.searchSorted,selu:()=>h.selu,separableConv2d:()=>h.separableConv2d,sequential:()=>Xo,serialization:()=>h.serialization,setBackend:()=>h.setBackend,setPlatform:()=>h.setPlatform,setWebGLContext:()=>zd.setWebGLContext,setdiff1dAsync:()=>h.setdiff1dAsync,shared:()=>Nd.shared,sigmoid:()=>h.sigmoid,sign:()=>h.sign,signal:()=>h.signal,sin:()=>h.sin,sinh:()=>h.sinh,slice:()=>h.slice,slice1d:()=>h.slice1d,slice2d:()=>h.slice2d,slice3d:()=>h.slice3d,slice4d:()=>h.slice4d,slice_util:()=>h.slice_util,softmax:()=>h.softmax,softplus:()=>h.softplus,spaceToBatchND:()=>h.spaceToBatchND,sparse:()=>h.sparse,sparseToDense:()=>h.sparseToDense,spectral:()=>h.spectral,split:()=>h.split,sqrt:()=>h.sqrt,square:()=>h.square,squaredDifference:()=>h.squaredDifference,squeeze:()=>h.squeeze,stack:()=>h.stack,step:()=>h.step,stridedSlice:()=>h.stridedSlice,string:()=>h.string,sub:()=>h.sub,sum:()=>h.sum,sumOutType:()=>h.sumOutType,tan:()=>h.tan,tanh:()=>h.tanh,tensor:()=>h.tensor,tensor1d:()=>h.tensor1d,tensor2d:()=>h.tensor2d,tensor3d:()=>h.tensor3d,tensor4d:()=>h.tensor4d,tensor5d:()=>h.tensor5d,tensor6d:()=>h.tensor6d,tensorScatterUpdate:()=>h.tensorScatterUpdate,tensor_util:()=>h.tensor_util,test_util:()=>h.test_util,tidy:()=>h.tidy,tile:()=>h.tile,time:()=>h.time,topk:()=>h.topk,train:()=>h.train,transpose:()=>h.transpose,truncatedNormal:()=>h.truncatedNormal,unique:()=>h.unique,unregisterGradient:()=>h.unregisterGradient,unregisterKernel:()=>h.unregisterKernel,unsortedSegmentSum:()=>h.unsortedSegmentSum,unstack:()=>h.unstack,upcastType:()=>h.upcastType,upperBound:()=>h.upperBound,util:()=>h.util,valueAndGrad:()=>h.valueAndGrad,valueAndGrads:()=>h.valueAndGrads,variable:()=>h.variable,variableGrads:()=>h.variableGrads,version:()=>Ad,version_converter:()=>dp.version_converter,version_core:()=>h.version_core,version_cpu:()=>Nd.version_cpu,version_layers:()=>Ao,version_webgl:()=>zd.version_webgl,webgl:()=>zd.webgl,webgl_util:()=>zd.webgl_util,where:()=>h.where,whereAsync:()=>h.whereAsync,zeros:()=>h.zeros,zerosLike:()=>h.zerosLike});var n={};s.r(n),s.d(n,{maxNorm:()=>fa,minMaxNorm:()=>ya,nonNeg:()=>ma,unitNorm:()=>ga});var i={};s.r(i),s.d(i,{constant:()=>va,glorotNormal:()=>Ca,glorotUniform:()=>Aa,heNormal:()=>Ia,heUniform:()=>Ta,identity:()=>Na,leCunNormal:()=>Da,leCunUniform:()=>Ea,ones:()=>ba,orthogonal:()=>Fa,randomNormal:()=>Sa,randomUniform:()=>ka,truncatedNormal:()=>xa,varianceScaling:()=>za,zeros:()=>wa});var r={};s.r(r),s.d(r,{Layer:()=>Hr,RNN:()=>su,RNNCell:()=>nu,activation:()=>Mh,add:()=>qh,alphaDropout:()=>$c,average:()=>Gh,averagePooling1d:()=>ec,averagePooling2d:()=>ic,averagePooling3d:()=>oc,avgPool1d:()=>sc,avgPool2d:()=>rc,avgPool3d:()=>lc,avgPooling1d:()=>nc,avgPooling2d:()=>ac,avgPooling3d:()=>uc,batchNormalization:()=>Xh,bidirectional:()=>Cc,categoryEncoding:()=>Pc,centerCrop:()=>_c,concatenate:()=>Hh,conv1d:()=>Ch,conv2d:()=>Ih,conv2dTranspose:()=>Th,conv3d:()=>Dh,conv3dTranspose:()=>Eh,convLstm2d:()=>xc,convLstm2dCell:()=>Nc,cropping2D:()=>Lh,dense:()=>Oh,depthwiseConv2d:()=>$h,dot:()=>Yh,dropout:()=>_h,elu:()=>kh,embedding:()=>Vh,flatten:()=>Ph,gaussianDropout:()=>Rc,gaussianNoise:()=>Lc,globalAveragePooling1d:()=>hc,globalAveragePooling2d:()=>cc,globalMaxPool1d:()=>Tc,globalMaxPool2d:()=>Dc,globalMaxPooling1d:()=>pc,globalMaxPooling2d:()=>dc,gru:()=>yc,gruCell:()=>wc,input:()=>Qo,inputLayer:()=>vh,layerNormalization:()=>Qh,leakyReLU:()=>xh,lstm:()=>bc,lstmCell:()=>vc,masking:()=>Mc,maxPool1d:()=>Ec,maxPool2d:()=>Fc,maxPooling1d:()=>fc,maxPooling2d:()=>gc,maxPooling3d:()=>mc,maximum:()=>Kh,minimum:()=>Jh,multiply:()=>Zh,permute:()=>jh,prelu:()=>Nh,randomWidth:()=>Wc,reLU:()=>Sh,repeatVector:()=>Wh,rescaling:()=>Oc,reshape:()=>Uh,resizing:()=>Bc,rnn:()=>zc,separableConv2d:()=>Fh,simpleRNN:()=>kc,simpleRNNCell:()=>Sc,softmax:()=>zh,spatialDropout1d:()=>Bh,stackedRNNCells:()=>Ac,thresholdedReLU:()=>Ah,timeDistributed:()=>Ic,upSampling2d:()=>Rh,zeroPadding2d:()=>tc});var a={};s.r(a),s.d(a,{MAPE:()=>Xc,MSE:()=>ep,binaryAccuracy:()=>Uc,binaryCrossentropy:()=>jc,categoricalAccuracy:()=>qc,categoricalCrossentropy:()=>Gc,cosineProximity:()=>Jc,mape:()=>Qc,meanAbsoluteError:()=>Zc,meanAbsolutePercentageError:()=>Yc,meanSquaredError:()=>tp,mse:()=>sp,precision:()=>Hc,r2Score:()=>np,recall:()=>Kc,sparseCategoricalAccuracy:()=>Vc});var o={};s.r(o),s.d(o,{modelFromJSON:()=>Ko});var l={};s.r(l),s.d(l,{l1:()=>rp,l1l2:()=>ip,l2:()=>ap});var u={};s.r(u),s.d(u,{CSVDataset:()=>nd,Dataset:()=>qp,FileDataSource:()=>md,TextLineDataset:()=>Zp,URLDataSource:()=>yd,array:()=>Hp,csv:()=>wd,func:()=>bd,generator:()=>vd,microphone:()=>Sd,version_data:()=>xd,webcam:()=>kd,zip:()=>Kp});var h=s(5743),c=s(9554),p=s(7794),d=s(803),f=s(319);const g={kernelName:c.ljI,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,(0,f.P)((0,p.w)(s,"float32"),-1))}}};var m=s(4974),y=s(1011),w=s(1997),b=s(191),v=s(7738),k=s(7951);const S={kernelName:c.Vvy,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>{const e=(0,v.E)((0,p.w)(s,"float32")),n=(0,b.R)((0,k.j)((0,w.d)(1),e));return(0,y.H)((0,m.y)(t,n))}}}},x={kernelName:c.PH8,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>{const e=(0,b.R)((0,k.j)((0,v.E)((0,p.w)(s,"float32")),1));return(0,m.y)(t,e)}}}};var N=s(8805),z=s(5583),A=s(7382);const C={kernelName:c.OMN,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=N.assertAndGetBroadcastShape(s.shape,n.shape);return{a:()=>{let e=t;const n=N.getReductionAxes(s.shape,i);return n.length>0&&(e=(0,A.c)(e,n)),(0,z.t)(e,s.shape)},b:()=>{let e=t;const s=N.getReductionAxes(n.shape,i);return s.length>0&&(e=(0,A.c)(e,s)),(0,z.t)(e,n.shape)}}}},I={kernelName:c.EkD,saveAllInputs:!0,gradFunc:(t,e)=>{const s={};return e.forEach(((e,n)=>{s[n]=()=>t.clone()})),s}};var T=s(3290);const D={kernelName:c.Jp_,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,T.P)(s)}}},E={kernelName:c.p_m,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,T.P)(s)}}},F={kernelName:c.QKF,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,b.R)((0,k.j)((0,w.d)(1),(0,v.E)((0,p.w)(s,"float32")))))}}};var L=s(7242);const R={kernelName:c.epO,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>{const e=(0,b.R)((0,L.W)((0,w.d)(1),(0,v.E)((0,p.w)(s,"float32"))));return(0,m.y)(t,e)}}}},$={kernelName:c.lxb,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=(0,N.assertAndGetBroadcastShape)(s.shape,n.shape);return{a:()=>{const e=(0,L.W)((0,v.E)(s),(0,v.E)(n));let r=(0,d.l)(t,(0,m.y)(n,e));const a=(0,N.getReductionAxes)(s.shape,i);return a.length>0&&(r=(0,A.c)(r,a)),(0,z.t)(r,s.shape)},b:()=>{const e=(0,L.W)((0,v.E)(s),(0,v.E)(n));let r=(0,y.H)((0,d.l)(t,(0,m.y)(s,e)));const a=(0,N.getReductionAxes)(n.shape,i);return a.length>0&&(r=(0,A.c)(r,a)),(0,z.t)(r,n.shape)}}}},M={kernelName:c.TyE,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,L.W)((0,v.E)((0,p.w)(s,"float32")),1))}}},O={kernelName:c.zP9,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,k.j)((0,w.d)(1),(0,v.E)((0,p.w)(s,"float32"))))}}};var _=s(2164),B=s(4148),P=s(1426),W=s(7538),U=s(7892);const j=(0,U.op)({avgPool3dGrad_:function(t,e,s,n,i,r){const a=(0,B.YT)(t,"dy","avgPool3dGrad"),o=(0,B.YT)(e,"input","avgPool3dGrad");let l=a,u=o,h=!1;4===o.rank&&(h=!0,l=(0,z.t)(a,[1,a.shape[0],a.shape[1],a.shape[2],a.shape[3]]),u=(0,z.t)(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),P.vA(5===l.rank,(()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`)),P.vA(5===u.rank,(()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${u.rank}.`)),(0,W.s_)("avgPool3dGrad",i,r);const p={dy:l,input:u},d={filterSize:s,strides:n,pad:i,dimRoundingMode:r},f=_.T2.runKernel(c.wwC,p,d);return h?(0,z.t)(f,[f.shape[1],f.shape[2],f.shape[3],f.shape[4]]):f}}),V={kernelName:c.cS,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{filterSize:i,strides:r,pad:a,dimRoundingMode:o}=s;return{x:()=>j(t,n,i,r,a,o)}}};const q=(0,U.op)({avgPoolGrad_:function(t,e,s,n,i){const r=(0,B.YT)(t,"dy","avgPoolGrad"),a=(0,B.YT)(e,"input","avgPoolGrad");P.vA(a.rank===r.rank,(()=>`Rank of input (${a.rank}) does not match rank of dy (${r.rank})`));let o=a,l=r,u=!1;3===a.rank&&(u=!0,o=(0,z.t)(a,[1,a.shape[0],a.shape[1],a.shape[2]]),l=(0,z.t)(r,[1,r.shape[0],r.shape[1],r.shape[2]])),P.vA(4===l.rank,(()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`)),P.vA(4===o.rank,(()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${o.rank}.`));const h={dy:l,input:o},p={filterSize:s,strides:n,pad:i},d=_.T2.runKernel(c.VCH,h,p);return u?(0,z.t)(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),G={kernelName:c.ho8,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{filterSize:i,strides:r,pad:a}=s;return{x:()=>q(t,n,i,r,a)}}};var H=s(5162);const K={kernelName:c.jAQ,inputsToSave:["a","b"],gradFunc:(t,e,s)=>{const[n,i]=e,{transposeA:r,transposeB:a}=s;return r||a?!r&&a?{a:()=>(0,H.N)(t,i,!1,!1),b:()=>(0,H.N)(t,n,!0,!1)}:r&&!a?{a:()=>(0,H.N)(i,t,!1,!0),b:()=>(0,H.N)(n,t,!1,!1)}:{a:()=>(0,H.N)(i,t,!0,!0),b:()=>(0,H.N)(t,n,!0,!0)}:{a:()=>(0,H.N)(t,i,!1,!0),b:()=>(0,H.N)(n,t,!0,!1)}}};var J=s(3585);const Z={kernelName:c.Ik2,gradFunc:(t,e,s)=>{const{blockShape:n,crops:i}=s;return{x:()=>(0,J.e)(t,n,i)}}},Y={kernelName:c.LB5,gradFunc:(t,e,s)=>{const n=s,i=n.inputShape,r=n.shape,a=Array.from(r);for(let l=i.length-1;l>=0;l--)if(i[l]===r[l])a[l]=1;else if(1!==i[l])throw new Error(`broadcastTo(): [${i}] cannot be broadcast to [${r}].`);const o=[];for(let l=0;l<a.length;l++)a[l]>1&&o.push(l);return{x:()=>(0,A.c)(t,o,!0)}}},X={kernelName:c.KXH,gradFunc:t=>({x:()=>t.clone()})},Q={kernelName:c.QDP,gradFunc:t=>({x:()=>(0,T.P)(t)})};var tt=s(9996),et=s(827),st=s(5692),nt=s(3986);const it={kernelName:c.vaV,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{clipValueMin:i,clipValueMax:r}=s;return{x:()=>(0,nt._)((0,st.n)((0,tt.D)(n,i),(0,et.I)(n,r)),t,(0,T.P)(t))}}},rt={kernelName:c.$zE,inputsToSave:["x"],gradFunc:g.gradFunc};var at=s(5181);const ot={kernelName:c.$dB,saveAllInputs:!0,gradFunc:(t,e,s)=>{const n=e.map((t=>t.shape)),{axis:i}=s,r=(0,P.Y6)(i,e[0].shape)[0],a=n.map((t=>t[r]));return(0,at.l)(t,a,r).map((t=>()=>t))}};var lt=s(6927),ut=s(1565);const ht={kernelName:c.p2J,inputsToSave:["x","filter"],gradFunc:(t,e,s)=>{const[n,i]=e,{dilations:r,strides:a,pad:o,dataFormat:l}=s;return P.vA(W.Dh(r),(()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`)),{x:()=>(0,ut.v)(n.shape,t,i,a,o,l),filter:()=>(0,lt.H)(n,t,i.shape,a,o,l)}}};var ct=s(4969);const pt={kernelName:c.jfg,inputsToSave:["dy","filter"],gradFunc:(t,e,s)=>{const[n,i]=e,{strides:r,pad:a,dataFormat:o,dimRoundingMode:l}=s;return{dy:()=>(0,ct.X)(t,i,r,a,o,1,l),filter:()=>(0,lt.H)(t,n,i.shape,r,a,o,l)}}};const dt=(0,U.op)({conv3DBackpropFilter_:function(t,e,s,n,i){let r=t;4===t.rank&&(r=(0,z.t)(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]));let a=e;4===a.rank&&(a=(0,z.t)(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]])),P.vA(5===r.rank,(()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${r.shape}.`)),P.vA(5===a.rank,(()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${a.shape}.`)),P.vA(5===s.length,(()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${s}.`)),P.vA(r.shape[4]===s[3],(()=>`Error in conv3dDerFilter: depth of input ${r.shape[4]}) must match input depth in filter (${s[3]}.`)),P.vA(a.shape[4]===s[4],(()=>`Error in conv3dDerFilter: depth of dy (${a.shape[4]}) must match output depth for filter (${s[4]}).`));const o={x:r,dy:a},l={strides:n,pad:i,filterShape:s};return _.T2.runKernel(c.iGz,o,l)}});var ft=s(6410);const gt={kernelName:c.A1h,inputsToSave:["x","filter"],gradFunc:(t,e,s)=>{const{dilations:n,strides:i,pad:r}=s;P.vA((0,W.Dh)(n),(()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${n}'`));const[a,o]=e;return{x:()=>(0,ft.c)(a.shape,t,o,i,r),filter:()=>dt(a,t,o.shape,i,r)}}};var mt=s(9519);const yt={kernelName:c.Mn0,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)((0,y.H)((0,mt.F)((0,p.w)(s,"float32"))),t)}}};var wt=s(8143);const bt={kernelName:c.MnK,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)((0,wt.L)((0,p.w)(s,"float32")),t)}}};var vt=s(9235),kt=s(7167),St=s(2154);const xt={kernelName:c.nY8,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{axis:i,exclusive:r,reverse:a}=s;return{x:()=>{const e=(0,vt.Em)([i],n.rank);let s=(0,kt.r)(t,i,r,!a);return null!=e&&(s=(0,St.m)(s,e)),s}}}};var Nt=s(7399),zt=s(261);const At={kernelName:c.tGH,inputsToSave:["x","filter"],gradFunc:(t,e,s)=>{const{dilations:n,strides:i,pad:r,dimRoundingMode:a}=s,o=null==n?[1,1]:n;P.vA(W.Dh(o),(()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`));const[l,u]=e;return P.vA(4===l.rank,(()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`)),P.vA(4===u.rank,(()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`)),P.vA(l.shape[3]===u.shape[2],(()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`)),P.vA(W.G0(i,o),(()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${i} and dilations '${o}'.`)),W.s_("depthwiseConv2d",r,a),{x:()=>(0,zt.l)(l.shape,t,u,i,r,o,a),filter:()=>(0,Nt.x)(l,t,u.shape,i,r,o,a)}}},Ct={kernelName:c.jxD,inputsToSave:["x","filter"],gradFunc:(t,e,s)=>{const[n,i]=e,r={x:n,filter:i,dy:t},a={x:n,filter:i,dy:t};return{x:()=>_.T2.runKernel(c.bP9,r,s),filter:()=>_.T2.runKernel(c.pk0,a,s)}}},It={kernelName:c.Pah,outputsToSave:[!0],gradFunc:(t,e)=>{const[s]=e,n={dy:t,y:s};return{x:()=>_.T2.runKernel(c.rsH,n)}}};var Tt=s(5462);const Dt={kernelName:c._s9,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e,n=(0,d.l)((0,Tt.o)((0,y.H)((0,v.E)(s))),2/Math.sqrt(Math.PI));return{x:()=>(0,d.l)(t,n)}}},Et={kernelName:c.ox3,outputsToSave:[!0],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,s)}}},Ft={kernelName:c.ybN,inputsToSave:["input"],gradFunc:(t,e)=>{const[s]=e;return{input:()=>(0,z.t)(t,s.shape)}}},Lt={kernelName:c.ybj,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,(0,Tt.o)(s))}}},Rt={kernelName:c.ZgB,gradFunc:t=>({x:()=>(0,T.P)(t)})},$t={kernelName:c.ElG,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=(0,N.assertAndGetBroadcastShape)(s.shape,n.shape);return{a:()=>{const e=(0,m.y)(t,(0,p.w)(n,"float32")),r=(0,N.getReductionAxes)(s.shape,i);return r.length>0?(0,z.t)((0,A.c)(e,r),s.shape):e},b:()=>{let e=(0,d.l)(t,(0,p.w)(s,"float32"));const r=(0,N.getReductionAxes)(n.shape,i);r.length>0&&(e=(0,z.t)((0,A.c)(e,r),n.shape));const a=(0,v.E)(n);return(0,y.H)((0,m.y)(e,(0,p.w)(a,"float32")))}}}};var Mt=s(6777),Ot=s(3017);const _t={kernelName:c.i5R,inputsToSave:["x","mean","variance","scale"],gradFunc:(t,e,s)=>{const{varianceEpsilon:n}=s,[i,r,a,o]=e,l=null==o?(0,w.d)(1):o,u=(0,N.getReductionAxes)(r.shape,i.shape),h=[];if(1===r.rank){for(let t=0;t<i.shape.length-1;++t)h.push(i.shape[t]);h.push(1)}const c=(0,k.j)(i,r),p=(0,d.l)(t,l),f=(0,Mt.Z)((0,L.W)(a,(0,w.d)(n))),g=(0,d.l)((0,d.l)((0,d.l)(f,f),f),(0,w.d)(-.5));return{x:()=>1===r.rank?(0,z.t)((0,d.l)((0,d.l)(t,(0,Ot.V)((0,z.t)(f,[1,1,1,r.shape[0]]),h)),l),i.shape):(0,z.t)((0,d.l)((0,d.l)(t,f),l),i.shape),mean:()=>{let t=(0,d.l)((0,d.l)(f,(0,w.d)(-1)),p);return 1===r.rank&&(t=(0,A.c)(t,u)),(0,z.t)(t,r.shape)},variance:()=>{let t=(0,d.l)((0,d.l)(g,c),p);return 1===r.rank&&(t=(0,A.c)(t,u)),(0,z.t)(t,r.shape)},scale:()=>{const e=(0,d.l)(c,f);let s=(0,d.l)(t,e);return 1===r.rank&&(s=(0,A.c)(s,u)),(0,z.t)(s,r.shape)},offset:()=>{let e=t;return 1===r.rank&&(e=(0,A.c)(e,u)),(0,z.t)(e,r.shape)}}}};var Bt=s(901),Pt=s(5149);const Wt={kernelName:c.mxL,inputsToSave:["x","indices"],gradFunc:(t,e,s)=>{const[n,i]=e,{axis:r,batchDims:a}=s,o=(0,P.Y6)(r,n.shape)[0],l=(t,e,s)=>()=>{const n=t.shape,i=e.size,a=n.slice(0,o),l=a.length,u=n.slice(r,n.length).slice(1),h=u.length,c=Ut(0,l),p=Ut(l+1,l+1+h),d=jt([a,[i],u]),f=(0,z.t)(s,d),g=(0,z.t)(e,[i]),m=jt([[l],c,p]),y=(0,St.m)(f,m);let w=(0,Pt.z)(y,g,t.shape[o]);const b=(0,vt.gx)(m);return w=(0,St.m)(w,b),w};if(1===a){const e=n.shape[0],s=n.split(e,0);return{x:()=>{const e=(0,Bt.t)(s.map(((e,s)=>l(e,i.slice(s,1),t.slice(s,1))())));return e.reshape(n.shape)},indices:()=>i}}return{x:l(n,i,t),indices:()=>i}}};function Ut(t,e){const s=[];for(let n=t;n<e;++n)s.push(n);return s}function jt(t){const e=[];for(let s=0;s<t.length;++s)for(let n=0;n<t[s].length;++n)e.push(t[s][n]);return e}const Vt={kernelName:c.lLS,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e;return{a:()=>(0,T.P)(s),b:()=>(0,T.P)(n)}}},qt={kernelName:c.lzr,gradFunc:t=>({x:()=>(0,p.w)(t,"float32")})},Gt={kernelName:c.gIW,gradFunc:t=>({x:()=>(0,T.P)(t)})},Ht={kernelName:c.E3$,gradFunc:t=>({x:()=>(0,T.P)(t)})},Kt={kernelName:c.iPs,gradFunc:t=>({x:()=>(0,T.P)(t)})};var Jt=s(2759);const Zt={kernelName:c.X0$,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{alpha:i}=s,r=(0,Jt.r)(n,0);return{x:()=>(0,nt._)(r,t,(0,d.l)(t,i))}}},Yt={kernelName:c.Cg$,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,L.W)(s,1))}}},Xt={kernelName:c.tG8,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,p.w)(s,"float32"))}}},Qt={kernelName:c.zfU,inputsToSave:[],outputsToSave:[!0],gradFunc:(t,e,s)=>{const[n]=e,{axis:i}=s;return{logits:()=>{const e=(0,Tt.o)(n);return(0,k.j)(t,(0,d.l)((0,A.c)(t,i,!0),e))}}}};const te=(0,U.op)({localResponseNormalizationBackprop_:function(t,e,s){const n={x:t,y:e,dy:s},i={depthRadius:arguments.length>3&&void 0!==arguments[3]?arguments[3]:5,bias:arguments.length>4&&void 0!==arguments[4]?arguments[4]:1,alpha:arguments.length>5&&void 0!==arguments[5]?arguments[5]:1,beta:arguments.length>6&&void 0!==arguments[6]?arguments[6]:.5};return _.T2.runKernel(c.ToN,n,i)}}),ee={kernelName:c.jM4,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,s)=>{const[n,i]=e,{depthRadius:r,bias:a,alpha:o,beta:l}=s;return{x:()=>te(n,i,t,r,a,o,l)}}};var se=s(7457);function ne(t,e,s,n){return e.rank<s.rank&&(e=(0,z.t)(e,vt.SM(e.shape,n))),t.rank<s.rank&&(t=(0,z.t)(t,vt.SM(t.shape,n))),{x:()=>(0,d.l)(t,(0,p.w)((0,se.L)(s,e),t.dtype))}}const ie={kernelName:c.VAI,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,s)=>{const n=s,{reductionIndices:i}=n,r=e[0],a=ne(t,e[1],r,P.Y6(i,r.shape));return{x:()=>a.x()}}};var re=s(8320);const ae={kernelName:c.LDN,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e;return{a:()=>(0,d.l)(t,(0,p.w)((0,tt.D)(s,n),"float32")),b:()=>(0,d.l)(t,(0,p.w)((0,re.M)(s,n),"float32"))}}};const oe=(0,U.op)({maxPool3dGrad_:function(t,e,s,n,i,r,a){const o=(0,B.YT)(t,"dy","maxPool3dGrad"),l=(0,B.YT)(e,"input","maxPool3dGrad"),u=(0,B.YT)(s,"output","maxPool3dGrad");let h=o,p=l,d=u,f=!1;4===l.rank&&(f=!0,h=(0,z.t)(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),p=(0,z.t)(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),d=(0,z.t)(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),P.vA(5===h.rank,(()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${h.rank}.`)),P.vA(5===p.rank,(()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${p.rank}.`)),P.vA(5===d.rank,(()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${d.rank}.`)),(0,W.s_)("maxPool3dGrad",r,a);const g={dy:h,input:p,output:d},m={filterSize:n,strides:i,pad:r,dimRoundingMode:a},y=_.T2.runKernel(c.cHb,g,m);return f?(0,z.t)(y,[y.shape[1],y.shape[2],y.shape[3],y.shape[4]]):y}}),le={kernelName:c.ySp,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,s)=>{const[n,i]=e,{filterSize:r,strides:a,pad:o,dimRoundingMode:l}=s;return{x:()=>oe(t,n,i,r,a,o,l)}}};const ue=(0,U.op)({maxPoolGrad_:function(t,e,s,n,i,r,a){const o=(0,B.YT)(t,"dy","maxPoolGrad"),l=(0,B.YT)(e,"input","maxPoolGrad"),u=(0,B.YT)(s,"output","maxPoolGrad");P.vA(l.rank===o.rank,(()=>`Rank of input (${l.rank}) does not match rank of dy (${o.rank})`)),P.vA(4===o.rank,(()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${o.rank}.`)),P.vA(4===l.rank,(()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`)),W.s_("maxPoolGrad",r,a);const h={dy:o,input:l,output:u},p={filterSize:n,strides:i,pad:r,dimRoundingMode:a};return _.T2.runKernel(c.RXX,h,p)}}),he={kernelName:c.t3d,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,s)=>{const[n,i]=e,{filterSize:r,strides:a,pad:o}=s;return{x:()=>ue(t,n,i,r,a,o)}}};var ce=s(4616);const pe={kernelName:c.g5A,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{axis:i}=s,r=P.Y6(i,n.shape),a=(0,vt.lb)(n.shape,r)[1],o=P.Ze(a);return{x:()=>{const e=n.shape.slice();r.forEach((t=>{e[t]=1}));const s=(0,z.t)(t,e);return(0,m.y)((0,d.l)(s,(0,ce.S)(n.shape,"float32")),o)}}}},de={kernelName:c.lNG,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,s)=>{const n=s,{axis:i}=n,[r,a]=e,o=ne(t,a,r,P.Y6(i,r.shape));return{x:()=>o.x()}}},fe={kernelName:c.LG0,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e;return{a:()=>(0,d.l)(t,(0,p.w)((0,et.I)(s,n),"float32")),b:()=>(0,d.l)(t,(0,p.w)((0,Jt.r)(s,n),"float32"))}}};var ge=s(463);const me={kernelName:c.x7F,inputsToSave:["x"],gradFunc:(t,e,s)=>{const n=e[0],{paddings:i}=s,r=i.map((t=>t[0]));return{x:()=>(0,ge.d)(t,r,n.shape)}}};var ye=s(8587);const we={kernelName:c.BLA,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=(0,N.assertAndGetBroadcastShape)(s.shape,n.shape);return{a:()=>{const e=(0,N.getReductionAxes)(s.shape,i);return e.length>0?(0,z.t)((0,A.c)(t,e),s.shape):t},b:()=>{const e=(0,d.l)(t,(0,y.H)((0,ye.R)((0,m.y)(s,n)))),r=(0,N.getReductionAxes)(n.shape,i);return r.length>0?(0,z.t)((0,A.c)(e,r),n.shape):e}}}},be={kernelName:c.xu7,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=(0,N.assertAndGetBroadcastShape)(s.shape,n.shape);return{a:()=>{const e=(0,d.l)(t,(0,p.w)(n,"float32")),r=(0,N.getReductionAxes)(s.shape,i);return r.length>0?(0,z.t)((0,A.c)(e,r),s.shape):e},b:()=>{const e=(0,d.l)(t,(0,p.w)(s,"float32")),r=(0,N.getReductionAxes)(n.shape,i);return r.length>0?(0,z.t)((0,A.c)(e,r),n.shape):e}}}},ve={kernelName:c.l0G,gradFunc:t=>({x:()=>(0,y.H)(t)})};var ke=s(4218);const Se={kernelName:c.urI,inputsToSave:["indices"],gradFunc:(t,e)=>{const s=e[0];return{indices:()=>(0,ke.U)(s.shape,"float32")}}},xe={kernelName:c.LWX,gradFunc:t=>({x:()=>(0,T.P)(t)})};var Ne=s(3984);const ze={kernelName:c.mM$,saveAllInputs:!0,gradFunc:(t,e,s)=>{const{axis:n}=s;return(0,Ne.K)(t,n).map((t=>()=>t))}},Ae={kernelName:c.ODT,inputsToSave:["x"],gradFunc:(t,e,s)=>{const n=e[0],{paddings:i}=s,r=i.map((t=>t[0]));return{x:()=>(0,ge.d)(t,r,n.shape)}}};var Ce=s(5911),Ie=s(7587);const Te={kernelName:c.pyJ,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(t,e)=>{const[s,n,i]=e,r=s,a=n,o=N.assertAndGetBroadcastShape(r.shape,a.shape);return{a:()=>{const e=(0,p.w)(a,"float32");let s=(0,d.l)(t,(0,d.l)(e,(0,Ie.n)(r,(0,k.j)(e,(0,w.d)(1)))));const n=N.getReductionAxes(r.shape,o);return n.length>0&&(s=(0,A.c)(s,n)),(0,z.t)(s,r.shape)},b:()=>{const e=(0,Jt.r)(r,0),s=(0,nt._)(e,(0,Ce.R)(r),(0,T.P)(r));let n=(0,d.l)(t,(0,d.l)(i,s));const l=N.getReductionAxes(a.shape,o);return l.length>0&&(n=(0,A.c)(n,l)),(0,z.t)(n,a.shape)}}}},De={kernelName:c.Ncv,inputsToSave:["x","alpha"],gradFunc:(t,e)=>{const[s,n]=e,i=(0,Jt.r)(s,0);return{x:()=>(0,nt._)(i,t,(0,d.l)(t,n)),alpha:()=>{let e=(0,nt._)(i,(0,T.P)(t),(0,d.l)(t,s));const r=(0,N.getReductionAxes)(n.shape,t.shape);return r.length>0&&(e=(0,A.c)(e,r)),(0,z.t)(e,n.shape)}}}};var Ee=s(3739);function Fe(t,e,s){const n=t.shape.length,i=n-s.length,r=vt.Em(s,n);let a=t;null!=r&&(a=(0,St.m)(t,r));const o=a.shape.slice(),l=o.splice(n-s.length,s.length).reduce(((t,e)=>t*e),1);o.push(l);let u=function(t,e,s){const n=t.shape.slice();n[s]=1;const i=(0,z.t)(e,n),r=(0,Ee.L)(t,s,!0,!1),a=(0,Ee.L)(t,s,!0,!0),o=(0,d.l)(r,a);return(0,d.l)(i,o)}(a.reshape(o),e,i);if(u=u.reshape(a.shape),null!=r){const t=vt.gx(r);u=(0,St.m)(u,t)}return u}const Le={kernelName:c.kdj,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{axis:i}=s;let r=[];return r=void 0===i||null===i?n.shape.map(((t,e)=>e)):"number"===typeof i?[i]:i,{x:()=>Fe(n,t,r)}}},Re={kernelName:c.sDr,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=N.assertAndGetBroadcastShape(s.shape,n.shape);return{a:()=>{const e=(0,m.y)(t,(0,p.w)(n,"float32")),r=N.getReductionAxes(s.shape,i);return r.length>0?(0,z.t)((0,A.c)(e,r),s.shape):e},b:()=>{let e=(0,d.l)(t,(0,p.w)(s,"float32"));const r=N.getReductionAxes(n.shape,i);r.length>0&&(e=(0,z.t)((0,A.c)(e,r),n.shape));const a=(0,v.E)(n);return(0,y.H)((0,m.y)(e,(0,p.w)(a,"float32")))}}}},$e={kernelName:c.huO,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,y.H)((0,v.E)(s)))}}},Me={kernelName:c.P_L,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e,n=(0,d.l)((0,et.I)(s,6),(0,f.P)(s));return{x:()=>(0,d.l)(t,(0,p.w)(n,"float32"))}}},Oe={kernelName:c.fUj,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,(0,p.w)((0,f.P)(s),"float32"))}}},_e={kernelName:c.R23,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,z.t)(t,s.shape)}}},Be={kernelName:c.hgw,inputsToSave:["images"],gradFunc:(t,e,s)=>{const[n]=e,i={dy:t,images:n};return{images:()=>_.T2.runKernel(c.FCQ,i,s)}}},Pe={kernelName:c.jOE,inputsToSave:["images"],gradFunc:(t,e,s)=>{const[n]=e,i={dy:t,images:n};return{images:()=>_.T2.runKernel(c.XQy,i,s)}}};var We=s(7419);const Ue={kernelName:c.D7i,gradFunc:(t,e,s)=>{const{dims:n}=s,i=(0,P.Y6)(n,t.shape);return{x:()=>(0,We.B)(t,i)}}},je={kernelName:c.hVg,gradFunc:t=>({x:()=>(0,T.P)(t)})},Ve={kernelName:c.TOR,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,y.H)((0,m.y)(t,(0,d.l)((0,Ie.n)(s,1.5),2)))}}};var qe=s(5344);const Ge={kernelName:c.l6P,inputsToSave:["condition"],gradFunc:(t,e)=>{const[s]=e;return{condition:()=>(0,p.w)((0,T.P)(s),"float32"),t:()=>(0,d.l)(t,(0,p.w)(s,t.dtype)),e:()=>(0,d.l)(t,(0,p.w)((0,qe.N)(s),t.dtype))}}};var He=s(3765);const Ke={kernelName:c.u$b,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>{const e=(0,Jt.r)(s,(0,w.d)(0)),n=(0,w.d)(He.j),i=(0,w.d)(He.X),r=(0,d.l)(t,i),a=(0,d.l)((0,d.l)(t,n),(0,Tt.o)((0,p.w)(s,"float32")));return(0,nt._)(e,r,a)}}}},Je={kernelName:c.vI1,outputsToSave:[!0],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,(0,d.l)(s,(0,k.j)((0,w.d)(1),s)))}}},Ze={kernelName:c.YVe,gradFunc:t=>({x:()=>(0,T.P)(t)})};var Ye=s(5894);const Xe={kernelName:c.hql,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)((0,Ye.g)((0,p.w)(s,"float32")),t)}}};var Qe=s(1164);const ts={kernelName:c.J3C,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)((0,Qe.y)((0,p.w)(s,"float32")),t)}}};var es=s(5048),ss=s(4642);const ns={kernelName:c.JiE,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{begin:i,size:r}=s,a=n.shape,[o,l]=(0,ss.parseSliceParams)(n,i,r),u=[];for(let h=0;h<t.rank;h++)u.push([o[h],a[h]-o[h]-l[h]]);return{x:()=>(0,es.e)(t,u)}}},is={kernelName:c.rFG,outputsToSave:[!0],gradFunc:(t,e,s)=>{const[n]=e,{dim:i}=s,r=(0,d.l)(t,n);return{logits:()=>(0,k.j)(r,(0,d.l)((0,A.c)(r,[i],true),n))}}};var rs=s(4213);const as={kernelName:c.Fin,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,(0,rs.r)(s))}}};var os=s(2557);const ls={kernelName:c.A8B,gradFunc:(t,e,s)=>{const{blockShape:n,paddings:i}=s;return{x:()=>(0,os.G)(t,n,i)}}};var us=s(4429);const hs={kernelName:c.Blb,gradFunc:(t,e,s)=>{const{axis:n}=s;return{x:()=>(0,us.x)(t,n)}}},cs={kernelName:c.dFH,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,d.l)((0,b.R)((0,p.w)(s,"float32")),2))}}},ps={kernelName:c.M6A,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)(t,(0,d.l)((0,p.w)(s,"float32"),2))}}},ds={kernelName:c.Ddj,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=(0,w.d)(2);return{a:()=>(0,d.l)(t,(0,d.l)(i,(0,k.j)(s,n))),b:()=>(0,d.l)(t,(0,d.l)(i,(0,k.j)(n,s)))}}},fs={kernelName:c.pnw,gradFunc:t=>({x:()=>(0,T.P)(t)})},gs={kernelName:c.PbM,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[s,n]=e,i=N.assertAndGetBroadcastShape(s.shape,n.shape);return{a:()=>{let e=t;const n=N.getReductionAxes(s.shape,i);return n.length>0&&(e=(0,A.c)(e,n)),(0,z.t)(e,s.shape)},b:()=>{let e=t;const s=N.getReductionAxes(n.shape,i);return s.length>0&&(e=(0,A.c)(e,s)),(0,z.t)((0,y.H)(e),n.shape)}}}},ms={kernelName:c.WuN,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,i=n.shape.slice(),{axis:r}=s;(0,P.Y6)(r,n.shape).forEach((t=>{i[t]=1}));const a=(0,z.t)(t,i),o=(0,d.l)(a,(0,ce.S)(n.shape,"float32"));return{x:()=>o}}},ys={kernelName:c.oFs,inputsToSave:["x"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,m.y)(t,(0,v.E)((0,Ye.g)(s)))}}},ws={kernelName:c.iuW,outputsToSave:[!0],gradFunc:(t,e)=>{const[s]=e;return{x:()=>(0,d.l)((0,k.j)((0,w.d)(1),(0,v.E)(s)),t)}}},bs={kernelName:c.FAs,inputsToSave:["x"],gradFunc:(t,e,s)=>{const[n]=e,{reps:i}=s;return{x:()=>{let e=(0,T.P)(n);if(1===n.rank)for(let s=0;s<i[0];++s)e=(0,L.W)(e,(0,ge.d)(t,[s*n.shape[0]],[n.shape[0]]));else if(2===n.rank)for(let s=0;s<i[0];++s)for(let r=0;r<i[1];++r)e=(0,L.W)(e,(0,ge.d)(t,[s*n.shape[0],r*n.shape[1]],[n.shape[0],n.shape[1]]));else if(3===n.rank)for(let s=0;s<i[0];++s)for(let r=0;r<i[1];++r)for(let a=0;a<i[2];++a)e=(0,L.W)(e,(0,ge.d)(t,[s*n.shape[0],r*n.shape[1],a*n.shape[2]],[n.shape[0],n.shape[1],n.shape[2]]));else{if(4!==n.rank)throw new Error(`Gradient for tile operation is not implemented for rank-${n.rank} tensors yet.`);for(let s=0;s<i[0];++s)for(let r=0;r<i[1];++r)for(let a=0;a<i[2];++a)for(let o=0;o<i[3];++o)e=(0,L.W)(e,(0,ge.d)(t,[s*n.shape[0],r*n.shape[1],a*n.shape[2],o*n.shape[3]],[n.shape[0],n.shape[1],n.shape[2],n.shape[3]]))}return e}}}},vs={kernelName:c.wx0,gradFunc:(t,e,s)=>{const n=s,{perm:i}=n,r=vt.gx(i);return{x:()=>(0,St.m)(t,r)}}},ks={kernelName:c.dXR,gradFunc:(t,e,s)=>{const n=s,{axis:i}=n;return{value:()=>(0,Bt.t)(t,i)}}};var Ss=s(4023),xs=s(6178),Ns=s(2131);const zs={kernelName:c.pPe,inputsToSave:["segmentIds"],gradFunc:(t,e)=>{const[s]=e;return{x:()=>function(t,e){const s=(0,Ns.P)(e,(0,T.P)(e)),n=(0,xs.k)(t,s);let i=(0,tt.D)(e,(0,w.d)(0,"int32"));const r=n.rank-i.rank;for(let o=0;o<r;++o)i=(0,Ss.U)(i,o+1);i=(0,st.n)(i,(0,ce.S)(n.shape,"bool"));const a=(0,T.P)(n);return(0,nt._)(i,n,a)}(t,s)}}};const As={kernelName:c.xJ3,gradFunc:t=>({x:()=>(0,T.P)(t)})};var Cs=s(843);const Is=[g,S,x,C,I,D,E,F,R,$,M,O,V,G,K,Z,Y,X,Q,it,rt,ot,pt,ht,gt,yt,bt,xt,At,Ct,Re,It,Dt,Et,Ft,Lt,$t,Rt,_t,Wt,Vt,qt,Gt,Ht,Kt,Zt,Yt,Xt,Qt,ee,ie,ie,ae,le,he,pe,de,fe,me,we,be,ve,Se,xe,ze,Ae,Ae,Te,De,Le,$e,Me,Oe,_e,Be,Pe,Ue,je,Ve,Ge,Ke,Je,Ze,Xe,ts,ns,is,as,ls,ls,hs,hs,cs,ds,ps,fs,gs,ms,ys,ws,bs,vs,ks,zs,As];for(const Cd of Is)(0,Cs.kr)(Cd);var Ts=s(3753),Ds=s(9494);(0,Ds.tp)().prototype.abs=function(){return this.throwIfDisposed(),(0,Ts.t)(this)};var Es=s(4759);(0,Ds.tp)().prototype.acos=function(){return this.throwIfDisposed(),(0,Es.H)(this)};var Fs=s(983);(0,Ds.tp)().prototype.acosh=function(){return this.throwIfDisposed(),(0,Fs.F)(this)},(0,Ds.tp)().prototype.add=function(t){return this.throwIfDisposed(),(0,L.W)(this,t)};var Ls=s(1802);(0,Ds.tp)().prototype.all=function(t,e){return this.throwIfDisposed(),(0,Ls.Q)(this,t,e)};var Rs=s(1819);(0,Ds.tp)().prototype.any=function(t,e){return this.throwIfDisposed(),(0,Rs.b)(this,t,e)};var $s=s(3068);(0,Ds.tp)().prototype.argMax=function(t){return this.throwIfDisposed(),(0,$s.F)(this,t)};var Ms=s(8482);(0,Ds.tp)().prototype.argMin=function(t){return this.throwIfDisposed(),(0,Ms.X)(this,t)},(0,Ds.tp)().prototype.asScalar=function(){return this.throwIfDisposed(),(0,P.vA)(1===this.size,(()=>"The array must have only 1 element.")),(0,z.t)(this,[])},(0,Ds.tp)().prototype.asType=function(t){return this.throwIfDisposed(),(0,p.w)(this,t)},(0,Ds.tp)().prototype.as1D=function(){return this.throwIfDisposed(),(0,z.t)(this,[this.size])},(0,Ds.tp)().prototype.as2D=function(t,e){return this.throwIfDisposed(),(0,z.t)(this,[t,e])},(0,Ds.tp)().prototype.as3D=function(t,e,s){return this.throwIfDisposed(),(0,z.t)(this,[t,e,s])},(0,Ds.tp)().prototype.as4D=function(t,e,s,n){return this.throwIfDisposed(),(0,z.t)(this,[t,e,s,n])},(0,Ds.tp)().prototype.as5D=function(t,e,s,n,i){return this.throwIfDisposed(),(0,z.t)(this,[t,e,s,n,i])};var Os=s(3010);(0,Ds.tp)().prototype.asin=function(){return this.throwIfDisposed(),(0,Os.q)(this)};var _s=s(6464);(0,Ds.tp)().prototype.asinh=function(){return this.throwIfDisposed(),(0,_s.y)(this)};var Bs=s(7803);(0,Ds.tp)().prototype.atan=function(){return this.throwIfDisposed(),(0,Bs.r)(this)};var Ps=s(6349);(0,Ds.tp)().prototype.atan2=function(t){return this.throwIfDisposed(),(0,Ps.F)(this,t)};var Ws=s(8147);(0,Ds.tp)().prototype.atanh=function(){return this.throwIfDisposed(),(0,Ws.r)(this)};var Us=s(8650);(0,Ds.tp)().prototype.avgPool=function(t,e,s,n){return this.throwIfDisposed(),(0,Us.$)(this,t,e,s,n)},(0,Ds.tp)().prototype.batchToSpaceND=function(t,e){return this.throwIfDisposed(),(0,os.G)(this,t,e)};var js=s(7237);(0,Ds.tp)().prototype.batchNorm=function(t,e,s,n,i){return this.throwIfDisposed(),(0,js.$)(this,t,e,s,n,i)};var Vs=s(4920);(0,Ds.tp)().prototype.broadcastTo=function(t){return this.throwIfDisposed(),(0,Vs.h)(this,t)},(0,Ds.tp)().prototype.cast=function(t){return this.throwIfDisposed(),(0,p.w)(this,t)};var qs=s(5396);(0,Ds.tp)().prototype.ceil=function(){return this.throwIfDisposed(),(0,qs.m)(this)};var Gs=s(3829);(0,Ds.tp)().prototype.clipByValue=function(t,e){return this.throwIfDisposed(),(0,Gs.z)(this,t,e)},(0,Ds.tp)().prototype.concat=function(t,e){return this.throwIfDisposed(),t instanceof Ds.qY&&(t=[t]),(0,us.x)([this,...t],e)};var Hs=s(9870);(0,Ds.tp)().prototype.conv1d=function(t,e,s,n,i,r){return this.throwIfDisposed(),(0,Hs.k)(this,t,e,s,n,i,r)};var Ks=s(1137);(0,Ds.tp)().prototype.conv2dTranspose=function(t,e,s,n,i){return this.throwIfDisposed(),(0,Ks.w)(this,t,e,s,n,i)},(0,Ds.tp)().prototype.conv2d=function(t,e,s,n,i,r){return this.throwIfDisposed(),(0,ct.X)(this,t,e,s,n,i,r)},(0,Ds.tp)().prototype.cos=function(){return this.throwIfDisposed(),(0,Ye.g)(this)},(0,Ds.tp)().prototype.cosh=function(){return this.throwIfDisposed(),(0,Qe.y)(this)},(0,Ds.tp)().prototype.cumprod=function(t,e,s){return this.throwIfDisposed(),(0,Ee.L)(this,t,e,s)},(0,Ds.tp)().prototype.cumsum=function(t,e,s){return this.throwIfDisposed(),(0,kt.r)(this,t,e,s)};var Js=s(1719);(0,Ds.tp)().prototype.depthToSpace=function(t,e){return this.throwIfDisposed(),(0,Js.R)(this,t,e)};var Zs=s(9899);(0,Ds.tp)().prototype.depthwiseConv2d=function(t,e,s,n,i,r){return this.throwIfDisposed(),(0,Zs.G)(this,t,e,s,n,i,r)};var Ys=s(3789);(0,Ds.tp)().prototype.dilation2d=function(t,e,s,n,i){return this.throwIfDisposed(),(0,Ys.X)(this,t,e,s,n,i)};var Xs=s(44);(0,Ds.tp)().prototype.divNoNan=function(t){return this.throwIfDisposed(),(0,Xs.e)(this,t)},(0,Ds.tp)().prototype.div=function(t){return this.throwIfDisposed(),(0,m.y)(this,t)};var Qs=s(6434);(0,Ds.tp)().prototype.dot=function(t){return this.throwIfDisposed(),(0,Qs.O)(this,t)};var tn=s(3645);(0,Ds.tp)().prototype.elu=function(){return this.throwIfDisposed(),(0,tn.P)(this)},(0,Ds.tp)().prototype.equal=function(t){return this.throwIfDisposed(),(0,se.L)(this,t)};var en=s(8810);(0,Ds.tp)().prototype.erf=function(){return this.throwIfDisposed(),(0,en.Y)(this)};var sn=s(8826);(0,Ds.tp)().prototype.euclideanNorm=function(t,e){return this.throwIfDisposed(),(0,sn.p)(this,t,e)},(0,Ds.tp)().prototype.exp=function(){return this.throwIfDisposed(),(0,Tt.o)(this)},(0,Ds.tp)().prototype.expandDims=function(t){return this.throwIfDisposed(),(0,Ss.U)(this,t)};var nn=s(2520);(0,Ds.tp)().prototype.expm1=function(){return this.throwIfDisposed(),(0,nn.I)(this)};var rn=s(3062);(0,Ds.tp)().prototype.fft=function(){return this.throwIfDisposed(),(0,rn.h)(this)},(0,Ds.tp)().prototype.flatten=function(){return this.throwIfDisposed(),(0,z.t)(this,[this.size])},(0,Ds.tp)().prototype.floor=function(){return this.throwIfDisposed(),(0,ye.R)(this)};var an=s(3612);(0,Ds.tp)().prototype.floorDiv=function(t){return this.throwIfDisposed(),(0,an.w)(this,t)},(0,Ds.tp)().prototype.gather=function(t,e,s){return this.throwIfDisposed(),(0,xs.k)(this,t,e,s)},(0,Ds.tp)().prototype.greaterEqual=function(t){return this.throwIfDisposed(),(0,tt.D)(this,t)},(0,Ds.tp)().prototype.greater=function(t){return this.throwIfDisposed(),(0,Jt.r)(this,t)};var on=s(1405);(0,Ds.tp)().prototype.ifft=function(){return this.throwIfDisposed(),(0,on.K)(this)};var ln=s(7307);(0,Ds.tp)().prototype.irfft=function(){return this.throwIfDisposed(),(0,ln.g)(this)};var un=s(9027);(0,Ds.tp)().prototype.isFinite=function(){return this.throwIfDisposed(),(0,un.M)(this)};var hn=s(6005);(0,Ds.tp)().prototype.isInf=function(){return this.throwIfDisposed(),(0,hn.E)(this)};var cn=s(3467);(0,Ds.tp)().prototype.isNaN=function(){return this.throwIfDisposed(),(0,cn.y)(this)};var pn=s(8076);(0,Ds.tp)().prototype.leakyRelu=function(t){return this.throwIfDisposed(),(0,pn.H)(this,t)},(0,Ds.tp)().prototype.lessEqual=function(t){return this.throwIfDisposed(),(0,et.I)(this,t)},(0,Ds.tp)().prototype.less=function(t){return this.throwIfDisposed(),(0,re.M)(this,t)};var dn=s(6584);(0,Ds.tp)().prototype.localResponseNormalization=function(t,e,s,n){return this.throwIfDisposed(),(0,dn.K)(this,t,e,s,n)};var fn=s(4824);(0,Ds.tp)().prototype.logSigmoid=function(){return this.throwIfDisposed(),(0,fn.n)(this)};var gn=s(1194);(0,Ds.tp)().prototype.logSoftmax=function(t){return this.throwIfDisposed(),(0,gn.H)(this,t)};var mn=s(2175);(0,Ds.tp)().prototype.logSumExp=function(t,e){return this.throwIfDisposed(),(0,mn.V)(this,t,e)},(0,Ds.tp)().prototype.log=function(){return this.throwIfDisposed(),(0,Ce.R)(this)};var yn=s(1386);(0,Ds.tp)().prototype.log1p=function(){return this.throwIfDisposed(),(0,yn.K)(this)},(0,Ds.tp)().prototype.logicalAnd=function(t){return this.throwIfDisposed(),(0,st.n)(this,t)},(0,Ds.tp)().prototype.logicalNot=function(){return this.throwIfDisposed(),(0,qe.N)(this)};var wn=s(7920);(0,Ds.tp)().prototype.logicalOr=function(t){return this.throwIfDisposed(),(0,wn.z)(this,t)};var bn=s(3708);(0,Ds.tp)().prototype.logicalXor=function(t){return this.throwIfDisposed(),(0,bn.r)(this,t)},(0,Ds.tp)().prototype.matMul=function(t,e,s){return this.throwIfDisposed(),(0,H.N)(this,t,e,s)};var vn=s(6044);(0,Ds.tp)().prototype.maxPool=function(t,e,s,n){return this.throwIfDisposed(),(0,vn.j)(this,t,e,s,n)};var kn=s(891);(0,Ds.tp)().prototype.max=function(t,e){return this.throwIfDisposed(),(0,kn.T)(this,t,e)},(0,Ds.tp)().prototype.maximum=function(t){return this.throwIfDisposed(),(0,Ns.P)(this,t)};var Sn=s(3015);(0,Ds.tp)().prototype.mean=function(t,e){return this.throwIfDisposed(),(0,Sn.i)(this,t,e)};var xn=s(1465);(0,Ds.tp)().prototype.min=function(t,e){return this.throwIfDisposed(),(0,xn.j)(this,t,e)};var Nn=s(6561);(0,Ds.tp)().prototype.minimum=function(t){return this.throwIfDisposed(),(0,Nn.B)(this,t)};var zn=s(4252);(0,Ds.tp)().prototype.mirrorPad=function(t,e){return this.throwIfDisposed(),(0,zn.F)(this,t,e)};var An=s(3617);(0,Ds.tp)().prototype.mod=function(t){return this.throwIfDisposed(),(0,An.z)(this,t)},(0,Ds.tp)().prototype.mul=function(t){return this.throwIfDisposed(),(0,d.l)(this,t)},(0,Ds.tp)().prototype.neg=function(){return this.throwIfDisposed(),(0,y.H)(this)};var Cn=s(2155);(0,Ds.tp)().prototype.norm=function(t,e,s){return this.throwIfDisposed(),(0,Cn.x)(this,t,e,s)};var In=s(135);(0,Ds.tp)().prototype.notEqual=function(t){return this.throwIfDisposed(),(0,In.E)(this,t)};var Tn=s(6865);(0,Ds.tp)().prototype.oneHot=function(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1,s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0;return this.throwIfDisposed(),(0,Tn.M)(this,t,e,s)};var Dn=s(4100);(0,Ds.tp)().prototype.onesLike=function(){return this.throwIfDisposed(),(0,Dn.P)(this)},(0,Ds.tp)().prototype.pad=function(t,e){return this.throwIfDisposed(),(0,es.e)(this,t,e)};var En=s(7751);(0,Ds.tp)().prototype.pool=function(t,e,s,n,i,r){return this.throwIfDisposed(),(0,En.d)(this,t,e,s,n,i,r)},(0,Ds.tp)().prototype.pow=function(t){return this.throwIfDisposed(),(0,Ie.n)(this,t)};var Fn=s(9855);(0,Ds.tp)().prototype.prelu=function(t){return this.throwIfDisposed(),(0,Fn.N)(this,t)};var Ln=s(9556);(0,Ds.tp)().prototype.prod=function(t,e){return this.throwIfDisposed(),(0,Ln._)(this,t,e)};var Rn=s(6309);(0,Ds.tp)().prototype.reciprocal=function(){return this.throwIfDisposed(),(0,Rn.V)(this)};var $n=s(5251);(0,Ds.tp)().prototype.relu=function(){return this.throwIfDisposed(),(0,$n.V)(this)};var Mn=s(9721);(0,Ds.tp)().prototype.relu6=function(){return this.throwIfDisposed(),(0,Mn.j)(this)},(0,Ds.tp)().prototype.reshapeAs=function(t){return this.throwIfDisposed(),(0,z.t)(this,t.shape)},(0,Ds.tp)().prototype.reshape=function(t){return this.throwIfDisposed(),(0,z.t)(this,t)};var On=s(2214);(0,Ds.tp)().prototype.resizeBilinear=function(t,e,s){return this.throwIfDisposed(),(0,On.v)(this,t,e,s)};var _n=s(2823);(0,Ds.tp)().prototype.resizeNearestNeighbor=function(t,e,s){return this.throwIfDisposed(),(0,_n.b)(this,t,e,s)},(0,Ds.tp)().prototype.reverse=function(t){return this.throwIfDisposed(),(0,We.B)(this,t)};var Bn=s(9486);(0,Ds.tp)().prototype.rfft=function(){return this.throwIfDisposed(),(0,Bn.z)(this)};var Pn=s(6509);(0,Ds.tp)().prototype.round=function(){return this.throwIfDisposed(),(0,Pn.L)(this)},(0,Ds.tp)().prototype.rsqrt=function(){return this.throwIfDisposed(),(0,Mt.Z)(this)};var Wn=s(2022);(0,Ds.tp)().prototype.selu=function(){return this.throwIfDisposed(),(0,Wn.W)(this)};var Un=s(3117);(0,Ds.tp)().prototype.separableConv2d=function(t,e,s,n,i,r){return this.throwIfDisposed(),(0,Un.w)(this,t,e,s,n,i,r)},(0,Ds.tp)().prototype.sigmoid=function(){return this.throwIfDisposed(),(0,rs.r)(this)};var jn=s(5740);(0,Ds.tp)().prototype.sign=function(){return this.throwIfDisposed(),(0,jn._)(this)},(0,Ds.tp)().prototype.sin=function(){return this.throwIfDisposed(),(0,mt.F)(this)},(0,Ds.tp)().prototype.sinh=function(){return this.throwIfDisposed(),(0,wt.L)(this)},(0,Ds.tp)().prototype.slice=function(t,e){return this.throwIfDisposed(),(0,ge.d)(this,t,e)};var Vn=s(6719);(0,Ds.tp)().prototype.softmax=function(t){return this.throwIfDisposed(),(0,Vn.V)(this,t)};var qn=s(9973);(0,Ds.tp)().prototype.softplus=function(){return this.throwIfDisposed(),(0,qn.l)(this)},(0,Ds.tp)().prototype.spaceToBatchND=function(t,e){return this.throwIfDisposed(),(0,J.e)(this,t,e)},(0,Ds.tp)().prototype.split=function(t,e){return this.throwIfDisposed(),(0,at.l)(this,t,e)},(0,Ds.tp)().prototype.sqrt=function(){return this.throwIfDisposed(),(0,b.R)(this)},(0,Ds.tp)().prototype.square=function(){return this.throwIfDisposed(),(0,v.E)(this)};var Gn=s(208);(0,Ds.tp)().prototype.squaredDifference=function(t){return this.throwIfDisposed(),(0,Gn.P)(this,t)};var Hn=s(613);(0,Ds.tp)().prototype.squeeze=function(t){return this.throwIfDisposed(),(0,Hn.r)(this,t)},(0,Ds.tp)().prototype.stack=function(t,e){this.throwIfDisposed();const s=t instanceof Ds.qY?[this,t]:[this,...t];return(0,Bt.t)(s,e)},(0,Ds.tp)().prototype.step=function(t){return this.throwIfDisposed(),(0,f.P)(this,t)};var Kn=s(1231);(0,Ds.tp)().prototype.stridedSlice=function(t,e,s,n,i,r,a,o){return this.throwIfDisposed(),(0,Kn.Y)(this,t,e,s,n,i,r,a,o)},(0,Ds.tp)().prototype.sub=function(t){return this.throwIfDisposed(),(0,k.j)(this,t)},(0,Ds.tp)().prototype.sum=function(t,e){return this.throwIfDisposed(),(0,A.c)(this,t,e)};var Jn=s(4894);(0,Ds.tp)().prototype.tan=function(){return this.throwIfDisposed(),(0,Jn.M)(this)};var Zn=s(6532);(0,Ds.tp)().prototype.tanh=function(){return this.throwIfDisposed(),(0,Zn.y)(this)},(0,Ds.tp)().prototype.tile=function(t){return this.throwIfDisposed(),(0,Ot.V)(this,t)},(0,Ds.tp)().prototype.toBool=function(){return this.throwIfDisposed(),(0,p.w)(this,"bool")},(0,Ds.tp)().prototype.toFloat=function(){return this.throwIfDisposed(),(0,p.w)(this,"float32")},(0,Ds.tp)().prototype.toInt=function(){return this.throwIfDisposed(),(0,p.w)(this,"int32")};var Yn=s(2765);(0,Ds.tp)().prototype.topk=function(t,e){return this.throwIfDisposed(),(0,Yn.r)(this,t,e)},(0,Ds.tp)().prototype.transpose=function(t){return this.throwIfDisposed(),(0,St.m)(this,t)};var Xn=s(9694);(0,Ds.tp)().prototype.unique=function(t){return this.throwIfDisposed(),(0,Xn.A)(this,t)},(0,Ds.tp)().prototype.unsortedSegmentSum=function(t,e){return this.throwIfDisposed(),(0,Pt.z)(this,t,e)},(0,Ds.tp)().prototype.unstack=function(t){return this.throwIfDisposed(),(0,Ne.K)(this,t)},(0,Ds.tp)().prototype.where=function(t,e){return this.throwIfDisposed(),(0,nt._)(t,this,e)},(0,Ds.tp)().prototype.zerosLike=function(){return this.throwIfDisposed(),(0,T.P)(this)};class Qn extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Qn.prototype)}}class ti extends Error{constructor(t){super(t),Object.setPrototypeOf(this,ti.prototype)}}class ei extends Error{constructor(t){super(t),Object.setPrototypeOf(this,ei.prototype)}}class si extends Error{constructor(t){super(t),Object.setPrototypeOf(this,si.prototype)}}class ni extends Error{constructor(t){super(t),Object.setPrototypeOf(this,ni.prototype)}}Error;class ii{constructor(t){this.maxEntries=t||100,this.cache=new Map}get(t){let e;return this.cache.has(t)&&(e=this.cache.get(t),this.cache.delete(t),this.cache.set(t,e)),e}put(t,e){if(this.cache.has(t))this.cache.delete(t);else if(this.cache.size>=this.maxEntries){const t=this.cache.keys().next().value;this.cache.delete(t)}this.cache.set(t,e)}getMaxEntries(){return this.maxEntries}setMaxEntries(t){if(t<0)throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${t}.`);if(this.maxEntries>t)for(let e=0;e<this.maxEntries-t;e++){const t=this.cache.keys().next().value;this.cache.delete(t)}this.maxEntries=t}}function ri(t,e){if(Array.isArray(t)){let s=[];for(let n=0;n<e;n++)s=s.concat(t);return s}{const s=new Array(e);return s.fill(t),s}}function ai(t,e){if(!t)throw new ni(e)}function oi(t,e){let s=0;for(const n of t)n===e&&s++;return s}function li(t){return 1===t.length?t[0]:t}function ui(t){return Array.isArray(t)?t:[t]}function hi(t){const e=t.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==e[0]?e:"private"+e}function ci(t){return t.length<=1||-1===t.indexOf("_")?t:t.replace(/[_]+(\w|$)/g,((t,e)=>e.toUpperCase()))}let pi={};function di(t){if(null===t||void 0===t)return null;const e={};return e.className=t.getClassName(),e.config=t.getConfig(),e}function fi(t){if(null!=t&&"object"===typeof t)if(Array.isArray(t))t.forEach((t=>fi(t)));else{const e=Object.keys(t);for(const s of e){const e=t[s];null!=e&&"object"===typeof e&&(Array.isArray(e)||"ndarray"!==e.type||"number"!==typeof e.value?fi(e):t[s]=e.value)}}}function gi(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"object",i=arguments.length>4&&void 0!==arguments[4]&&arguments[4];if("string"===typeof t){const i=t;let r;if(i in s)r=s[i];else if(i in pi)r=pi[i];else if(r=e[i],null==r)throw new ei(`Unknown ${n}: ${t}. This may be due to one of the following reasons:\n1. The ${n} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${n} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return r}{const r=t;if(null==r.className||null==r.config)throw new ei(`${n}: Improper config format: ${JSON.stringify(r)}.\n'className' and 'config' must set.`);const a=r.className;let o,l;if(a in s?[o,l]=s[a]:a in pi?[o,l]=pi.className:a in e&&([o,l]=e[a]),null==o)throw new ei(`Unknown ${n}: ${a}. This may be due to one of the following reasons:\n1. The ${n} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${n} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=l){const t={};for(const s of Object.keys(pi))t[s]=pi[s];for(const i of Object.keys(s))t[i]=s[i];r.config.customObjects=t;const e=Object.assign({},pi);for(const i of Object.keys(s))pi[i]=s[i];fi(r.config);const n=l(o,r.config,s,i);return pi=Object.assign({},e),n}{const t=Object.assign({},pi);for(const n of Object.keys(s))pi[n]=s[n];const e=new o(r.config);return pi=Object.assign({},t),e}}}function mi(t,e){return-1*function(t,e){return t<e?-1:t>e?1:0}(t,e)}function yi(t){if(null==t)return t;const e=[];for(const s of t)-1===e.indexOf(s)&&e.push(s);return e}function wi(t){if(null==t)throw new ei(`Invalid value in obj: ${JSON.stringify(t)}`);for(const e in t)if(t.hasOwnProperty(e))return!1;return!0}function bi(t,e,s){if(null!=s&&t.indexOf(s)<0)throw new ei(`${s} is not a valid ${e}.  Valid values are ${t} or null/undefined.`)}function vi(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1/0;return ai(s>=0),ai(n>=s),Array.isArray(t)&&t.length>=s&&t.length<=n&&t.every((t=>typeof t===e))}function ki(t,e){Array.isArray(t)?(h.util.assert(t.length>0,(()=>`${e} is unexpectedly an empty array.`)),t.forEach(((t,s)=>ki(t,`element ${s+1} of ${e}`)))):h.util.assert(Number.isInteger(t)&&t>0,(()=>`Expected ${e} to be a positive integer, but got ${Si(t)}.`))}function Si(t){return null===t?"null":Array.isArray(t)?"["+t.map((t=>Si(t))).join(",")+"]":"string"===typeof t?`"${t}"`:`${t}`}function xi(t){return"relu"===t?"relu":"linear"===t?"linear":"elu"===t?"elu":null}let Ni=0;function zi(){return Ni++}const Ai={};function Ci(){let t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"";return t in Ai||(Ai[t]=0),Ai[t]+=1,t+Ai[t].toString()}const Ii=["channelsFirst","channelsLast"],Ti=["nearest","bilinear"],Di=["valid","same","causal"],Ei=["max","avg"],Fi=["sum","mul","concat","ave"],Li=new Map;function Ri(t){bi(Ii,"DataFormat",t)}function $i(t){bi(Di,"PaddingMode",t)}function Mi(t){bi(Ei,"PoolMode",t)}const Oi=[];function _i(t,e){Oi.push(t);try{const t=e();return Oi.pop(),t}catch(s){throw Oi.pop(),s}}function Bi(t){if(!Ui(t))throw new Error("Not a valid tensor name: '"+t+"'");return(0===Oi.length?"":Oi.join("/")+"/")+t}function Pi(t){if(!Ui(t))throw new Error("Not a valid tensor name: '"+t+"'");Li.has(t)||Li.set(t,0);const e=Li.get(t);if(Li.set(t,Li.get(t)+1),e>0){const s=`${t}_${e}`;return Li.set(s,1),s}return t}const Wi=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function Ui(t){return!!t.match(Wi)}function ji(t,e,s){null==e&&(e=0),null==s&&(s=t.length);let n=1;for(let i=e;i<s;++i)n*=t[i];return n}function Vi(t){if(0===t.length)return Number.NaN;let e=Number.POSITIVE_INFINITY;for(let s=0;s<t.length;s++){const n=t[s];n<e&&(e=n)}return e}function qi(t){if(0===t.length)return Number.NaN;let e=Number.NEGATIVE_INFINITY;for(let s=0;s<t.length;s++){const n=t[s];n>e&&(e=n)}return e}function Gi(t,e){if(e<t)throw new ei(`end (${e}) < begin (${t}) is forbidden.`);const s=[];for(let n=t;n<e;++n)s.push(n);return s}let Hi;function Ki(){return null==Hi&&(Hi=(0,h.backend)().epsilon()),Hi}function Ji(t,e){return h.cast(t,e)}function Zi(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-1;const s=t.shape.slice();return e<0&&(e=s.length+e+1),s.splice(e,0,1),h.reshape(t,s)}function Yi(t,e,s){return(0,h.tidy)((()=>{switch(t.rank){case 1:return h.slice1d(t,e,s);case 2:return h.slice2d(t,[e,0],[s,t.shape[1]]);case 3:return h.slice3d(t,[e,0,0],[s,t.shape[1],t.shape[2]]);case 4:return h.slice4d(t,[e,0,0,0],[s,t.shape[1],t.shape[2],t.shape[3]]);case 5:return h.slice(t,[e,0,0,0,0],[s,t.shape[1],t.shape[2],t.shape[3],t.shape[4]]);case 6:return h.slice(t,[e,0,0,0,0,0],[s,t.shape[1],t.shape[2],t.shape[3],t.shape[4],t.shape[5]]);default:throw new ei(`sliceAlongFirstAxis() received an unsupported tensor rank: ${t.rank}`)}}))}function Xi(t,e,s){return(0,h.tidy)((()=>{switch(t.rank){case 1:return h.slice1d(t,e,s);case 2:return h.slice2d(t,[0,e],[t.shape[0],s]);case 3:return h.slice3d(t,[0,0,e],[t.shape[0],t.shape[1],s]);case 4:return h.slice4d(t,[0,0,0,e],[t.shape[0],t.shape[1],t.shape[2],s]);default:throw new ei(`sliceAlongLastAxis() received an unsupported tensor rank: ${t.rank}`)}}))}function Qi(t,e,s,n){return(0,h.tidy)((()=>{switch(t.rank){case 1:return h.slice1d(t,e,s);case 2:switch(n){case 1:return Yi(t,e,s);case 2:return Xi(t,e,s);default:throw new ei(`The axis is not within the rank of the tensor ${n}`)}case 3:switch(n){case 1:return Yi(t,e,s);case 2:return h.slice3d(t,[0,e,0],[t.shape[0],s,t.shape[2]]);case 3:return Xi(t,e,s);default:throw new ei(`The axis is not within the rank of the tensor ${n}`)}case 4:switch(n){case 1:return Yi(t,e,s);case 2:return h.slice4d(t,[0,e,0,0],[t.shape[0],s,t.shape[2],t.shape[3]]);case 3:return h.slice4d(t,[0,0,e,0],[t.shape[0],t.shape[1],s,t.shape[3]]);case 4:return Xi(t,e,s);default:throw new ei(`The axis is not within the rank of the tensor ${n}`)}default:throw new ei(`sliceAlongLastAxis() received an unsupported tensor rank: ${t.rank}`)}}))}function tr(t){let e,s=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-1;return s<0&&(e=t[0].rank,s=0!==e?e:0),s===t[0].rank&&(s=-1),h.concat(t,s)}function er(t,e){switch(t.rank){case 1:return h.concat1d([t,e]);case 2:return h.concat2d([t,e],0);case 3:return h.concat3d([t,e],0);case 4:return h.concat4d([t,e],0);default:throw new ei(`concatAlongFirstAxis() received an unsupported tensor rank: ${t.rank}`)}}function sr(t,e){if(Array.isArray(e)||(e=[e]),t.rank!==e.length)throw new ei(`The length of input n (${e.length}) does not match the number of dimensions in input x (${t.rank})`);return h.tile(t,e)}function nr(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:1,n=arguments.length>3?arguments[3]:void 0,i=arguments.length>4?arguments[4]:void 0;return h.randomNormal(t,e,s,n,i)}function ir(t,e,s,n){if(t.rank<2||e.rank<2)throw new si(`dot requires both inputs to be rank >= 2 but got x shape = ${t.shape} and y shape = ${e.shape}`);if(e.rank>=3){if(t.shape.slice(-1)[0]!==e.shape.slice(-2)[0])throw new si(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${t.shape} and  y shape = ${e.shape}`)}if(2===t.rank&&2===e.rank){const i=!1,r=!1;return h.fused.matMul({a:t,b:e,transposeA:i,transposeB:r,bias:n?or(t.rank,n,"channelsLast"):null,activation:s})}{const i=t.shape.slice(),r=i.pop();t=h.reshape(t,[-1,r]);const a=e.shape.slice(),o=a.pop(),l=a.pop(),u=[...a,o],c=Array.from({length:e.rank},((t,s)=>0===s?e.rank-2:s<=e.rank-2?s-1:s));e=h.reshape(h.transpose(e,c),[l,-1]);const p=[...i,...u],d=!1,f=!1;return h.reshape(h.fused.matMul({a:t,b:e,transposeA:d,transposeB:f,bias:n?or(t.rank,n,"channelsLast"):null,activation:s}),p)}}function rr(t,e,s){return(0,h.tidy)((()=>(e=Array.isArray(e)?(0,h.tensor1d)(e,"int32"):h.cast(e,"int32"),h.gather(t,e,s))))}function ar(t){return h.mul(t,t)}function or(t,e,s){const n=e.shape;if(1!==e.rank&&e.rank!==t)throw new ei(`Unexpected bias dimensions: ${e.rank}; expected it to be 1 or ${t}`);if(5===t){if("channelsFirst"===s)return 1===n.length?h.reshape(e,[1,n[0],1,1,1]):h.reshape(e,[1,n[3],n[0],n[1],n[2]]);if("channelsLast"===s)return 1===n.length?h.reshape(e,[1,1,1,1,n[0]]):h.reshape(e,[1].concat(n))}else if(4===t){if("channelsFirst"===s)return 1===n.length?h.reshape(e,[1,n[0],1,1]):h.reshape(e,[1,n[2],n[0],n[1]]);if("channelsLast"===s)return 1===n.length?h.reshape(e,[1,1,1,n[0]]):h.reshape(e,[1].concat(n))}else if(3===t){if("channelsFirst"===s)return 1===n.length?h.reshape(e,[1,n[0],1]):h.reshape(e,[1,n[1],n[0]]);if("channelsLast"===s)return 1===n.length?h.reshape(e,[1,1,n[0]]):h.reshape(e,[1].concat(n))}else if(t<3)return e;throw new ei(`Unsupported input rank by biasAdd: ${e.rank}`)}function lr(t,e,s){return(0,h.tidy)((()=>(null==s&&(s="channelsLast"),Ri(s),h.add(t,or(t.rank,e,s)))))}function ur(t,e,s,n){return(0,h.tidy)((()=>h.dropout(t,e,s,n)))}function hr(t,e){return arguments.length>2&&void 0!==arguments[2]&&arguments[2]?t():e()}const cr=["fanIn","fanOut","fanAvg"],pr=["normal","uniform","truncatedNormal"];class dr extends h.serialization.Serializable{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class fr extends dr{apply(t,e){return(0,h.zeros)(t,e)}}fr.className="Zeros",h.serialization.registerClass(fr);class gr extends dr{apply(t,e){return(0,h.ones)(t,e)}}gr.className="Ones",h.serialization.registerClass(gr);class mr extends dr{constructor(t){if(super(),"object"!==typeof t)throw new ei(`Expected argument of type ConstantConfig but got ${t}`);if(void 0===t.value)throw new ei(`config must have value set but got ${t}`);this.value=t.value}apply(t,e){return(0,h.tidy)((()=>(0,h.mul)((0,h.scalar)(this.value),(0,h.ones)(t,e))))}getConfig(){return{value:this.value}}}mr.className="Constant",h.serialization.registerClass(mr);class yr extends dr{constructor(t){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=t.minval||this.DEFAULT_MINVAL,this.maxval=t.maxval||this.DEFAULT_MAXVAL,this.seed=t.seed}apply(t,e){return(0,h.randomUniform)(t,this.minval,this.maxval,e,this.seed)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}yr.className="RandomUniform",h.serialization.registerClass(yr);class wr extends dr{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new si(`randomNormal does not support dType ${e}.`);return nr(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}wr.className="RandomNormal",h.serialization.registerClass(wr);class br extends dr{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new si(`truncatedNormal does not support dType ${e}.`);return(0,h.truncatedNormal)(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}br.className="TruncatedNormal",h.serialization.registerClass(br);class vr extends dr{constructor(t){super(),this.gain=null!=t.gain?t.gain:1}apply(t,e){return(0,h.tidy)((()=>{if(2!==t.length||t[0]!==t[1])throw new ei("Identity matrix initializer can only be used for 2D square matrices.");return(0,h.mul)(this.gain,(0,h.eye)(t[0]))}))}getConfig(){return{gain:this.gain}}}vr.className="Identity",h.serialization.registerClass(vr);class kr extends dr{constructor(t){if(super(),t.scale<0)throw new ei(`scale must be a positive float. Got: ${t.scale}`);var e;this.scale=null==t.scale?1:t.scale,this.mode=null==t.mode?"fanIn":t.mode,e=this.mode,bi(cr,"FanMode",e),this.distribution=null==t.distribution?"normal":t.distribution,function(t){bi(pr,"Distribution",t)}(this.distribution),this.seed=t.seed}apply(t,e){const s=function(t){let e,s,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"channelsLast";if(Ri(n),2===t.length)e=t[0],s=t[1];else if(-1!==[3,4,5].indexOf(t.length)){if("channelsFirst"===n){const n=ji(t,2);e=t[1]*n,s=t[0]*n}else if("channelsLast"===n){const n=ji(t,0,t.length-2);e=t[t.length-2]*n,s=t[t.length-1]*n}}else{const n=ji(t);e=Math.sqrt(n),s=Math.sqrt(n)}return[e,s]}(t),n=s[0],i=s[1];let r=this.scale;if("fanIn"===this.mode?r/=Math.max(1,n):"fanOut"===this.mode?r/=Math.max(1,i):r/=Math.max(1,(n+i)/2),"normal"===this.distribution){const s=Math.sqrt(r);if("float32"!==(e=e||"float32")&&"int32"!==e)throw new si(`${this.getClassName()} does not support dType ${e}.`);return(0,h.truncatedNormal)(t,0,s,e,this.seed)}{const s=Math.sqrt(3*r);return(0,h.randomUniform)(t,-s,s,e,this.seed)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}kr.className="VarianceScaling",h.serialization.registerClass(kr);class Sr extends kr{constructor(t){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return kr.className}}Sr.className="GlorotUniform",h.serialization.registerClass(Sr);class xr extends kr{constructor(t){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return kr.className}}xr.className="GlorotNormal",h.serialization.registerClass(xr);class Nr extends kr{constructor(t){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return kr.className}}Nr.className="HeNormal",h.serialization.registerClass(Nr);class zr extends kr{constructor(t){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return kr.className}}zr.className="HeUniform",h.serialization.registerClass(zr);class Ar extends kr{constructor(t){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return kr.className}}Ar.className="LeCunNormal",h.serialization.registerClass(Ar);class Cr extends kr{constructor(t){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return kr.className}}Cr.className="LeCunUniform",h.serialization.registerClass(Cr);class Ir extends dr{constructor(t){super(),this.DEFAULT_GAIN=1,this.ELEMENTS_WARN_SLOW=2e3,this.gain=null==t.gain?this.DEFAULT_GAIN:t.gain,this.seed=t.seed}apply(t,e){return(0,h.tidy)((()=>{if(t.length<2)throw new si("Shape must be at least 2D.");if("int32"!==e&&"float32"!==e&&void 0!==e)throw new TypeError(`Unsupported data type ${e}.`);const s=h.util.sizeFromShape(t.slice(0,-1)),n=t[t.length-1],i=s*n;i>this.ELEMENTS_WARN_SLOW&&console.warn(`Orthogonal initializer is being called on a matrix with more than ${this.ELEMENTS_WARN_SLOW} (${i}) elements: Slowness may result.`);const r=nr([Math.max(n,s),Math.min(n,s)],0,1,e,this.seed),a=h.linalg.qr(r,!1);let o=a[0];const l=a[1].flatten().stridedSlice([0],[Math.min(n,s)*Math.min(n,s)],[Math.min(n,s)+1]);return o=(0,h.mul)(o,l.sign()),s<n&&(o=o.transpose()),(0,h.mul)((0,h.scalar)(this.gain),o.reshape(t))}))}getConfig(){return{gain:this.gain,seed:this.seed}}}Ir.className="Orthogonal",h.serialization.registerClass(Ir);const Tr={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function Dr(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return gi(t,h.serialization.SerializationMap.getMap().classNameMap,e,"initializer")}function Er(t){return di(t)}function Fr(t){if("string"===typeof t){const e=t in Tr?Tr[t]:t;if("GlorotNormal"===e)return new xr;if("GlorotUniform"===e)return new Sr;if("HeNormal"===e)return new Nr;if("HeUniform"===e)return new zr;if("LeCunNormal"===e)return new Ar;if("LeCunUniform"===e)return new Cr;{const t={};return t.className=e,t.config={},Dr(t)}}return t instanceof dr?t:Dr(t)}function Lr(t){return Array.isArray(t)&&Array.isArray(t[0])}function Rr(t){return 0===t.length?[]:Array.isArray(t[0])?t:[t]}function $r(t){let e;if(Array.isArray(t)){if(1!==t.length)throw new ei(`Expected Tensor length to be 1; got ${t.length}`);e=t[0]}else e=t;return e}function Mr(t){if(Array.isArray(t)&&Array.isArray(t[0])){if(1===t.length)return t[0];throw new ei(`Expected exactly 1 Shape; got ${t.length}`)}return t}function Or(t){let e=0;for(const s of t)0===s.shape.length?e+=1:e+=s.shape.reduce(((t,e)=>t*e));return e}const _r="Variable";class Br{constructor(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"float32",s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:_r,n=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:null;this.dtype=null==e?"float32":e,this.shape=t.shape,this.id=zi(),s=null==s?_r:s,this.originalName=Bi(s),this.name=Pi(this.originalName),this.trainable_=n,this.constraint=i,this.val=h.variable(t,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(t){return this.assertNotDisposed(),function(t,e){if(t.shape.toString()!==e.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(t.shape)+" vs. "+JSON.stringify(e.shape))}(this.val,t),this.val.id!==t.id&&(this.val.assign(t),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(t){this.trainable_=t,this.val.trainable=t}}function Pr(t){return t.map((t=>t.read()))}function Wr(t){t.forEach((t=>{t[0].write(t[1])}))}class Ur{constructor(t){this.dtype=t.dtype,this.shape=t.shape,null!=t.shape?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}class jr{constructor(t,e,s,n,i,r,a){this.dtype=t,this.shape=e,this.sourceLayer=s,this.inputs=n,this.callArgs=i,this.outputTensorIndex=a,this.id=zi(),null!=r&&(this.originalName=Bi(r),this.name=Pi(this.originalName)),this.rank=e.length}}let Vr=0;class qr{constructor(t,e){this.callArgs=e,this.id=Vr++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const s of t.inboundLayers)null!=s&&s.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)null!=e?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let Gr=0;class Hr extends h.serialization.Serializable{constructor(){let t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=Gr++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){const t=this.getClassName();e=hi(t)+"_"+Ci(t)}if(this.name=e,this.trainable_=null==t.trainable||t.trainable,null!=t.inputShape||null!=t.batchInputShape){let e;if(null!=t.batchInputShape)e=t.batchInputShape;else if(null!=t.inputShape){let s=null;null!=t.batchSize&&(s=t.batchSize),e=[s].concat(t.inputShape)}this.batchInputShape=e;let s=t.dtype;null==s&&(s=t.inputDType),null==s&&(s="float32"),this.dtype=s}null!=t.weights?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(0===this.inboundNodes.length)throw new ti(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new ei(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return li(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return li(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new Qn(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new Qn(`Layer ${this.name} is not connected, no input to return.`);return li(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new Qn(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new Qn(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return li(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map((t=>t()))}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach((e=>e.trainable=t)),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter((t=>t.trainable)):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter((t=>!t.trainable)).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){const e=ui(t);if(null==this.inputSpec||0===this.inputSpec.length)return;const s=ui(this.inputSpec);if(e.length!==s.length)throw new ei(`Layer ${this.name} expects ${s.length} inputs, but it received ${e.length} input tensors. Input received: ${t}`);for(let n=0;n<e.length;n++){const t=e[n],i=s[n];if(null==i)continue;const r=t.rank;if(null!=i.ndim&&r!==i.ndim)throw new ei(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${i.ndim}, found ndim=${r}`);if(null!=i.maxNDim&&r>i.maxNDim)throw new ei(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${i.maxNDim}, found ndim=${r}`);if(null!=i.minNDim&&r<i.minNDim)throw new ei(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${i.minNDim}, found ndim=${r}.`);if(null!=i.dtype&&t.dtype!==i.dtype)throw new ei(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${i.dtype}, found dtype=${t.dtype}.`);if(i.axes){const e=t.shape;for(const t in i.axes){const s=Number(t),r=i.axes[t],a=s>=0?e[s]:e[e.length+s];if(null!=r&&-1===[r,null].indexOf(a))throw new ei(`Input ${n} is incompatible with layer ${this.name}: expected axis ${s} of input shape to have value ${r} but got shape ${e}.`)}}if(null!=i.shape)for(let e=0;e<i.shape.length;++e){const s=i.shape[e],r=t.shape[e];if(null!=s&&null!=r&&s!==r)throw new ei(`Input ${n} is incompatible with layer ${this.name}: expected shape=${i.shape}, found shape=${t.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){null!=this._callHook&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const s=ui(t),n=function(t){let e=!0;for(const s of ui(t))if(!(s instanceof jr)){e=!1;break}return e}(t),i=function(t){let e=!0;for(const s of ui(t))if(s instanceof jr){e=!1;break}return e}(t);if(n===i)throw new ei("Arguments to apply() must be all SymbolicTensors or all Tensors");return _i(this.name,(()=>{if(!this.built){this.assertInputCompatibility(t);const e=[];for(const s of ui(t))e.push(s.shape);this.build(li(e)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&i&&(this._refCount=1)}if(this.assertInputCompatibility(t),i){let n=this.call(t,e);this.supportsMasking&&this.setMaskMetadata(t,n);const i=ui(n),r=[];for(let t of i)-1!==s.indexOf(t)&&(t=t.clone()),r.push(t);if(n=li(r),null!=this.activityRegularizer)throw new si("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return n}{const s=function(t){t=ui(t);const e=[];for(const s of t)e.push(s.shape);return li(e)}(t),n=this.computeOutputShape(s);let i;const r="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(t)?s[0]:s),i=null!=n&&n.length>0&&Array.isArray(n[0])?n.map(((s,n)=>new jr(r,s,this,ui(t),e,this.name,n))):new jr(r,n,this,ui(t),e,this.name),this.addInboundNode(t,i,null,null,s,n,e),this._refCount++,null!=this.activityRegularizer)throw new si("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return i}}))}warnOnIncompatibleInputShape(t){if(null!=this.batchInputShape)if(t.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let e=!1;this.batchInputShape.forEach(((s,n)=>{null!=s&&null!=t[n]&&t[n]!==s&&(e=!0)})),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new Qn(`The layer ${this.name} has never been called and thus has no defined output shape.`);const t=[];for(const e of this.inboundNodes){const s=JSON.stringify(e.outputShapes);-1===t.indexOf(s)&&t.push(s)}if(1===t.length){const t=this.inboundNodes[0].outputShapes;return Array.isArray(t)&&Array.isArray(t[0])&&1===t.length?t[0]:t}throw new Qn(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new ti(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return Or(this.weights)}build(t){this.built=!0}getWeights(){return Pr(arguments.length>0&&void 0!==arguments[0]&&arguments[0]?this.trainableWeights:this.weights)}setWeights(t){(0,h.tidy)((()=>{const e=this.weights;if(e.length!==t.length)throw new ei(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(0===e.length)return;const s=[],n=Pr(e);for(let i=0;i<n.length;++i){const r=n[i],a=e[i],o=t[i];if(!h.util.arraysEqual(r.shape,o.shape))throw new ei(`Layer weight shape ${r.shape} not compatible with provided weight shape ${o.shape}`);s.push([a,o])}Wr(s)}))}addWeight(t,e,s,n,i,r,a,o){if(-1!==this._addedWeightNames.indexOf(t))throw new ei(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),null==s&&(s="float32"),this.fastWeightInitDuringBuild&&(n=null!=o?o():Fr("zeros"));const l=n.apply(e,s),u=new Br(l,s,t,r,a);return l.dispose(),null!=i&&this.addLoss((()=>i.apply(u.read()))),null==r&&(r=!0),r?this._trainableWeights.push(u):this._nonTrainableWeights.push(u),u}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){null==t||Array.isArray(t)&&0===t.length||(t=ui(t),void 0!==this._losses&&null!==this._losses&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(null!=e){if(!Array.isArray(e))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);e.forEach((t=>{if(null!=t)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)}))}return null}return e}setMaskMetadata(t,e,s){if(!this.supportsMasking)return;const n=this.computeMask(t,s),i=ui(e),r=ui(n);if(i.length!==r.length)throw new Error(`${this.name} outputs ${i.length} tensors but ${i.length} masks for those tensors`);for(let a=0;a<i.length;a++)i[a].kerasMask=r[a]}addInboundNode(t,e,s,n,i,r){let a=arguments.length>6&&void 0!==arguments[6]?arguments[6]:null;const o=ui(t);e=ui(e),s=ui(s),n=ui(n),i=Rr(i),r=Rr(r);const l=[],u=[],h=[];for(const c of o)l.push(c.sourceLayer),u.push(c.nodeIndex),h.push(c.tensorIndex);new qr({outboundLayer:this,inboundLayers:l,nodeIndices:u,tensorIndices:h,inputTensors:o,outputTensors:e,inputMasks:s,outputMasks:n,inputShapes:i,outputShapes:r},a);for(let c=0;c<e.length;c++)e[c].sourceLayer=this,e[c].nodeIndex=this.inboundNodes.length-1,e[c].tensorIndex=c}getConfig(){const t={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(t.batchInputShape=this.batchInputShape),null!=this.dtype&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach((t=>t.dispose())),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return 0===--this._refCount&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}function Kr(t,e,s){if((null==e||null!=s&&s>0)&&(e=t.sourceLayer,s=t.nodeIndex),0===e.inboundNodes.length)return[t];{const t=e.inboundNodes[s];if(0===t.inboundLayers.length)return t.inputTensors;{const e=[];for(let s=0;s<t.inboundLayers.length;s++){const n=Kr(t.inputTensors[s],t.inboundLayers[s],t.nodeIndices[s]);for(const t of n)-1===e.indexOf(t)&&e.push(t)}return e}}}class Jr extends Hr{constructor(t){if(super({dtype:t.dtype,name:null!=t.name?t.name:Ci("input").toString()}),null==t.batchSize&&(t.batchSize=null),null==t.sparse&&(t.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=t.sparse,null!=t.inputShape&&null!=t.batchInputShape)throw new ei("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let e=t.batchInputShape;if(null==e){if(null==t.inputShape)throw new ei("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");e=[t.batchSize].concat(t.inputShape)}else if(null!=t.batchSize)throw new ei("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const s=t.dtype||"float32";this.batchInputShape=e,this.dtype=s,this.inputSpec=[{shape:e}];const n=new jr(this.dtype,this.batchInputShape,this,[],{},this.name);n.nodeIndex=0,n.tensorIndex=0,new qr({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[n],outputTensors:[n],inputMasks:[null],outputMasks:[null],inputShapes:[e],outputShapes:[e]})}apply(t,e){throw new ei(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}function Zr(t){if(null==t.batchShape&&null==t.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=t.batchShape&&null!=t.shape)throw new ei("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let e=t.batchShape;null!=t.shape&&null==e&&(e=[null].concat(t.shape));let s=t.dtype;null==s&&(s="float32");return new Jr({batchInputShape:e,name:t.name,dtype:s,sparse:t.sparse}).inboundNodes[0].outputTensors[0]}Jr.className="InputLayer",h.serialization.registerClass(Jr);class Yr{constructor(t){if(this.id2Value={},this.id2Mask={},this.name2Id={},t instanceof Yr)for(const e in t.id2Value)this.id2Value[e]=t.id2Value[e],e in t.id2Mask&&(this.id2Mask[e]=t.id2Mask[e]);else{if(null==t)return;for(const e of t)this.add(e.key,e.value)}}add(t,e,s){if(null!=this.id2Value[t.id])throw new ei(`Duplicate key: name=${t.name}, id=${t.id}`);return this.id2Value[t.id]=function(t,e){if(null==t.dtype||t.dtype===e.dtype)return e;try{return(0,h.cast)(e,t.dtype)}catch(s){throw new ei(`The dtype of the feed (${e.dtype}) can not be cast to the dtype of the key '${t.name}' (${t.dtype}).`)}}(t,e),this.name2Id[t.name]=t.id,null!=s&&(this.id2Mask[t.id]=s),this}addFeed(t){this.add(t.key,t.value)}hasKey(t){return null!=this.id2Value[t.id]}names(){return Object.keys(this.name2Id)}getValue(t){if(t instanceof jr){if(null==this.id2Value[t.id])throw new ei(`Nonexistent key: ${t.name}`);return this.id2Value[t.id]}{const e=this.name2Id[t];if(null==e)throw new ei(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Value[e]}}getMask(t){if(t instanceof jr){if(null==this.id2Value[t.id])throw new ei(`Nonexistent key: ${t.name}`);return this.id2Mask[t.id]}{const e=this.name2Id[t];if(null==e)throw new ei(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Mask[e]}}disposeMasks(){null!=this.id2Mask&&(0,h.dispose)(this.id2Mask)}}const Xr=new ii,Qr=new ii;function ta(t,e,s,n){const i=null!=s&&s.training,r=Array.isArray(t),a=r?t:[t],o=a.map((t=>t.name)),l=[],u=e.names();for(const h of o)-1!==u.indexOf(h)?l.push(e.getValue(h)):l.push(null);null!=n&&(n.maxNumTensors=-1/0,n.minNumTensors=1/0);const c=o.join(",")+"|"+e.names().sort().join(",");let p,d=Xr.get(c);if(null==d){const t=function(t,e){h.util.assert(null!=t&&t.length>0,(()=>"Expected at least one fetch, got none"));let s=[],n={};if(1===t.length){const i=sa(t[0],e);s=i.sorted,n=i.recipientMap}else{const i=new Set;for(const r of t){const{sorted:t,recipientMap:a}=sa(r,e);for(const e of t)i.has(e.name)||(s.push(e),i.add(e.name));for(const e in a)null==n[e]&&(n[e]=new Set),a[e].forEach((t=>n[e].add(t)))}}return{sorted:s,recipientCounts:ea(n)}}(a,e);d=t.sorted,p=t.recipientCounts,Xr.put(c,d),Qr.put(c,p)}p={},i||Object.assign(p,Qr.get(c));const f=new Yr(e);for(let g=0;g<d.length;++g){if(null!=n){const t=(0,h.memory)().numTensors;t>n.maxNumTensors&&(n.maxNumTensors=t),t<n.minNumTensors&&(n.minNumTensors=t)}const t=d[g],r=t.sourceLayer;if(r instanceof Jr)continue;const a=[],u=[],c=[];let m=!1;for(const s of t.inputs){const t=f.getValue(s),n=f.getMask(s);a.push(t),u.push(n),null!=n&&(m=!0),i||(p[s.name]--,0!==p[s.name]||e.hasKey(s)||-1!==o.indexOf(s.name)||t.isDisposed||!0===s.sourceLayer.stateful||c.push(t))}m&&((s=s||{}).mask=u[0]);const y=ui(r.apply(a,s));let w=null;r.supportsMasking&&(w=r.computeMask(a,u));const b=na(t),v=Array.isArray(b)?b:[b];for(let e=0;e<v.length;++e){f.hasKey(v[e])||f.add(v[e],y[e],Array.isArray(w)?w[0]:w);const t=o.indexOf(v[e].name);-1!==t&&(l[t]=y[e])}i||(0,h.dispose)(c)}return f.disposeMasks(),r?l:l[0]}function ea(t){const e={};for(const s in t)e[s]=t[s].size;return e}function sa(t,e){const s=new Set,n=[],i={};for(const o of e.names())s.add(o);const r=[],a=[];for(r.push(t);r.length>0;){const t=r[r.length-1];if(s.has(t.name)){r.pop();continue}const e=a[a.length-1]===r.length-1;if(0===t.inputs.length||e)r.pop(),n.push(t),s.add(t.name),e&&a.pop();else{a.push(r.length-1);for(const e of t.inputs)null==i[e.name]&&(i[e.name]=new Set),i[e.name].add(t.name),s.has(e.name)||r.push(e)}}return{sorted:n,recipientMap:i}}function na(t){let e;if(1===t.sourceLayer.inboundNodes.length)e=t.sourceLayer.output;else{let s=null;for(let e=0;e<t.sourceLayer.inboundNodes.length;++e)for(const n of t.sourceLayer.inboundNodes[e].outputTensors)if(n.id===t.id){s=e;break}e=t.sourceLayer.getOutputAt(s)}return e}function ia(t,e){return(0,h.tidy)((()=>h.sqrt(h.sum(h.mul(t,t),e,!0))))}(0,h.env)().registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES",(()=>100),(function(t){null!=Xr&&Xr.setMaxEntries(t),null!=Qr&&Qr.setMaxEntries(t)}));class ra extends h.serialization.Serializable{getConfig(){return{}}}class aa extends ra{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return(0,h.tidy)((()=>{const e=ia(t,this.axis),s=h.clipByValue(e,0,this.maxValue);return h.mul(t,h.div(s,h.add(Ki(),e)))}))}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}aa.className="MaxNorm",h.serialization.registerClass(aa);class oa extends ra{constructor(t){super(),this.defaultAxis=0,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return(0,h.tidy)((()=>h.div(t,h.add(Ki(),ia(t,this.axis)))))}getConfig(){return{axis:this.axis}}}oa.className="UnitNorm",h.serialization.registerClass(oa);class la extends ra{apply(t){return h.relu(t)}}la.className="NonNeg",h.serialization.registerClass(la);class ua extends ra{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=t.minValue?t.minValue:this.defaultMinValue,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.rate=null!=t.rate?t.rate:this.defaultRate,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return(0,h.tidy)((()=>{const e=ia(t,this.axis),s=h.add(h.mul(this.rate,h.clipByValue(e,this.minValue,this.maxValue)),h.mul(1-this.rate,e));return h.mul(t,h.div(s,h.add(Ki(),e)))}))}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}ua.className="MinMaxNorm",h.serialization.registerClass(ua);const ha={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function ca(t){return di(t)}function pa(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return gi(t,h.serialization.SerializationMap.getMap().classNameMap,e,"constraint")}function da(t){if(null==t)return null;if("string"===typeof t){return pa({className:t in ha?ha[t]:t,config:{}})}return t instanceof ra?t:pa(t)}function fa(t){return new aa(t)}function ga(t){return new oa(t)}function ma(){return new la}function ya(t){return new ua(t)}function wa(){return new fr}function ba(){return new gr}function va(t){return new mr(t)}function ka(t){return new yr(t)}function Sa(t){return new wr(t)}function xa(t){return new br(t)}function Na(t){return new vr(t)}function za(t){return new kr(t)}function Aa(t){return new Sr(t)}function Ca(t){return new xr(t)}function Ia(t){return new Nr(t)}function Ta(t){return new zr(t)}function Da(t){return new Ar(t)}function Ea(t){return new Cr(t)}function Fa(t){return new Ir(t)}async function La(t){if(null==t)return;const e=[],s=[],n=[];for(const i in t){const r=t[i];if("number"!==typeof r){const t=r;e.push(t.data()),s.push(i),n.push(t)}}if(e.length>0){const i=await Promise.all(e);for(let e=0;e<i.length;++e)t[s[e]]=i[e][0];(0,h.dispose)(n)}}function Ra(t){if(null!=t)for(const e in t){const s=t[e];"number"!==typeof s&&s.dispose()}}var $a;!function(t){t[t.SILENT=0]="SILENT",t[t.VERBOSE=1]="VERBOSE"}($a||($a={}));class Ma{constructor(){this.validationData=null}setParams(t){this.params=t}async onEpochBegin(t,e){}async onEpochEnd(t,e){}async onBatchBegin(t,e){}async onBatchEnd(t,e){}async onTrainBegin(t){}async onTrainEnd(t){}setModel(t){}}class Oa{constructor(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:10;null==t&&(t=[]),this.callbacks=t,this.queueLength=e}append(t){this.callbacks.push(t)}setParams(t){for(const e of this.callbacks)e.setParams(t)}setModel(t){for(const e of this.callbacks)e.setModel(t)}async onEpochBegin(t,e){null==e&&(e={});for(const s of this.callbacks)await s.onEpochBegin(t,e)}async onEpochEnd(t,e){null==e&&(e={});for(const s of this.callbacks)await s.onEpochEnd(t,e)}async onBatchBegin(t,e){null==e&&(e={});for(const s of this.callbacks)await s.onBatchBegin(t,e)}async onBatchEnd(t,e){null==e&&(e={});for(const s of this.callbacks)await s.onBatchEnd(t,e)}async onTrainBegin(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainBegin(t)}async onTrainEnd(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainEnd(t)}}class _a extends Ma{constructor(){super()}async onEpochBegin(t){this.seen=0,this.totals={}}async onBatchEnd(t,e){null==e&&(e={});const s=null==e.size?0:e.size;this.seen+=s;for(const n in e){const t=e[n];if("number"===typeof t)this.totals.hasOwnProperty(n)||(this.totals[n]=0),this.totals[n]=this.totals[n]+t*s;else{let e;n in this.totals?e=this.totals[n]:this.totals[n]=0;const i=(0,h.tidy)((()=>(0,h.add)(this.totals[n],(0,h.mul)(t,s))));this.totals[n]=i,null!=e&&e.dispose()}}}async onEpochEnd(t,e){if(null!=e)for(const s of this.params.metrics)null!=this.totals[s]&&("number"===typeof this.totals[s]?e[s]=this.totals[s]/this.seen:(0,h.tidy)((()=>{const t=(0,h.mul)((0,h.div)(1,this.seen),this.totals[s]);e[s]=t,this.totals[s].dispose(),(0,h.keep)(e[s])})))}}class Ba extends Ma{async onTrainBegin(t){this.epoch=[],this.history={}}async onEpochEnd(t,e){null==e&&(e={}),this.epoch.push(t);for(const s in e)null==this.history[s]&&(this.history[s]=[]),this.history[s].push(e[s])}async syncData(){const t=[],e=[],s=[];for(const i in this.history){const n=this.history[i];for(let r=0;r<n.length;++r)if("number"!==typeof n[r]){const a=n[r];t.push(a.data()),e.push(i),s.push(r)}}const n=await Promise.all(t);for(let i=0;i<n.length;++i){this.history[e[i]][s[i]].dispose(),this.history[e[i]][s[i]]=n[i][0]}}}class Pa extends Ma{constructor(t,e){if(super(),this.currentEpoch=0,this.nowFunc=t.nowFunc,this.nextFrameFunc=t.nextFrameFunc||h.nextFrame,this.yieldEvery=e||"auto","auto"===this.yieldEvery&&(this.yieldEvery=125),"never"===this.yieldEvery&&null!=t.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");h.util.isNumber(this.yieldEvery)&&(this.maybeWait=function(t,e,s){let n,i=null!=s?s():h.util.now();return function(){const r=null!=s?s():h.util.now();return r-i<e||(i=r,n=t(...arguments)),n}}(this.maybeWait.bind(this),this.yieldEvery,this.nowFunc)),this.trainBegin=t.onTrainBegin,this.trainEnd=t.onTrainEnd,this.epochBegin=t.onEpochBegin,this.epochEnd=t.onEpochEnd,this.batchBegin=t.onBatchBegin,this.batchEnd=t.onBatchEnd,this.yield=t.onYield}async maybeWait(t,e,s){const n=[];null!=this.yield&&(await La(s),n.push(this.yield(t,e,s))),n.push(this.nextFrameFunc()),await Promise.all(n)}async onEpochBegin(t,e){this.currentEpoch=t,null!=this.epochBegin&&(await La(e),await this.epochBegin(t,e))}async onEpochEnd(t,e){const s=[];null!=this.epochEnd&&(await La(e),s.push(this.epochEnd(t,e))),"epoch"===this.yieldEvery&&s.push(this.nextFrameFunc()),await Promise.all(s)}async onBatchBegin(t,e){null!=this.batchBegin&&(await La(e),await this.batchBegin(t,e))}async onBatchEnd(t,e){const s=[];null!=this.batchEnd&&(await La(e),s.push(this.batchEnd(t,e))),"batch"===this.yieldEvery?s.push(this.nextFrameFunc()):h.util.isNumber(this.yieldEvery)&&s.push(this.maybeWait(this.currentEpoch,t,e)),await Promise.all(s)}async onTrainBegin(t){null!=this.trainBegin&&(await La(t),await this.trainBegin(t))}async onTrainEnd(t){null!=this.trainEnd&&(await La(t),await this.trainEnd(t))}}function Wa(t,e){if(null==t&&(t={}),t instanceof Ma)return[t];if(Array.isArray(t)&&t[0]instanceof Ma)return t;return ui(t).map((t=>new Pa(t,e)))}class Ua{constructor(){}static registerCallbackConstructor(t,e){h.util.assert(t>=0&&Number.isInteger(t),(()=>`Verbosity level is expected to be an integer >= 0, but got ${t}`)),Ua.checkForDuplicate(e),null==Ua.constructors[t]&&(Ua.constructors[t]=[]),Ua.constructors[t].push(e)}static checkForDuplicate(t){for(const e in Ua.constructors){Ua.constructors[+e].forEach((e=>{if(e===t)throw new ei("Duplicate callback constructor.")}))}}static clear(){Ua.constructors={}}static createCallbacks(t){const e=[];for(const s in Ua.constructors){const n=+s;t>=n&&e.push(...Ua.constructors[n])}return e.map((t=>new t))}}function ja(t,e,s,n,i,r,a,o,l){const u=new Ba,h=[new _a,...Ua.createCallbacks(e)];null!=t&&h.push(...t),h.push(u);const c=new Oa(h);return c.setParams({epochs:s,initialEpoch:n,samples:i,steps:r,batchSize:a,verbose:e,doValidation:o,metrics:l}),{callbackList:c,history:u}}function Va(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},s=arguments.length>2&&void 0!==arguments[2]&&arguments[2];return gi(t,h.serialization.SerializationMap.getMap().classNameMap,e,"layer",s)}function qa(t,e){return(0,h.tidy)((()=>{"float32"!==t.dtype&&(t=h.cast(t,"float32"));const s=h.sum(ar(t),e,!0),n=h.fill(s.shape,Ki()),i=h.sqrt(h.maximum(s,n));return h.div(t,i)}))}function Ga(t,e){return(0,h.tidy)((()=>h.mean(ar(h.sub(e,t)),-1)))}function Ha(t,e){return(0,h.tidy)((()=>h.mean(h.abs(h.sub(e,t)),-1)))}function Ka(t,e){return(0,h.tidy)((()=>{const s=h.sub(t,e),n=h.clipByValue(h.abs(t),Ki(),Number.MAX_VALUE),i=h.abs(h.div(s,n));return h.mul(100,h.mean(i,-1))}))}function Ja(t,e){return(0,h.tidy)((()=>{const s=h.clipByValue(e,Ki(),Number.MAX_VALUE),n=h.log(h.add(1,s)),i=h.clipByValue(t,Ki(),Number.MAX_VALUE),r=h.log(h.add(1,i));return h.mean(ar(h.sub(n,r)),-1)}))}function Za(t,e){let s=arguments.length>2&&void 0!==arguments[2]&&arguments[2];return(0,h.tidy)((()=>{if(s)e=h.softmax(e);else{const t=h.sum(e,e.shape.length-1,!0);e=h.div(e,t)}return e=h.clipByValue(e,Ki(),1-Ki()),h.neg(h.sum(h.mul(h.cast(t,"float32"),h.log(e)),e.shape.length-1))}))}function Ya(t,e){let s=arguments.length>2&&void 0!==arguments[2]&&arguments[2];return(0,h.tidy)((()=>{const n=h.cast(h.floor(function(t){const e=[ji(t.shape)];return h.reshape(t,e)}(t)),"int32"),i=(e=h.clipByValue(e,Ki(),1-Ki())).shape;return Za(h.reshape(h.oneHot(n,i[i.length-1]),i),e,s)}))}function Xa(t,e){return(0,h.tidy)((()=>{let s;return s=h.clipByValue(e,Ki(),1-Ki()),s=h.log(h.div(s,h.sub(1,s))),h.mean(function(t,e){if(!h.util.arraysEqual(t.shape,e.shape))throw new ei(`logits and labels must have the same shape, but got shapes ${JSON.stringify(t.shape)} and ${JSON.stringify(e.shape)}`);return(0,h.tidy)((()=>{const s=h.relu(e),n=h.neg(h.abs(e));return h.add(h.sub(s,h.mul(e,t)),h.log1p(h.exp(n)))}))}(t,s),-1)}))}function Qa(t,e){return(0,h.tidy)((()=>{const s=h.clipByValue(t,Ki(),1),n=h.clipByValue(e,Ki(),1);return h.sum(h.mul(t,h.log(h.div(s,n))),-1)}))}function to(t,e){return(0,h.tidy)((()=>{const s=qa(t,-1),n=qa(e,-1),i=h.mul(s,n);return h.neg(h.sum(i,-1))}))}Ua.constructors={};const eo={meanSquaredError:Ga,meanAbsoluteError:Ha,meanAbsolutePercentageError:Ka,meanSquaredLogarithmicError:Ja,squaredHinge:function(t,e){return(0,h.tidy)((()=>{const s=h.maximum(0,h.sub(1,h.mul(t,e)));return h.mean(ar(s),-1)}))},hinge:function(t,e){return(0,h.tidy)((()=>{const s=h.maximum(0,h.sub(1,h.mul(t,e)));return h.mean(s,-1)}))},categoricalHinge:function(t,e){return(0,h.tidy)((()=>{const s=h.sum(h.mul(t,e),-1),n=h.max(h.mul(h.sub(1,t),e),-1);return h.maximum(0,h.add(1,h.sub(n,s)))}))},logcosh:function(t,e){return(0,h.tidy)((()=>{const s=Math.log(2),n=h.sub(e,t),i=h.sub(h.add(n,h.softplus(h.mul(-2,n))),s);return h.mean(i,-1)}))},categoricalCrossentropy:Za,sparseCategoricalCrossentropy:Ya,binaryCrossentropy:Xa,kullbackLeiblerDivergence:Qa,poisson:function(t,e){return(0,h.tidy)((()=>{const s=h.log(h.add(Ki(),e));return h.mean(h.sub(e,h.mul(t,s)),-1)}))},cosineProximity:to};function so(t){if("string"===typeof t){if(t in eo)return eo[t];let e=`Unknown loss ${t}`;throw t.toLowerCase().includes("softmaxcrossentropy")&&(e=`Unknown loss ${t}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new ei(e)}return t}function no(t,e){return(0,h.tidy)((()=>{const s=h.mul(.5,h.onesLike(e)),n=Ji(h.greater(e,s),t.dtype);return h.mean(h.equal(t,n),-1)}))}function io(t,e){return(0,h.tidy)((()=>Ji(h.equal(h.argMax(t,-1),h.argMax(e,-1)),"float32")))}function ro(t,e){return(0,h.tidy)((()=>h.cast(h.sum(h.logicalAnd(h.equal(t,1),h.equal(e,1))),"float32")))}function ao(t,e){return(0,h.tidy)((()=>{const s=ro(t,e),n=function(t,e){return(0,h.tidy)((()=>h.cast(h.sum(h.logicalAnd(h.equal(t,0),h.equal(e,1))),"float32")))}(t,e),i=h.add(s,n);return h.cast(h.where(h.greater(i,0),h.div(s,i),0),"float32")}))}function oo(t,e){return(0,h.tidy)((()=>{const s=ro(t,e),n=function(t,e){return(0,h.tidy)((()=>h.cast(h.sum(h.logicalAnd(h.equal(t,1),h.equal(e,0))),"float32")))}(t,e),i=h.add(s,n);return h.cast(h.where(h.greater(i,0),h.div(s,i),0),"float32")}))}function lo(t,e){return Xa(t,e)}function uo(t,e){return t.rank===e.rank&&(t=h.squeeze(t,[t.rank-1])),(e=h.argMax(e,-1)).dtype!==t.dtype&&(e=h.cast(e,t.dtype)),h.cast(h.equal(t,e),"float32")}const ho=Za,co=Ya,po={binaryAccuracy:no,categoricalAccuracy:io,precision:ao,categoricalCrossentropy:ho,sparseCategoricalCrossentropy:co,mse:Ga,MSE:Ga,mae:Ha,MAE:Ha,mape:Ka,MAPE:Ka,cosine:to};function fo(t){if("string"===typeof t&&t in po)return po[t];if("string"!==typeof t&&null!=t)return t;throw new ei(`Unknown metric ${t}`)}function go(t){if(ai(null!==t,`Unknown LossOrMetricFn ${t}`),"string"===typeof t)return t;{let e;for(const s of Object.keys(eo))if(eo[s]===t){e=s;break}if(void 0!==e)return e;for(const s of Object.keys(po))if(po[s]===t){e=s;break}return void 0!==e?e:t.name}}const mo=1048576;function yo(t,e){let s=arguments.length>2&&void 0!==arguments[2]&&arguments[2];if(null==t||"object"!==typeof t||Object.getPrototypeOf(t)!==Object.prototype||!wo(t))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(s){const s=JSON.stringify(t);s.length>mo&&console.warn(`User-defined metadata of model "${e}" is too large in size (length=${s.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)}}function wo(t){if(null===t)return!0;if("object"===typeof t){if(Object.getPrototypeOf(t)===Object.prototype){const e=Object.keys(t);for(const s of e){if("string"!==typeof s)return!1;if(!wo(t[s]))return!1}return!0}if(Array.isArray(t)){for(const e of t)if(!wo(e))return!1;return!0}return!1}{const e=typeof t;return"string"===e||"number"===e||"boolean"===e}}function bo(t,e,s){let n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:console.log;const i=function(t){let e=!0;const s=[],n=[];for(const i in t.nodesByDepth)s.push(t.nodesByDepth[i]);for(const i of s){if(i.length>1||1===i.length&&i[0].inboundLayers.length>1){e=!1;break}n.push(...i)}if(e)for(const i of t.layers){let t=!1;for(const s of i.inboundNodes)if(-1!==n.indexOf(s)){if(t){e=!1;break}t=!0}if(!e)break}return e}(t),r=["Layer (type)","Input Shape","Output shape","Param #"];let a;if(i?(e=e||90,s=s||[.32,.61,.89,1]):(e=e||115,s=s||[.24,.48,.7,.8,1]),s[s.length-1]<=1&&(s=s.map((t=>Math.floor(e*t)))),!i){r.push("Receives inputs"),a=[];for(const e in t.nodesByDepth)a.push(...t.nodesByDepth[e])}n("_".repeat(e)),vo(r,s,n),n("=".repeat(e));const o=t.layers;for(let h=0;h<o.length;++h)i?ko(o[h],s,n):So(o[h],s,a,n),n((h===o.length-1?"=":"_").repeat(e));t.checkTrainableWeightsConsistency();const l=function(t){let e;e=null!=t.collectedTrainableWeights?Or(t.collectedTrainableWeights):Or(t.trainableWeights);return e}(t),u=Or(t.nonTrainableWeights);n(`Total params: ${l+u}`),n(`Trainable params: ${l}`),n(`Non-trainable params: ${u}`),n("_".repeat(e))}function vo(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:console.log,n="";for(let i=0;i<t.length;++i)i>0&&(n=n.slice(0,n.length-1)+" "),n+=t[i],n=n.slice(0,e[i]),n+=" ".repeat(e[i]-n.length);s(n)}function ko(t,e,s){let n,i;try{i=t.inboundNodes.map((t=>JSON.stringify(t.inputShapes))).join(",")}catch(r){i="multiple"}try{n=JSON.stringify(t.outputShape)}catch(r){n="multiple"}vo([`${t.name} (${t.getClassName()})`,i,n,t.countParams().toString()],e,s)}function So(t,e,s,n){let i,r;try{r=t.inboundNodes.map((t=>JSON.stringify(t.inputShapes))).join(",")}catch(h){r="multiple"}try{i=JSON.stringify(t.outputShape)}catch(h){i="multiple"}const a=[];for(const c of t.inboundNodes)if(!(null!=s&&s.length>0&&-1===s.indexOf(c)))for(let t=0;t<c.inboundLayers.length;++t){const e=c.inboundLayers[t].name,s=c.nodeIndices[t],n=c.tensorIndices[t];a.push(`${e}[${s}][${n}]`)}const o=t.name,l=t.getClassName(),u=0===a.length?"":a[0];vo([`${o} (${l})`,r,i,t.countParams().toString(),u],e,n);for(let c=1;c<a.length;++c)vo(["","","","",a[c]],e,n)}function xo(t,e,s){return("inboundNodes"===t||"outputLayers"===t||"inputLayers"===t)&&0===e&&"string"===typeof s}function No(t,e){if(null===t)return null;if("string"===typeof t)return ci(t);if("number"===typeof t||"boolean"===typeof t)return t;if(t instanceof Array){const s=[],n=t.length;for(let i=0;i<n;++i){const n=t[i];xo(e,i,n)?s.push(n):s.push(No(n,e))}return s}{const e={};for(const s of Object.keys(t)){const n=t[s];if("name"===s&&"string"===typeof n)e[s]=n;else{const t=ci(s);e[t]=No(n,t)}}return e}}function zo(t,e){if(null===t||void 0===t)return null;if("string"===typeof t)return hi(t);if("number"===typeof t||"boolean"===typeof t)return t;if(t instanceof Array){const s=[],n=t.length;for(let i=0;i<n;++i){const n=t[i];xo(e,i,n)?s.push(n):s.push(zo(n,e))}return s}{const e={};for(const s of Object.keys(t)){const n=t[s],i=hi(s);e[i]="name"!==s&&"className"!==s||"string"!==typeof n?zo(n,s):n}return e}}const Ao="4.22.0";class Co extends Hr{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=Ci(t)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],yi(this.inputs).length!==this.inputs.length)throw new ei(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((t=>t.name))}`);yi(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((t=>t.name))}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const y of this.outputs){const t=y.sourceLayer,e=y.nodeIndex,s=y.tensorIndex;this.outputLayers.push(t),this.outputLayersNodeIndices.push(e),this.outputLayersTensorIndices.push(s)}for(const y of this.inputs){const t=y.sourceLayer,e=y.nodeIndex,s=y.tensorIndex;ai(0===e,"input layer has >1 nodes"),ai(0===s,"input layer has >1 tensors"),this.inputLayers.push(t),this.inputLayersNodeIndices.push(e),this.inputLayersTensorIndices.push(s)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let y=0;y<this.inputLayers.length;y++){const e=this.inputLayers[y];if(!(e instanceof Jr))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${y} (0-based) originates from layer type ${e.getClassName()}.`);this.inputNames.push(e.name),this.feedInputShapes.push(e.batchInputShape),this.feedInputNames.push(e.name)}for(const y of this.outputLayers)this.outputNames.push(y.name);this.internalInputShapes=this.inputs.map((t=>t.shape)),this.internalOutputShapes=this.outputs.map((t=>t.shape));const e={},s={},n={},i={},r={},a=[],o=(t,e,s,n,i,l)=>{null!=n&&null!=i&&null!=l||(n=t.sourceLayer,i=t.nodeIndex,l=t.tensorIndex);const u=n.inboundNodes[i];if(-1!==s.indexOf(u))throw new ti(`The tensor ${t.name} at layer "${n.name}" is part of a cycle.`);if(-1!==e.indexOf(u))return;this.containerNodes.add(Co.nodeKey(n,i)),n.id in r||(r[n.id]=Object.keys(r).length),-1===s.indexOf(u)&&s.push(u);const h=u.inboundLayers.length;for(let r=0;r<h;r++){const t=u.inputTensors[r],n=u.inboundLayers[r],i=u.nodeIndices[r],a=u.tensorIndices[r];o(t,e,s,n,i,a)}for(e.push(u);s.indexOf(u)>=0;)s.splice(s.indexOf(u),1);a.push(u)},l=[],u=[];for(const y of this.outputs)o(y,l,u);const h=a.slice().reverse();for(const y of h){s[y.id]=y,y.id in e||(e[y.id]=0);let t=e[y.id];const r=null==n[y.outboundLayer.id]?0:n[y.outboundLayer.id];t=Math.max(t,r),n[y.outboundLayer.id]=t,i[y.outboundLayer.id]=y.outboundLayer,e[y.id]=t;for(let n=0;n<y.inboundLayers.length;n++){const i=y.inboundLayers[n],r=y.nodeIndices[n],a=i.inboundNodes[r],o=null==e[a.id]?0:e[a.id];e[a.id]=Math.max(t+1,o),s[a.id]=a}}const c={};for(const y in e){const t=e[y];t in c||(c[t]=[]),c[t].push(s[y])}const p={};for(const y in n){const t=n[y];t in p||(p[t]=[]),p[t].push(i[y])}let d=Object.keys(p).map((t=>parseInt(t,10))).sort(mi);this.layers=[];for(const y of d){const t=p[y];t.sort(((t,e)=>{const s=r[t.id],n=r[e.id];return s<n?-1:s>n?1:0}));for(const e of t)e instanceof Co&&this.internalContainerRefs.push(e),this.layers.push(e)}this.layersByDepth=p,d=Object.keys(c).map((t=>parseInt(t,10))).sort(mi);const f=this.inputs.slice(),g=[];for(const y of d)for(const t of c[y]){const e=t.outboundLayer;if(null!=e){for(const s of t.inputTensors)if(-1===f.indexOf(s))throw new ti(`Graph disconnected: cannot obtain value for tensor ${s} at layer "${e.name}". The following previous layers were accessed without issue: ${g}`);for(const e of t.outputTensors)f.push(e);g.push(e.name)}}this.nodesByDepth=c;const m=this.layers.map((t=>t.name));for(const y of m){const t=m.filter((t=>t===y)).length;if(1!==t)throw new ti(`The name "${y}" is used ${t} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(m))}this.outboundNodes=[],this.inboundNodes=[],new qr({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map((t=>null)),outputMasks:this.outputs.map((t=>null)),inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs.map((t=>t.shape))}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0===--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach((e=>{e._trainableWeights.forEach((e=>e.trainable=t))})),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new ei("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t){let e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];const s={};let n=0;const i=(t=>{const e=Object.keys(t);if(0===e.length)return!1;const s=e[0].split("/");return!isNaN(parseInt(s[s.length-1],10))})(t);i&&this.parseWeights(t);for(const a of this.layers)for(const[t,e]of a.weights.entries()){const r=i?`${e.name.split("/").slice(0,-1).join("/")+"/"}${t}`:e.originalName;if(null!=s[r])throw new ei(`Duplicate weight name: ${r}`);s[r]=e,n++}const r=[];for(const a in t){let n=a;if(null==s[a]){const t=a.split("/");n=t.slice(0,-2).concat([t[t.length-1]]).join("/")}if(null!=s[n])r.push([s[n],t[a]]);else if(e)throw new ei(`Provided weight data has no target variable: ${a}`);delete s[n]}if(e){const t=[];for(const e in s)t.push(e);if(t.length>0)throw new ei(`${t.length} of ${n} weights are not set: ${t}`)}Wr(r)}parseWeights(t){for(const e in Object.keys(t)){const s=e.split("/"),n=["vars","layer_checkpoint_dependencies"],i=s.map((t=>t.startsWith("_")?t.slice(1):t)).filter((t=>!n.includes(t))).join("/");i!==e&&(t[i]=t[e],delete t[e])}}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion=`tfjs-layers ${Ao}`,e.backend="TensorFlow.js",e}toJSON(t){let e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];const s=zo(this.updatedConfig());return e?JSON.stringify(s):s}call(t,e){return(0,h.tidy)((()=>{t=ui(t);const s=new Yr;for(let e=0;e<this.inputs.length;++e)s.add(this.inputs[e],t[e]);return ta(this.outputs,s,e)}))}computeMask(t,e){return(0,h.tidy)((()=>{let s;return t=ui(t),s=null==e?ri(null,t.length):ui(e),this.runInternalGraph(t,s)[1]}))}computeOutputShape(t){const e=Rr(t);if(e.length!==this.inputLayers.length)throw new ei(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const s={};for(let a=0;a<e.length;a++){const t=this.inputLayers[a],n=e[a];s[t.name+"_0_0"]=n}const n=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(mi);if(n.length>1)for(const a of n){const t=this.nodesByDepth[a];for(const e of t){const t=e.outboundLayer;if(-1!==this.inputLayers.map((t=>t.id)).indexOf(t.id))continue;const n=[];for(let a=0;a<e.inboundLayers.length;a++){const t=e.inboundLayers[a],i=e.nodeIndices[a],r=e.tensorIndices[a],o=s[`${t.name}_${i}_${r}`];n.push(o)}const i=Rr(t.computeOutputShape(li(n))),r=t.inboundNodes.indexOf(e);for(let e=0;e<i.length;e++){s[`${t.name}_${r}_${e}`]=i[e]}}}const i=[],r=[];for(let a=0;a<this.outputLayers.length;a++){const t=this.outputLayers[a],e=this.outputLayersNodeIndices[a],s=this.outputLayersTensorIndices[a],n=`${t.name}_${e}_${s}`;r.push(n)}for(let a=0;a<r.length;a++){const t=r[a];ai(t in s),i.push(s[t])}return li(i)}runInternalGraph(t,e){null==e&&(e=ri(null,t.length));const s={};for(let o=0;o<this.inputs.length;++o){const n=this.inputs[o],i=t[o],r=e[o];s[n.id]=[i,r]}const n=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(mi);for(const o of n){const t=this.nodesByDepth[o];for(const e of t){const t=e.outboundLayer,n=e.inputTensors,i=e.outputTensors,r=new Array;for(const e of n)e.id in s&&r.push(s[e.id]);if(r.length===n.length){let n,a,o,l,u={};if(null!=e.callArgs&&(u=e.callArgs),1===r.length){const[e,s]=r[0];null==u.mask&&(u.mask=s),o=ui(t.call(e,u)),l=ui(t.computeMask(e,s)),n=[e],a=[s]}else n=r.map((t=>t[0])),a=r.map((t=>t[1])),null==u.mask&&(u.mask=a),o=ui(t.call(n,u)),l=ui(t.computeMask(n,a));if(t.activityRegularizer)throw new si("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let t=0;t<i.length;++t){const e=i[t],n=o[t],r=l[t];s[e.id]=[n,r]}}}}const i=[],r=[],a=[];for(const o of this.outputs){ai(o.id in s,`Could not compute output ${o.name} : ${o.id}`);const[t,e]=s[o.id];a.push(t.shape),i.push(t),r.push(e)}return[i,r,a]}buildNodeConversionMap(t){const e={};let s;for(const n of this.layers){s=n instanceof Co?1:0;for(let t=0;t<n.inboundNodes.length;t++){const i=Co.nodeKey(n,t);this.containerNodes.has(i)&&(e[i]=s,s+=1)}}return e}getLayer(t,e){if(null!=e)return this.findLayer(e);if(null==t)throw new ei("Provide either a layer name or layer index");if("number"===typeof t)return this.findLayer(t);for(const s of this.layers)if(s.name===t)return s;throw new ei(`No such layer: ${t}`)}findLayer(t){if(this.layers.length<=t)throw new ei(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);return this.layers[t]}calculateLosses(){return(0,h.tidy)((()=>{const t=[];for(const e of this.layers)for(let s=0;s<e.inboundNodes.length;++s){const n=Co.nodeKey(e,s);this.containerNodes.has(n)&&t.push(...e.calculateLosses())}return t}))}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),s=[];for(const a of this.layers){const t=a.getClassName(),n=a.getConfig(),i=[];for(let s=0;s<a.inboundNodes.length;s++){const t=a.inboundNodes[s],n=Co.nodeKey(a,s);let o={};if(this.containerNodes.has(n)){if(t.callArgs)try{JSON.stringify(t.callArgs),o=t.callArgs}catch(r){console.warn(`Layer ${a.name} was passed non-serializable keyword arguments: ${t.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),o={}}if(t.inboundLayers.length>0){const s=[];for(let n=0;n<t.inboundLayers.length;n++){const i=t.inboundLayers[n],r=t.nodeIndices[n],a=t.tensorIndices[n];let l=e[Co.nodeKey(i,r)];null==l&&(l=0),s.push([i.name,l,a,o])}i.push(s)}}}const o={};o.name=a.name,o.className=t,o.config=n,o.inboundNodes=i,s.push(o)}t.layers=s;const n=[];for(let a=0;a<this.inputLayers.length;a++){const t=this.inputLayers[a],s=this.inputLayersNodeIndices[a],i=Co.nodeKey(t,s);if(!this.containerNodes.has(i))continue;let r=e[i];null!==r&&void 0!==r||(r=0);const o=this.inputLayersTensorIndices[a];n.push([t.name,r,o])}t.inputLayers=n;const i=[];for(let a=0;a<this.outputLayers.length;a++){const t=this.outputLayers[a],s=this.outputLayersNodeIndices[a],n=Co.nodeKey(t,s);if(!this.containerNodes.has(n))continue;let r=e[n];null!==r&&void 0!==r||(r=0);const o=this.outputLayersTensorIndices[a];i.push([t.name,r,o])}return t.outputLayers=i,t}static fromConfig(t,e){let s=arguments.length>3&&void 0!==arguments[3]&&arguments[3];const n={},i={};function r(t,e){t.name in i?i[t.name].push(e):i[t.name]=[e]}function a(t,e){const s=[];let i;for(const a of e){const o=a[0],l=a[1],u=a[2];if(i=null==a[3]?{}:a[3],!(o in n))return void r(t,e);const h=n[o];if(h.inboundNodes.length<=l)return void r(t,e);const c=h.inboundNodes[l];s.push(c.outputTensors[u])}s.length>0&&t.apply(li(s),i)}function o(t){const i=t.name,a=Va(t,null!=e.customObjects?e.customObjects:{});a.setFastWeightInitDuringBuild(s),n[i]=a;t.inboundNodes.forEach((t=>{if(!(t instanceof Array))throw new ei(`Corrupted configuration, expected array for nodeData: ${t}`);r(a,t)}))}const l=e.name,u=e.layers;for(const f of u)o(f);for(;!wi(i);)for(const t of u){const e=n[t.name];if(e.name in i){const t=i[e.name];delete i[e.name];for(const s of t)a(e,s)}}const h=[],c=[],p=e.inputLayers;for(const f of p){const t=f[0],e=f[1],s=f[2];ai(t in n);const i=n[t].inboundNodes[e].outputTensors;h.push(i[s])}const d=e.outputLayers;for(const f of d){const t=f[0],e=f[1],s=f[2];ai(t in n);const i=n[t].inboundNodes[e].outputTensors;c.push(i[s])}return new t({inputs:h,outputs:c,name:l})}get stateful(){if(this._stateful)throw new ei("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){(0,h.tidy)((()=>{this.layers.forEach((t=>{t.stateful&&t.resetStates()}))}))}}function Io(t,e,s){const n=e.length;if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>null));if(1===n)return Array.isArray(t)&&1===t.length?t:"object"===typeof t&&e[0]in t?[t[e[0]]]:[t];if(Array.isArray(t)){if(t.length!==n)throw new Error(`Provided ${s} is an array of ${t.length} element(s), but the model has ${n} outputs. Make sure a set of weights is provided for each model output.`);return t}if("object"===typeof t&&Object.keys(t).length>0&&"object"===typeof t[Object.keys(t)[0]]){const s=[];return e.forEach((e=>{e in t?s.push(t[e]):s.push(null)})),s}throw new Error(`The model has multiple (${n}) outputs, so ${s} must be either an array with ${n} elements or an object with ${e} keys. Provided ${s} not understood: ${JSON.stringify(t)}`)}function To(t,e){return Io(t,e,"classWeight")}async function Do(t,e,s,n){if(null!=e||null!=n)throw new Error("Support sampleWeight is not implemented yet");if(null!=s){const e=(0,h.tidy)((()=>{if(1===t.shape.length)return(0,h.clone)(t);if(2===t.shape.length){if(t.shape[1]>1){const e=1;return(0,h.argMax)(t,e)}if(1===t.shape[1])return(0,h.reshape)(t,[t.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${t.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${t.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)})),n=Array.from(await e.data());(0,h.dispose)(e);const i=[];return n.forEach((t=>{if(null==s[t])throw new Error(`classWeight must contain all classes in the training data. The class ${t} exists in the data but not in classWeight`);i.push(s[t])})),(0,h.tensor1d)(i,"float32")}return null}function Eo(t,e){return(0,h.mul)(t,e)}function Fo(t,e){let s,n;const i=e;s=i.xs,n=i.ys,h.util.assert(null!=s&&null!=n,(()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${e}`));const r=Lo("input",t.inputNames,s),a=Lo("output",t.outputNames,n),o=r[0].shape[0];h.util.assert(r.length===t.inputs.length,(()=>`LayersModel has ${t.inputs.length} inputs, but the dataset provides ${r.length} inputs.  (Expected input keys: ${JSON.stringify(t.inputNames)})`)),h.util.assert(a.length===t.outputs.length,(()=>`LayersModel has ${t.outputs.length} outputs, but the dataset provides ${a.length} outputs.  (Expected output keys: ${JSON.stringify(t.outputNames)})`));for(let l=0;l<r.length;l++)h.util.assert(r[l].shape[0]===o,(()=>`Batch size mismatch: input ${t.inputNames[l]} has ${r[l].shape[0]}; expected  ${o} based on input ${t.inputNames[0]}.`));for(let l=0;l<a.length;l++)h.util.assert(a[l].shape[0]===o,(()=>`Batch size mismatch: output ${t.outputNames[l]} has ${a[l].shape[0]}; expected  ${o} based on input ${t.inputNames[0]}.`));return{xs:r,ys:a}}function Lo(t,e,s){if(s instanceof h.Tensor)return[s];if(Array.isArray(s))return h.util.assert(s.length===e.length,(()=>`Received an array of ${s.length} Tensors, but expected ${e.length} to match the ${t} keys ${e}.`)),s;{const n=[];for(const i of e){if(null==s[i])throw new ei(`The feature data generated by the dataset lacks the required ${t} key '${i}'.`);n.push(s[i])}return n}}async function Ro(t,e,s){const n=null!=s.batchesPerEpoch;if(h.util.assert(null!=t.optimizer,(()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).")),h.util.assert(null!=s,(()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.")),h.util.assert(null!=s.epochs&&s.epochs>0&&Number.isInteger(s.epochs),(()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${s.epochs}`)),h.util.assert(!n||s.batchesPerEpoch>0&&Number.isInteger(s.batchesPerEpoch),(()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${s.batchesPerEpoch}`)),h.util.assert(null==s.validationSplit,(()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.")),t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");t.isTraining=!0;try{const i=null!=s.validationData;let r,a;if(i)if($o(s.validationData))h.util.assert(null==s.validationBatches||s.validationBatches>0&&Number.isInteger(s.validationBatches),(()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${s.validationBatches}`));else{const t=function(t){if(3===t.length)throw new si("Validation with sample weights is not implemented yet.");return{xs:t[0],ys:t[1]}}(s.validationData);r=t.xs,a=t.ys}const o=t.makeTrainFunction(),l=t.getDedupedMetricsNames();let u;u=i?l.slice().concat(l.map((t=>"val_"+t))):l.slice();const c=Wa(s.callbacks,s.yieldEvery),p=null==s.verbose?1:s.verbose,{callbackList:d,history:f}=ja(c,p,s.epochs,null,null,function(t,e){let s=null;null!=e.batchesPerEpoch?s=e.batchesPerEpoch:Number.isFinite(t.size)&&(s=t.size);return s}(e,s),null,i,u);d.setModel(t),t.history=f,await d.onTrainBegin(),t.stopTraining_=!1;let g=null==s.initialEpoch?0:s.initialEpoch,m=await e.iterator();for(;g<s.epochs;){const u={};await d.onEpochBegin(g);let c=0,p=0;for(n||(m=await e.iterator());!n||c<s.batchesPerEpoch;){const e=await m.next();if(n&&e.done){console.warn(`You provided \`batchesPerEpoch\` as ${s.batchesPerEpoch}, but your dataset iterator ran out of data after ${c} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, `+s.batchesPerEpoch*s.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=e.value){const{xs:n,ys:i}=Fo(t,e.value),r={};r.batch=p,r.size=n[0].shape[0],await d.onBatchBegin(p,r);const a=[];if(null!=s.classWeight){const e=To(s.classWeight,t.outputNames);for(let t=0;t<e.length;++t)a.push(await Do(i[t],null,e[t]))}const u=n.concat(i).concat(a),f=o(u);h.dispose(u);for(let t=0;t<l.length;++t){const e=l[t],s=f[t];r[e]=s,h.keep(s)}await d.onBatchEnd(p,r),Ra(r),p++,c++}if(n?c>=s.batchesPerEpoch:e.done){if(i){let e;e=$o(s.validationData)?ui(await t.evaluateDataset(s.validationData,{batches:s.validationBatches})):ui(t.evaluate(r,a,{batchSize:null==s.validationBatchSize?32:s.validationBatchSize,verbose:0}));for(let s=0;s<t.metricsNames.length;++s)u[`val_${t.metricsNames[s]}`]=e[s]}break}if(t.stopTraining_)break}if(await d.onEpochEnd(g,u),g++,t.stopTraining_)break}return await d.onTrainEnd(),await t.history.syncData(),t.history}finally{t.isTraining=!1}}function $o(t){return"function"===typeof t.iterator}function Mo(t){h.util.assert(t>0&&Number.isInteger(t),(()=>`batchSize is required to be a positive integer, but got ${t}`))}function Oo(t,e,s){return null==t?[null]:Array.isArray(t)?t.map((t=>Yi(t,e,s-e))):Yi(t,e,s-e)}function _o(t,e){return h.tidy((()=>null==t?null:Array.isArray(t)?t.map((t=>_o(t,e))):rr(t,"int32"===e.dtype?e:h.cast(e,"int32"))))}function Bo(t,e){const s=[];let n=0,i=null;for(;n<t;)i=n+e,i>=t&&(i=t),s.push([n,i]),n=i;return s}function Po(t){const e=[];t instanceof h.Tensor&&(t=[t]);for(let s=0;s<t.length;++s){const n=t[s];if(1===n.rank)e.push(Zi(n,1));else{if(0===n.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");e.push(n)}}return e}function Wo(t,e){if(null==t)return;const s=[];if(e instanceof h.Tensor)s.push(e.id);else if(Array.isArray(e))e.forEach((t=>s.push(t.id)));else if(null!=e)for(const i in e){const t=e[i];s.push(t.id)}const n=[];if(t instanceof h.Tensor)-1===s.indexOf(t.id)&&n.push(t);else if(Array.isArray(t))t.forEach((t=>{-1===s.indexOf(t.id)&&n.push(t)}));else if(null!=t)for(const i in t){const e=t[i];-1===s.indexOf(e.id)&&n.push(e)}n.forEach((t=>{t.isDisposed||t.dispose()}))}function Uo(t){return Array.isArray(t)}function jo(t){return!function(t){return t instanceof h.Tensor}(t)&&!Uo(t)}function Vo(t,e,s){let n,i=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r=arguments.length>4&&void 0!==arguments[4]?arguments[4]:"";if(null==e||0===e.length){if(null!=t){let e=!1;if(Uo(t)&&t.length>0)e=!0;else if(jo(t)){for(const s in t)if(t.hasOwnProperty(s)){e=!0;break}}else e=!0;if(e)throw new ei(`Error when checking model ${r} expected no data, but got ${t}`)}return[]}if(null==t)return e.map((t=>null));if(jo(t)){n=[];for(const s of e){if(null==t[s])throw new ei(`No data provided for "${s}". Need data for each key in: ${e}`);n.push(t[s])}}else if(Uo(t)){if(t.length!==e.length)throw new ei(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${e.length} Tensor(s), but instead got the following list of Tensor(s): ${t}`);n=t}else{if(e.length>1)throw new ei(`The model ${r} expects ${e.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${t.shape}`);n=[t]}if(n=Po(n),null!=s)for(let a=0;a<e.length;++a){if(null==s[a])continue;const t=n[a];if(t.shape.length!==s[a].length)throw new ei(`Error when checking ${r}: expected ${e[a]} to have ${s[a].length} dimension(s). but got array with shape ${t.shape}`);for(let e=0;e<s[a].length;++e){if(0===e&&!i)continue;const n=t.shape[e],o=s[a][e];if(null!=o&&o>=0&&n!==o)throw new ei(`${r} expected a batch of elements where each example has shape [${s[a].slice(1,s[a].length)}] (i.e.,tensor shape [*,${s[a].slice(1,s[a].length)}]) but the ${r} received an input with ${t.shape[0]} examples, each with shape [${t.shape.slice(1,t.shape.length)}] (tensor shape [${t.shape}])`)}}return n}function qo(t,e,s){let n,i=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r=arguments.length>4&&void 0!==arguments[4]?arguments[4]:"";if(Array.isArray(t)){if(t.length!==e.length)throw new ei(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${e.length} Tensor(s), but instead got ${t.length} Tensors(s).`);n=t}else{if(e.length>1)throw new ei(`The model expects ${e.length} ${r} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(t.shape)}.`);n=[t]}if(null!=s)for(let a=0;a<e.length;++a){if(null==s[a])continue;const t=n[a];if(t.shape.length!==s[a].length)throw new ei(`Error when checking ${r}: expected ${e[a]} to have ${s[a].length} dimension(s), but got array with shape ${JSON.stringify(t.shape)}`);for(let n=0;n<s[a].length;++n){if(0===n&&!i)continue;const o=t.shape[n],l=s[a][n];if(null!=l&&l!==o)throw new ei(`Error when checking ${r}: expected ${e[a]} to have shape ${JSON.stringify(s[a])} but got array with shape ${JSON.stringify(t.shape)}.`)}}}class Go extends Co{constructor(t){super(t),this.isTraining=!1}summary(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:console.log;if(!this.built)throw new ei("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");bo(this,t,e,s)}compile(t){if(null==t.loss&&(t.loss=[]),this.loss=t.loss,"string"===typeof t.optimizer)this.optimizer_=function(t){const e={Adagrad:()=>h.train.adagrad(.01),Adadelta:()=>h.train.adadelta(1,.95,Ki()),Adam:()=>h.train.adam(.001,.9,.999,Ki()),Adamax:()=>h.train.adamax(.002,.9,.999,Ki(),0),RMSProp:()=>h.train.rmsprop(.001,.9,0,Ki()),SGD:()=>h.train.sgd(.01)};if(e.adagrad=e.Adagrad,e.adadelta=e.Adadelta,e.adam=e.Adam,e.adamax=e.Adamax,e.rmsprop=e.RMSProp,e.sgd=e.SGD,t in e)return e[t]();throw new ei(`Unknown Optimizer ${t}`)}(t.optimizer),this.isOptimizerOwned=!0;else{if(!(t.optimizer instanceof h.Optimizer))throw new ei("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=t.optimizer,this.isOptimizerOwned=!1}let e=[];if(Array.isArray(t.loss)||"string"===typeof t.loss||"function"===typeof t.loss)if(Array.isArray(t.loss)){if(t.loss.length!==this.outputs.length)throw new ei(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);const s=t.loss;e=s.map((t=>so(t)))}else{const s=so(t.loss);this.outputs.forEach((t=>{e.push(s)}))}else{t.loss=t.loss;for(const e in t.loss)if(-1===this.outputNames.indexOf(e))throw new ei(`Unknown entry in loss dictionary: "${e}". Only expected the following keys: ${this.outputNames}`);for(const s of this.outputNames)null==t.loss[s]&&console.warn(`Output "${s}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${s} during training`),e.push(so(t.loss[s]))}this.lossFunctions=e,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let r=0;r<this.outputs.length;++r){const t=this.internalOutputShapes[r],e=this.outputNames[r];this.feedOutputNames.push(e),this.feedOutputShapes.push(t),this.feedLossFns.push(this.lossFunctions[r])}const s=[];this.metrics=t.metrics,this.metricsNames=["loss"],this.metricsTensors=[],_i("loss",(()=>{for(let t=0;t<this.outputs.length;++t){if(-1!==s.indexOf(t))continue;const e=this.lossFunctions[t];this.outputs.length>1&&(this.metricsTensors.push([e,t]),this.metricsNames.push(this.outputNames[t]+"_loss"))}}));const n=function(t,e){if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>[]));let s;if("string"===typeof t||"function"===typeof t)s=[t];else{if(!Array.isArray(t)&&"object"!==typeof t)throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${t}`);s=t}if(Array.isArray(s))return e.map((t=>s));{const t=[];for(const n of e){let e=s.hasOwnProperty(n)?s[n]:[];Array.isArray(e)||(e=[e]),t.push(e)}return t}}(t.metrics,this.outputNames),i=(t,e,s)=>{this.outputNames.length>1&&(e=this.outputNames[t]+"_"+e),this.metricsNames.push(e),this.metricsTensors.push([s,t])};_i("metric",(()=>{for(let t=0;t<this.outputs.length;++t){if(-1!==s.indexOf(t))continue;(e=>{let s,n,r;for(const a of e){if("string"===typeof a&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(a)){const e=this.internalOutputShapes[t];let i;1===e[e.length-1]||this.lossFunctions[t]===Xa?-1!==["accuracy","acc"].indexOf(a)?n=no:-1!==["crossentropy","ce"].indexOf(a)&&(n=lo):this.lossFunctions[t]===Ya?-1!==["accuracy","acc"].indexOf(a)?n=uo:-1!==["crossentropy","ce"].indexOf(a)&&(n=co):-1!==["accuracy","acc"].indexOf(a)?n=io:-1!==["crossentropy","ce"].indexOf(a)&&(n=ho),-1!==["accuracy","acc"].indexOf(a)?i="acc":-1!==["crossentropy","ce"].indexOf(a)&&(i="ce"),r=n,s=""+i}else{const t=fo(a);r=t,s=""+go(a)}let e;_i(s,(()=>{e=r})),i(t,s,e)}})(n[t])}})),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};const n=null==s.batchSize?32:s.batchSize;Mo(n);const i=this.standardizeUserDataXY(t,e,!0,n);try{const t=i[0].concat(i[1]);this.makeTestFunction();const e=this.testFunction;return li(this.testLoop(e,t,n,s.verbose,s.steps))}finally{Wo(i[0],t),Wo(i[1],e)}}async evaluateDataset(t,e){return this.makeTestFunction(),async function(t,e,s){const n=null!=(s=s||{}).batches,i=t.testFunction;let r=[];if(s.verbose>0)throw new si("Verbose mode is not implemented yet.");h.util.assert(!n||s.batches>0&&Number.isInteger(s.batches),(()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(s.batches)}`));const a="function"===typeof e.next?e:await e.iterator();let o=0,l=0;for(;!n||l<s.batches;){const e=await a.next();if(r=h.tidy((()=>{if(e.value){const{xs:s,ys:n}=Fo(t,e.value),a=s.concat(n),u=h.tidy((()=>i(a)));if(h.dispose(a),0===l)for(let t=0;t<u.length;++t)r.push((0,h.scalar)(0));const c=a[0].shape[0];for(let t=0;t<u.length;++t){const e=u[t],s=r[t];r[t]=h.tidy((()=>h.add(r[t],h.mul(c,e)))),l>0&&h.dispose(s)}h.dispose(u),o+=c,++l}return r})),e.done){n&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${s.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let u=0;u<r.length;++u){const t=r[u];r[u]=h.div(r[u],o),h.dispose(t)}return li(r)}(this,t,e)}checkNumSamples(t,e,s){let n,i=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"steps";if(null!=s){if(n=null,null!=e)throw new ei(`If ${i} is set, batchSize must be null or undefined.Got batchSize = ${e}`)}else{if(null==t)throw new ei(`Either the input data should have a defined shape, or ${i} shoud be specified.`);n=Array.isArray(t)?t[0].shape[0]:t.shape[0]}return n}execute(t,e){if(Array.isArray(e)&&0===e.length)throw new ei("`outputs` is an empty Array, which is not allowed.");const s=Array.isArray(e),n=s?e:[e],i=this.retrieveSymbolicTensors(n),r=new Yr;if(t instanceof h.Tensor&&(t=[t]),Array.isArray(t)){if(t.length!==this.inputs.length)throw new ei(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let e=0;e<this.inputs.length;++e)r.add(this.inputs[e],t[e])}else for(const o of this.inputs){const e=t[o.name];if(null==e)throw new ei(`No value is provided for the model's input ${o.name}`);r.add(o,e)}const a=ta(i,r);return s?a:a[0]}retrieveSymbolicTensors(t){const e=ri(null,t.length);let s=t.length;for(const n of this.layers){const i=Array.isArray(n.output)?n.output:[n.output],r=i.map((t=>t.name));for(let n=0;n<t.length;++n){const a=r.indexOf(t[n]);if(-1!==a&&(e[n]=i[a],s--),0===s)break}if(0===s)break}if(s>0){const s=[];throw e.forEach(((e,n)=>{null==e&&s.push(t[n])})),new ei(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(s)}`)}return e}predictLoop(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:32,s=arguments.length>2&&void 0!==arguments[2]&&arguments[2];return h.tidy((()=>{const n=this.checkNumSamples(t);if(s)throw new si("Verbose predictLoop() is not implemented yet.");const i=Bo(n,e),r=this.outputs.map((t=>[]));for(let e=0;e<i.length;++e){h.tidy((()=>{const s=i[e][0],n=i[e][1],r=Oo(t,s,n),a=[];if(Array.isArray(r))for(let t=0;t<r.length;++t)a.push({key:this.inputs[t],value:r[t]});else a.push({key:this.inputs[0],value:r});const o=new Yr(a);return ta(this.outputs,o)})).forEach(((t,e)=>r[e].push(t)))}return li(r.map((t=>h.concat(t,0))))}))}predict(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const s=Po(t);qo(s,this.inputNames,this.feedInputShapes,!1);try{const t=null==e.batchSize?32:e.batchSize;return Mo(t),this.predictLoop(s,t)}finally{Wo(s,t)}}predictOnBatch(t){qo(t,this.inputNames,this.feedInputShapes,!0);const e=(Array.isArray(t)?t[0]:t).shape[0];return this.predictLoop(t,e)}standardizeUserDataXY(t,e){let s=arguments.length>3?arguments[3]:void 0;if(null==this.optimizer_)throw new ti("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const n=[];for(let i=0;i<this.feedOutputShapes.length;++i){const t=this.feedOutputShapes[i];this.feedLossFns[i]===Ya?n.push(t.slice(0,t.length-1).concat([1])):n.push(t)}if(function(t,e){const s=yi(t.map((t=>t.shape[0])));s.sort();const n=yi(e.map((t=>t.shape[0])));if(n.sort(),s.length>1)throw new ei(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map((t=>t.shape)))}`);if(n.length>1)throw new ei(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(e.map((t=>t.shape)))}`);if(s.length>0&&n.length>0&&!h.util.arraysEqual(s,n))throw new ei(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${n[0]} target sample(s).`)}(t=Vo(t,this.feedInputNames,this.feedInputShapes,!1,"input"),e=Vo(e,this.feedOutputNames,n,!1,"target")),function(t,e,s){const n=[Ga,Xa,Za];for(let i=0;i<t.length;++i){const r=t[i],a=e[i],o=s[i];if(null!=a){if(a===Za&&1===r.shape[r.shape.length-1])throw new ei(`You are passing a target array of shape ${r.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==n.indexOf(a)){const t=r.shape.slice(1),e=o.slice(1);for(let s=0;s<t.length;++s){const n=t[s],i=e[s];if(null!=i&&n!==i)throw new ei(`A target Tensor with shape ${r.shape} was passed for an output of shape ${o}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}(e,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=s&&s>0&&t[0].shape[0]%s!==0)throw new ei(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${s}. Found: ${t[0].shape[0]} sample(s).`);return[t,e]}async standardizeUserData(t,e,s,n){let i=!(arguments.length>4&&void 0!==arguments[4])||arguments[4],r=arguments.length>5?arguments[5]:void 0;const[a,o]=this.standardizeUserDataXY(t,e,i,r);if(null!=s)throw new Error("sample weight is not supported yet.");let l=null;if(null!=n){const t=To(n,this.outputNames);l=[];for(let e=0;e<t.length;++e)l.push(await Do(o[e],null,t[e]))}return[a,o,l]}testLoop(t,e,s){let n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:0,i=arguments.length>4?arguments[4]:void 0;return h.tidy((()=>{const r=this.checkNumSamples(e,s,i,"steps"),a=[];if(n>0)throw new si("Verbose mode is not implemented yet.");if(null!=i)throw new si("steps mode in testLoop() is not implemented yet");{const n=Bo(r,s),i=(0,h.tensor1d)(Gi(0,r));for(let s=0;s<n.length;++s){const r=n[s][0],o=n[s][1],l=Yi(i,r,o-r),u=_o(e,l),c=t(u);if(0===s)for(let t=0;t<c.length;++t)a.push((0,h.scalar)(0));for(let t=0;t<c.length;++t){const e=c[t];a[t]=h.add(a[t],h.mul(o-r,e))}}for(let t=0;t<a.length;++t)a[t]=h.div(a[t],r)}return a}))}getDedupedMetricsNames(){const t=this.metricsNames,e=[];for(let s=0;s<t.length;++s){const n=t[s];let i=n;if(oi(t,n)>1){i+=`_${oi(t.slice(0,s),n)}`}e.push(i)}return e}makeTrainFunction(){return t=>{const e=[],s=t.slice(0,this.inputs.length),n=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),i=t.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),r=[],a=this.collectedTrainableWeights.map((t=>t.read()));return[this.optimizer_.minimize((()=>{const t=[];for(let e=0;e<this.inputs.length;++e)t.push({key:this.inputs[e],value:s[e]});const a=new Yr(t),o=ta(this.outputs,a,{training:!0});let l;for(let s=0;s<this.lossFunctions.length;++s){let t=(0,this.lossFunctions[s])(n[s],o[s]);null!=i[s]&&(t=Eo(t,i[s]));const r=h.mean(t);e.push(r),l=0===s?t:h.add(l,t)}for(let s=0;s<this.metricsTensors.length;++s){let t;if(this.outputs.length>1&&s<this.outputs.length)t=e[s];else{const e=this.metricsTensors[s][0],i=this.metricsTensors[s][1];t=h.mean(e(n[i],o[i]))}h.keep(t),r.push(t)}return l=h.mean(l),this.calculateLosses().forEach((t=>{l=h.add(l,t)})),l}),!0,a)].concat(r)}}makeTestFunction(){this.testFunction=t=>h.tidy((()=>{const e=[];let s;const n=t.slice(0,this.inputs.length),i=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),r=[];for(let t=0;t<this.inputs.length;++t)r.push({key:this.inputs[t],value:n[t]});const a=new Yr(r),o=ta(this.outputs,a);for(let t=0;t<this.lossFunctions.length;++t){const n=this.lossFunctions[t],r=h.mean(n(i[t],o[t]));s=0===t?r:h.add(s,r),e.push(s)}for(let t=0;t<this.metricsTensors.length;++t){const s=this.metricsTensors[t][0],n=this.metricsTensors[t][1],r=h.mean(s(i[n],o[n]));e.push(r)}return e}))}async fit(t,e){let s,n,i,r,a,o,l,u,c,p=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};if(this.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");this.isTraining=!0;try{const h=null==p.batchSize?32:p.batchSize;Mo(h);const d=!1,f=await this.standardizeUserData(t,e,p.sampleWeight,p.classWeight,d,h);s=f[0],n=f[1],c=f[2];let g,m=!1;if(null!=p.validationData&&p.validationData.length>0){if(m=!0,2!==p.validationData.length)throw 3===p.validationData.length?new si("validationData including sample weights is not supported yet."):new ei(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${p.validationData} is invalid.`);a=p.validationData[0],o=p.validationData[1];const t=!0,e=await this.standardizeUserData(a,o,null,null,t,h);l=e[0],u=e[1],g=l.concat(u)}else if(null!=p.validationSplit&&p.validationSplit>0&&p.validationSplit<1){m=!0;const t=Math.floor(s[0].shape[0]*(1-p.validationSplit)),e=s[0].shape[0];l=Oo(s,t,e),i=s,s=Oo(s,0,t),u=Oo(n,t,e),r=n,n=Oo(n,0,t),g=l.concat(u)}else null!=p.validationSteps&&(m=!0);const y=s.concat(n).concat(c);this.checkTrainableWeightsConsistency();const w=this.makeTrainFunction(),b=this.getDedupedMetricsNames();let v,k;m?(this.makeTestFunction(),v=this.testFunction,k=b.slice().concat(b.map((t=>"val_"+t)))):(v=null,g=[],k=b.slice());const S=Wa(p.callbacks,p.yieldEvery);return await this.fitLoop(w,y,b,h,p.epochs,p.verbose,S,v,g,p.shuffle,k,p.initialEpoch,null,null)}finally{this.isTraining=!1,Wo(s,t),Wo(n,e),Wo(i,t),Wo(r,e),Wo(l,a),Wo(u,o),null!=c&&h.dispose(c)}}async fitLoop(t,e,s,n,i,r,a,o,l,u,c,p,d,f){null==n&&(n=32),null==i&&(i=1),null==u&&(u=!0),null==p&&(p=0);let g=!1;if(null!=o&&null!=l&&(g=!0),null!=f&&(g=!0,null==d))throw new ei("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const m=this.checkNumSamples(e,n,d,"steps_per_epoch");let y;null!=m&&(y=Gi(0,m)),null==r&&(r=1);const{callbackList:w,history:b}=ja(a,r,i,p,m,d,n,g,c);w.setModel(this),this.history=b,await w.onTrainBegin(),this.stopTraining_=!1;for(let v=p;v<i;++v){await w.onEpochBegin(v);const i={};if(null!=d)throw new si("stepsPerEpoch mode is not implemented yet.");{if("batch"===u)throw new si("batch shuffling is not implemneted yet");u&&h.util.shuffle(y);const r=(0,h.tensor1d)(y),a=Bo(m,n);for(let u=0;u<a.length;++u){const c={};if(await w.onBatchBegin(u,c),h.tidy((()=>{const p=a[u][0],d=a[u][1],f=Yi(r,p,d-p);c.batch=u,c.size=d-p;const m=_o(e,f),y=t(m);for(let t=0;t<s.length;++t){const e=s[t],n=y[t];c[e]=n,h.keep(n)}if(u===a.length-1&&g){const t=this.testLoop(o,l,n);for(let e=0;e<s.length;++e){const n=s[e],r=t[e];h.keep(r),i["val_"+n]=r}}})),await w.onBatchEnd(u,c),Ra(c),this.stopTraining_)break}r.dispose()}if(await w.onEpochEnd(v,i),this.stopTraining_)break}return await w.onTrainEnd(),await this.history.syncData(),this.history}async fitDataset(t,e){return Ro(this,t,e)}async trainOnBatch(t,e){const s=await this.standardizeUserData(t,e),n=s[0],i=s[1],r=this.makeTrainFunction()(n.concat(i)),a=[];for(const o of r){const t=await o.data();a.push(t[0])}return h.dispose(r),Wo(s[0],t),Wo(s[1],e),li(a)}getNamedWeights(t){const e=[],s=null!=t&&t.trainableOnly,n=s?this.trainableWeights:this.weights,i=this.getWeights(s);for(let r=0;r<n.length;++r)s&&!n[r].trainable||e.push({name:n[r].originalName,tensor:i[r]});return e}set stopTraining(t){this.stopTraining_=t}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(t){this.optimizer_!==t&&(this.optimizer_=t,this.isOptimizerOwned=!1)}dispose(){const t=super.dispose();if(0===t.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const e=h.memory().numTensors;this.optimizer_.dispose(),t.numDisposedVariables+=e-h.memory().numTensors}return t}getLossIdentifiers(){let t;if("string"===typeof this.loss)t=hi(this.loss);else if(Array.isArray(this.loss)){for(const t of this.loss)if("string"!==typeof t)throw new Error("Serialization of non-string loss is not supported.");t=this.loss.map((t=>hi(t)))}else{const e=Object.keys(this.loss);t={};const s=this.loss;for(const n of e){if("string"!==typeof s[n])throw new Error("Serialization of non-string loss is not supported.");t[n]=hi(s[n])}}return t}getMetricIdentifiers(){if("string"===typeof this.metrics||"function"===typeof this.metrics)return[hi(go(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map((t=>hi(go(t))));{const t={};for(const e in this.metrics)t[e]=hi(go(this.metrics[e]));return t}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(t){if(null!=t.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=t.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=t.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const e=Va(No(t.optimizer_config));let s,n;if("string"===typeof t.loss)s=ci(t.loss);else if(Array.isArray(t.loss))s=t.loss.map((t=>ci(t)));else if(null!=t.loss){s={};for(const e in t.loss)s[e]=ci(t.loss[e])}if(Array.isArray(t.metrics))n=t.metrics.map((t=>ci(t)));else if(null!=t.metrics){n={};for(const e in t.metrics)n[e]=ci(t.metrics[e])}this.compile({loss:s,metrics:n,optimizer:e})}async save(t,e){if("string"===typeof t){const e=h.io.getSaveHandlers(t);if(0===e.length)throw new ei(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new ei(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new ei("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const s=await h.io.encodeWeights(this.getNamedWeights(e)),n={modelTopology:this.toJSON(null,!1),format:"layers-model",generatedBy:`TensorFlow.js tfjs-layers v${Ao}`,convertedBy:null};if(null!=e&&e.includeOptimizer&&null!=this.optimizer){n.trainingConfig=this.getTrainingConfig();const t="optimizer",{data:e,specs:i}=await h.io.encodeWeights(await this.optimizer.getWeights(),t);s.specs.push(...i),s.data=h.io.concatenateArrayBuffers([s.data,e])}if(null!=this.userDefinedMetadata){const t=!0;yo(this.userDefinedMetadata,this.name,t),n.userDefinedMetadata=this.userDefinedMetadata}return n.weightData=s.data,n.weightSpecs=s.specs,t.save(n)}setUserDefinedMetadata(t){yo(t,this.name),this.userDefinedMetadata=t}getUserDefinedMetadata(){return this.userDefinedMetadata}}Go.className="Model",h.serialization.registerClass(Go);class Ho extends Go{}async function Ko(t,e){"modelTopology"in t||(t={modelTopology:t});let s=t.modelTopology;null!=s.model_config&&(s=s.model_config);const n=Va(No(s),e);if(null!=t.weightsManifest){const e=await h.io.loadWeights(t.weightsManifest,t.pathPrefix,n.weights.map((t=>t.originalName))),s={};for(const t of n.weights)s[t.originalName]=e[t.originalName];n.loadWeights(s),(0,h.dispose)(e)}return n}async function Jo(t,e){if(null==e&&(e={}),"string"===typeof t){const s=h.io.getLoadHandlers(t,e);if(0===s.length)s.push(h.io.browserHTTPRequest(t,e));else if(s.length>1)throw new ei(`Found more than one (${s.length}) load handlers for URL '${t}'`);t=s[0]}return async function(t,e,s){null==s&&(s={});if(null==t.load)throw new ei("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const n=await t.load();let i=n.modelTopology;null!=i.model_config&&(i=i.model_config);const r=null==s.strict||s.strict,a=null!=n.weightData&&null!=n.weightSpecs&&r,o=Va(No(i),e,a),l=n.trainingConfig;null!=l&&o.loadTrainingConfig(l);null!=n.userDefinedMetadata&&o.setUserDefinedMetadata(n.userDefinedMetadata);if(null!=n.weightData){if(null==n.weightSpecs)throw new ei("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:t,optimizerWeights:e}=function(t,e){const s=h.io.decodeWeights(t,e),n={},i=[];return e.forEach((t=>{"optimizer"===t.group?i.push({name:t.name,tensor:s[t.name]}):n[t.name]=s[t.name]})),{modelWeights:n,optimizerWeights:i}}(n.weightData,n.weightSpecs);o.loadWeights(t,r),null!=o.optimizer&&e.length>0&&await o.optimizer.setWeights(e),(0,h.dispose)(t),(0,h.dispose)(e.map((t=>t.tensor)))}return o}(t,void 0,e)}Ho.className="Functional",h.serialization.registerClass(Ho);class Zo extends Go{constructor(t){if(super({inputs:[],outputs:[]}),t=t||{},this.trainable=!0,this.built=!1,this.name=null!=t.name?t.name:Ci("sequential_"),null!=t.layers)for(const e of t.layers)this.add(e)}checkShape(t){if(t.inboundNodes[0].outputTensors[0].shape.some((t=>t<0)))throw new ei(`Negative dimension size caused by adding layer ${t.name} with input shape [${t.inboundNodes[0].inputTensors[0].shape}]`)}add(t){const e=t instanceof Zo||t instanceof Go;let s;if(e){if(s=t,1!==s.outputs.length)throw new ei("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==s.inputs.length)throw new ei("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===t.inboundNodes.length){if(null==t.batchInputShape)throw new ei("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const e=Zr({batchShape:t.batchInputShape,dtype:t.dtype,name:t.name+"_input"});t.apply(e)}if(e)this.outputs=s.outputs,this.inputs=s.inputs;else{if(1!==t.inboundNodes.length)throw new ei(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);if(1!==t.inboundNodes[0].outputTensors.length)throw new ei("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[t.inboundNodes[0].outputTensors[0]],this.inputs=Kr(this.outputs[0])}this.inboundNodes=[],new qr({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:ri(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs[0].shape})}else{const e=t.apply(this.outputs[0]);if(Array.isArray(e))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[e],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(t),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const t=this.layers.length-1;this.layers[t].outboundNodes=[],this.outputs=[this.layers[t].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(t,e){return null==this.model&&this.build(),this.model.call(t,e)}build(t){if(Mr(t),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new Go({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:console.log;this.built||this.build(),super.summary(t,e,s)}setWeights(t){null==this.model&&this.build(),this.model.setWeights(t)}evaluate(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};if(!this.built)throw new ti("The model needs to be compiled before being used.");return this.model.evaluate(t,e,s)}async evaluateDataset(t,e){if(!this.built)throw new ti("The model needs to be compiled before being used.");return this.model.evaluateDataset(t,e)}predict(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return null==this.model&&this.build(),this.model.predict(t,e)}predictOnBatch(t){return null==this.model&&this.build(),this.model.predictOnBatch(t)}compile(t){this.build(),this.model.compile(t),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(t){this.model.optimizer=t}async fit(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};if(!this.built)throw new ti("The model needs to be compiled before being used.");return this.model.fit(t,e,s)}async fitDataset(t,e){if(!this.built)throw new ti("The model needs to be compiled before being used.");return this.model.fitDataset(t,e)}async trainOnBatch(t,e){return this.model.trainOnBatch(t,e)}static fromConfig(t,e){let s,n=arguments.length>3&&void 0!==arguments[3]&&arguments[3],i={};if(e instanceof Array){if(null==e[0].className||"Merge"===e[0].className)throw new ei("Legacy serialization format not supported yet.");s=e}else h.util.assert(null!=e.layers,(()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.")),s=e.layers,delete e.layers,i=e;const r=new t(i);if(!(r instanceof Zo))throw new si(`Sequential.fromConfig called on non-Sequential input: ${r}`);for(const a of s){const t=Va(a,void 0,n);n&&t.setFastWeightInitDuringBuild(!0),r.add(t)}return r}set stopTraining(t){if(null==this.model)throw new ei("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=t}get stopTraining(){if(null==this.model)throw new ei("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const t=[];for(const e of this.layers){const s={};s.className=e.getClassName(),s.config=e.getConfig(),t.push(s)}return{name:this.name,layers:t}}}function Yo(t){return new Go(t)}function Xo(t){return new Zo(t)}function Qo(t){return Zr(t)}function tl(t,e){Ua.registerCallbackConstructor(t,e)}Zo.className="Sequential",h.serialization.registerClass(Zo);class el extends h.serialization.Serializable{getConfig(){return{}}}class sl extends el{apply(t){return function(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1;if(1!==e)throw new si(`Support for alpha values other than 1 (${e}) is not implemented yet.`);return h.elu(t)}(t,arguments.length>1&&void 0!==arguments[1]?arguments[1]:1)}}sl.className="elu",h.serialization.registerClass(sl);class nl extends el{apply(t){return h.selu(t)}}nl.className="selu",h.serialization.registerClass(nl);class il extends el{apply(t){return h.relu(t)}}il.className="relu",h.serialization.registerClass(il);class rl extends el{apply(t){return(0,h.tidy)((()=>h.minimum(6,h.relu(t))))}}rl.className="relu6",h.serialization.registerClass(rl);class al extends el{apply(t){return t}}al.className="linear",h.serialization.registerClass(al);class ol extends el{apply(t){return h.sigmoid(t)}}ol.className="sigmoid",h.serialization.registerClass(ol);class ll extends el{apply(t){return function(t){return(0,h.tidy)((()=>{const e=h.add(.5,h.mul(.2,t));return h.clipByValue(e,0,1)}))}(t)}}ll.className="hardSigmoid",h.serialization.registerClass(ll);class ul extends el{apply(t){return h.softplus(t)}}ul.className="softplus",h.serialization.registerClass(ul);class hl extends el{apply(t){return function(t){return(0,h.tidy)((()=>h.div(t,h.add(h.abs(t),1))))}(t)}}hl.className="softsign",h.serialization.registerClass(hl);class cl extends el{apply(t){return h.tanh(t)}}cl.className="tanh",h.serialization.registerClass(cl);class pl extends el{apply(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-1;return h.softmax(t,e)}}pl.className="softmax",h.serialization.registerClass(pl);class dl extends el{apply(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:-1;return h.logSoftmax(t,e)}}dl.className="logSoftmax",h.serialization.registerClass(dl);class fl extends el{apply(t){return(0,h.tidy)((()=>h.tidy((()=>{const e=Math.sqrt(2),s=h.mul(.5,h.add(1,h.erf(h.div(t,e))));return h.mul(t,s)}))))}}fl.className="gelu",h.serialization.registerClass(fl);class gl extends el{apply(t){return(0,h.tidy)((()=>h.mul(.5,h.mul(t,h.add(1,h.tanh(h.mul(h.sqrt(h.div(2,Math.PI)),h.add(t,h.mul(.044715,h.pow(t,3))))))))))}}gl.className="gelu_new",h.serialization.registerClass(gl);class ml extends el{apply(t){return(0,h.tidy)((()=>h.mul(t,h.tanh(h.softplus(t)))))}}ml.className="mish",h.serialization.registerClass(ml);class yl extends el{apply(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1;return(0,h.tidy)((()=>h.mul(h.sigmoid(h.mul(t,e)),t)))}}function wl(t){return t.getClassName()}function bl(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return gi(t,h.serialization.SerializationMap.getMap().classNameMap,e,"activation")}function vl(t){if(null==t){const t={className:"linear",config:{}};return bl(t)}if("string"===typeof t){const e={};return e.className=t,e.config={},bl(e)}return t instanceof el?t:bl(t)}function kl(t){if(null!=t&&"object"!==typeof t)throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${t}`)}yl.className="swish",h.serialization.registerClass(yl);class Sl extends h.serialization.Serializable{}class xl extends Sl{constructor(t){super(),kl(t),this.l1=null==t||null==t.l1?.01:t.l1,this.l2=null==t||null==t.l2?.01:t.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(t){return(0,h.tidy)((()=>{let e=(0,h.zeros)([1]);return this.hasL1&&(e=(0,h.add)(e,(0,h.sum)(h.mul(this.l1,(0,h.abs)(t))))),this.hasL2&&(e=(0,h.add)(e,(0,h.sum)(h.mul(this.l2,ar(t))))),h.reshape(e,[])}))}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(t,e){return new t({l1:e.l1,l2:e.l2})}}xl.className="L1L2",h.serialization.registerClass(xl);const Nl={l1l2:"L1L2"};function zl(t){return di(t)}function Al(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return gi(t,h.serialization.SerializationMap.getMap().classNameMap,e,"regularizer")}function Cl(t){if(null==t)return null;if("string"===typeof t){return Al({className:t in Nl?Nl[t]:t,config:{}})}return t instanceof Sl?t:Al(t)}class Il extends Hr{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,null!=t&&(this.maxValue=t.maxValue)}call(t,e){t=$r(t);let s=(0,h.relu)(t);return null!=this.maxValue&&(s=(0,h.clipByValue)(s,0,this.maxValue)),s}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},e=super.getConfig();return Object.assign(t,e),t}}Il.className="ReLU",h.serialization.registerClass(Il);class Tl extends Hr{constructor(t){super(null==t?{}:t),this.DEFAULT_ALPHA=.3,null==t&&(t={}),this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const s=$r(t);return(0,h.leakyRelu)(s,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}Tl.className="LeakyReLU",h.serialization.registerClass(Tl);class Dl extends Hr{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==t&&(t={}),this.supportsMasking=!0,this.alphaInitializer=Fr(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=Cl(t.alphaRegularizer),this.alphaConstraint=da(t.alphaConstraint),null==t.sharedAxes)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else{if("number"!==typeof t.sharedAxes)throw new ei(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`);this.sharedAxes=[t.sharedAxes]}}build(t){const e=(t=Mr(t)).slice(1);if(null!=this.sharedAxes)for(const n of this.sharedAxes)e[n-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const s={};if(null!=this.sharedAxes)for(let n=1;n<t.length;++n)s[n]=t[n];this.inputSpec=[new Ur({ndim:t.length,axes:s})],this.built=!0}call(t,e){return t=$r(t),(0,h.prelu)(t,this.alpha.read())}getConfig(){const t={alphaInitializer:Er(this.alphaInitializer),alphaRegularizer:zl(this.alphaRegularizer),alphaConstraint:ca(this.alphaConstraint),sharedAxes:this.sharedAxes},e=super.getConfig();return Object.assign(t,e),t}}Dl.className="PReLU",h.serialization.registerClass(Dl);class El extends Hr{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA=1,null==t&&(t={}),null!=t.alpha&&t.alpha!==this.DEFAULT_ALPHA)throw new si(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const s=$r(t);return(0,h.elu)(s)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}El.className="ELU",h.serialization.registerClass(El);class Fl extends Hr{constructor(t){super(null==t?{}:t),this.DEFAULT_THETA=1,null==t&&(t={}),this.theta=null==t.theta?this.DEFAULT_THETA:t.theta}call(t,e){const s=$r(t);return(0,h.mul)(s,(0,h.cast)((0,h.greater)(s,this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},e=super.getConfig();return Object.assign(t,e),t}}Fl.className="ThresholdedReLU",h.serialization.registerClass(Fl);class Ll extends Hr{constructor(t){super(null==t?{}:t),this.DEFAULT_AXIS=1,null==t&&(t={}),this.softmax=(new pl).apply,this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis}call(t,e){return(0,h.tidy)((()=>{let s=$r(t);const n=e.mask;if(null!=n){const t=(0,h.mul)((0,h.sub)((0,h.ones)(s.shape),(0,h.cast)(n,s.dtype)),(0,h.scalar)(-1e9));s=(0,h.add)(s,t)}return this.axis instanceof Array?this.axis.length>1?(0,h.exp)((0,h.sub)(s,(0,h.logSumExp)(s,this.axis,!0))):this.softmax(s,this.axis[0]):this.softmax(s,this.axis)}))}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function Rl(t,e,s){if("number"===typeof t)return ri(t,e);if(t.length!==e)throw new ei(`The ${s} argument must be an integer or tuple of ${e} integers. Received: ${t.length} elements.`);for(let i=0;i<e;++i){const r=t[i];if((n=r)!==parseInt(n.toString(),10))throw new ei(`The ${s} argument must be an integer or tuple of ${e} integers. Received: ${JSON.stringify(t)} including a non-integer number ${r}`)}return t;var n}function $l(t,e,s,n){if(null==t)return t;let i;return i="same"===s?t:t-(e+(e-1)*((arguments.length>4&&void 0!==arguments[4]?arguments[4]:1)-1))+1,Math.floor((i+n-1)/n)}function Ml(t,e,s,n){if(null==t)return null;if("valid"===n)t=t*e+qi([s-e,0]);else{if("same"!==n)throw new ei(`Unsupport padding mode: ${n}.`);t*=e}return t}function Ol(t,e){return(0,h.tidy)((()=>(Ri(e),"channelsFirst"===e?h.transpose(t,[0,2,3,1]):t)))}function _l(t,e){return(0,h.tidy)((()=>(Ri(e),"channelsFirst"===e?h.transpose(t,[0,2,3,4,1]):t)))}function Bl(t,e,s){let n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1,i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:"valid",r=arguments.length>5?arguments[5]:void 0,a=arguments.length>6&&void 0!==arguments[6]?arguments[6]:1;return(0,h.tidy)((()=>{if(null==r&&(r="channelsLast"),Ri(r),3!==t.shape.length)throw new ei(`The input of a conv1dWithBias operation should be 3, but is ${t.shape.length} instead.`);if(3!==e.shape.length)throw new ei(`The kernel for a conv1dWithBias operation should be 3, but is ${e.shape.length} instead`);if(null!=s&&1!==s.shape.length)throw new ei(`The bias for a conv1dWithBias operation should be 1, but is ${s.shape.length} instead`);if("channelsFirst"===r&&(t=h.transpose(t,[0,2,1])),"causal"===i)throw new si("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let o=h.conv1d(t,e,n,"same"===i?"same":"valid","NWC",a);return null!=s&&(o=lr(o,s)),o}))}function Pl(t,e,s){let n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:[1,1],i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:"valid",r=arguments.length>5?arguments[5]:void 0,a=arguments.length>6?arguments[6]:void 0,o=arguments.length>7&&void 0!==arguments[7]?arguments[7]:null;return(0,h.tidy)((()=>{if(null==r&&(r="channelsLast"),Ri(r),3!==t.rank&&4!==t.rank)throw new ei(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${t.rank}.`);if(3!==e.rank&&4!==e.rank)throw new ei(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${t.rank}.`);let l=Ol(t,r);if("causal"===i)throw new si("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=h.fused.conv2d({x:l,filter:e,strides:n,pad:"same"===i?"same":"valid",dilations:a,dataFormat:"NHWC",bias:s,activation:o}),"channelsFirst"===r&&(l=h.transpose(l,[0,3,1,2])),l}))}function Wl(t,e,s){let n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:[1,1,1],i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:"valid",r=arguments.length>5?arguments[5]:void 0,a=arguments.length>6?arguments[6]:void 0;return(0,h.tidy)((()=>{if(null==r&&(r="channelsLast"),Ri(r),4!==t.rank&&5!==t.rank)throw new ei(`conv3dWithBias expects input to be of rank 4 or 5, but received ${t.rank}.`);if(4!==e.rank&&5!==e.rank)throw new ei(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${t.rank}.`);let o=_l(t,r);if("causal"===i)throw new si("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return o=h.conv3d(o,e,n,"same"===i?"same":"valid","NDHWC",a),null!=s&&(o=lr(o,s)),"channelsFirst"===r&&(o=h.transpose(o,[0,4,1,2,3])),o}))}Ll.className="Softmax",h.serialization.registerClass(Ll);class Ul extends Hr{constructor(t,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",Ul.verifyArgs(e),this.rank=t,ki(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new si(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=Rl(e.kernelSize,t,"kernelSize"),this.strides=Rl(null==e.strides?1:e.strides,t,"strides"),this.padding=null==e.padding?"valid":e.padding,$i(this.padding),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Ri(this.dataFormat),this.activation=vl(e.activation),this.useBias=null==e.useBias||e.useBias,this.biasInitializer=Fr(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=da(e.biasConstraint),this.biasRegularizer=Cl(e.biasRegularizer),this.activityRegularizer=Cl(e.activityRegularizer),this.dilationRate=Rl(null==e.dilationRate?1:e.dilationRate,t,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new ei(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"===typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new ei(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"===typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new ei(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(t){if(ai("kernelSize"in t,"required key 'kernelSize' not in config"),"number"!==typeof t.kernelSize&&!vi(t.kernelSize,"number",1,3))throw new ei(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:wl(this.activation),useBias:this.useBias,biasInitializer:Er(this.biasInitializer),biasRegularizer:zl(this.biasRegularizer),activityRegularizer:zl(this.activityRegularizer),biasConstraint:ca(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}class jl extends Ul{constructor(t,e){super(t,e),this.kernel=null,jl.verifyArgs(e),this.filters=e.filters,ki(this.filters,"filters"),this.kernelInitializer=Fr(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=da(e.kernelConstraint),this.kernelRegularizer=Cl(e.kernelRegularizer)}build(t){t=Mr(t);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new ei(`The channel dimension of the input should be defined. Found ${t[e]}`);const s=t[e],n=this.kernelSize.concat([s,this.filters]);this.kernel=this.addWeight("kernel",n,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:s}}],this.built=!0}call(t,e){return(0,h.tidy)((()=>{let e;t=$r(t);const s=null==this.bias?null:this.bias.read(),n=xi(this.activation.getClassName());if(null!=n&&2===this.rank)e=Pl(t,this.kernel.read(),s,this.strides,this.padding,this.dataFormat,this.dilationRate,n);else{if(1===this.rank)e=Bl(t,this.kernel.read(),s,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=Pl(t,this.kernel.read(),s,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new si("convolutions greater than 3D are not implemented yet.");e=Wl(t,this.kernel.read(),s,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(e=this.activation.apply(e))}return e}))}computeOutputShape(t){t=Mr(t);const e=[],s="channelsLast"===this.dataFormat?t.slice(1,t.length-1):t.slice(2);for(let i=0;i<s.length;++i){const t=$l(s[i],this.kernelSize[i],this.padding,this.strides[i],"number"===typeof this.dilationRate?this.dilationRate:this.dilationRate[i]);e.push(t)}let n=[t[0]];return"channelsLast"===this.dataFormat?(n=n.concat(e),n.push(this.filters)):(n.push(this.filters),n=n.concat(e)),n}getConfig(){const t={filters:this.filters,kernelInitializer:Er(this.kernelInitializer),kernelRegularizer:zl(this.kernelRegularizer),kernelConstraint:ca(this.kernelConstraint)},e=super.getConfig();return Object.assign(t,e),t}static verifyArgs(t){if(!("filters"in t)||"number"!==typeof t.filters||t.filters<1)throw new ei(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`)}}class Vl extends jl{constructor(t){super(2,t),Vl.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!==typeof t.kernelSize&&!vi(t.kernelSize,"number",1,2))throw new ei(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}Vl.className="Conv2D",h.serialization.registerClass(Vl);class ql extends jl{constructor(t){super(3,t),ql.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!==typeof t.kernelSize&&(!Array.isArray(t.kernelSize)||1!==t.kernelSize.length&&3!==t.kernelSize.length))throw new ei(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}ql.className="Conv3D",h.serialization.registerClass(ql);class Gl extends Vl{constructor(t){if(super(t),this.inputSpec=[new Ur({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new ei(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(4!==(t=Mr(t)).length)throw new ei("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new ei("The channel dimension of the inputs should be defined. Found `None`.");const s=t[e],n=this.kernelSize.concat([this.filters,s]);this.kernel=this.addWeight("kernel",n,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Ur({ndim:4,axes:{[e]:s}})],this.built=!0}call(t,e){return h.tidy((()=>{let e=$r(t);if(4!==e.shape.length)throw new ei(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${e.shape.length}`);const s=e.shape,n=s[0];let i,r;"channelsFirst"===this.dataFormat?(i=2,r=3):(i=1,r=2);const a=s[i],o=s[r],l=this.kernelSize[0],u=this.kernelSize[1],c=this.strides[0],p=this.strides[1],d=[n,Ml(a,c,l,this.padding),Ml(o,p,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(e=h.transpose(e,[0,2,3,1]));let f=h.conv2dTranspose(e,this.kernel.read(),d,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(f=h.transpose(f,[0,3,1,2])),null!=this.bias&&(f=lr(f,this.bias.read(),this.dataFormat)),null!=this.activation&&(f=this.activation.apply(f)),f}))}computeOutputShape(t){const e=(t=Mr(t)).slice();let s,n,i;"channelsFirst"===this.dataFormat?(s=1,n=2,i=3):(s=3,n=1,i=2);const r=this.kernelSize[0],a=this.kernelSize[1],o=this.strides[0],l=this.strides[1];return e[s]=this.filters,e[n]=Ml(e[n],o,r,this.padding),e[i]=Ml(e[i],l,a,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}Gl.className="Conv2DTranspose",h.serialization.registerClass(Gl);class Hl extends ql{constructor(t){if(super(t),this.inputSpec=[new Ur({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new ei(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(5!==(t=Mr(t)).length)throw new ei("Input should have rank 5; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new ei("The channel dimension of the inputs should be defined. Found `None`.");const s=t[e],n=this.kernelSize.concat([this.filters,s]);this.kernel=this.addWeight("kernel",n,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Ur({ndim:5,axes:{[e]:s}})],this.built=!0}call(t,e){return h.tidy((()=>{let e=$r(t);if(5!==e.shape.length)throw new ei(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${e.shape.length}`);const s=e.shape,n=s[0];let i,r,a;"channelsFirst"===this.dataFormat?(a=2,i=3,r=4):(a=1,i=2,r=3);const o=s[a],l=s[i],u=s[r],c=this.kernelSize[0],p=this.kernelSize[1],d=this.kernelSize[2],f=this.strides[0],g=this.strides[1],m=this.strides[2],y=[n,Ml(o,f,c,this.padding),Ml(l,g,p,this.padding),Ml(u,m,d,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(e=h.transpose(e,[0,2,3,4,1]));let w=h.conv3dTranspose(e,this.kernel.read(),y,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(w=h.transpose(w,[0,4,1,2,3])),null!==this.bias&&(w=lr(w,this.bias.read(),this.dataFormat)),null!==this.activation&&(w=this.activation.apply(w)),w}))}computeOutputShape(t){const e=(t=Mr(t)).slice();let s,n,i,r;"channelsFirst"===this.dataFormat?(s=1,n=2,i=3,r=4):(s=4,n=1,i=2,r=3);const a=this.kernelSize[0],o=this.kernelSize[1],l=this.kernelSize[2],u=this.strides[0],h=this.strides[1],c=this.strides[2];return e[s]=this.filters,e[n]=Ml(e[n],u,a,this.padding),e[i]=Ml(e[i],h,o,this.padding),e[r]=Ml(e[r],c,l,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}Hl.className="Conv3DTranspose",h.serialization.registerClass(Hl);class Kl extends jl{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==e.filters)throw new ei("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=e.kernelInitializer||null!=e.kernelRegularizer||null!=e.kernelConstraint)throw new ei("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=e.padding&&"same"!==e.padding&&"valid"!==e.padding)throw new ei(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=Fr(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=Cl(e.depthwiseRegularizer),this.depthwiseConstraint=da(e.depthwiseConstraint),this.pointwiseInitializer=Fr(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=Cl(e.pointwiseRegularizer),this.pointwiseConstraint=da(e.pointwiseConstraint)}build(t){if((t=Mr(t)).length<this.rank+2)throw new ei(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(t)}`);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e]||t[e]<0)throw new ei(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);const s=t[e],n=this.kernelSize.concat([s,this.depthMultiplier]),i=[];for(let a=0;a<this.rank;++a)i.push(1);i.push(s*this.depthMultiplier,this.filters);const r=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",n,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,r,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",i,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,r,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,r,this.biasConstraint):this.bias=null,this.inputSpec=[new Ur({ndim:this.rank+2,axes:{[e]:s}})],this.built=!0}call(t,e){return(0,h.tidy)((()=>{let e;if(t=$r(t),1===this.rank)throw new si("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(t=h.transpose(t,[0,2,3,1])),e=h.separableConv2d(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(e=lr(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),"channelsFirst"===this.dataFormat&&(e=h.transpose(e,[0,3,1,2])),e}))}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=Er(this.depthwiseInitializer),t.pointwiseInitializer=Er(this.pointwiseInitializer),t.depthwiseRegularizer=zl(this.depthwiseRegularizer),t.pointwiseRegularizer=zl(this.pointwiseRegularizer),t.depthwiseConstraint=ca(this.depthwiseConstraint),t.pointwiseConstraint=ca(this.pointwiseConstraint),t}}Kl.className="SeparableConv";class Jl extends Kl{constructor(t){super(2,t)}}Jl.className="SeparableConv2D",h.serialization.registerClass(Jl);class Zl extends jl{constructor(t){super(1,t),Zl.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if("number"!==typeof t.kernelSize&&!vi(t.kernelSize,"number",1,1))throw new ei(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}Zl.className="Conv1D",h.serialization.registerClass(Zl);class Yl extends Hr{constructor(t){super(t),"number"===typeof t.cropping?this.cropping=[[t.cropping,t.cropping],[t.cropping,t.cropping]]:"number"===typeof t.cropping[0]?this.cropping=[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:this.cropping=t.cropping,this.dataFormat=void 0===t.dataFormat?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return(0,h.tidy)((()=>{if(t=$r(t),"channelsLast"===this.dataFormat){const e=Qi(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return Qi(e,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const e=Qi(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return Qi(e,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}}))}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Yl.className="Cropping2D",h.serialization.registerClass(Yl);class Xl extends Hr{constructor(t){var e;super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==t.size?this.DEFAULT_SIZE:t.size,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Ri(this.dataFormat),this.interpolation=null==t.interpolation?"nearest":t.interpolation,e=this.interpolation,bi(Ti,"InterpolationFormat",e)}computeOutputShape(t){if("channelsFirst"===this.dataFormat){const e=null==t[2]?null:this.size[0]*t[2],s=null==t[3]?null:this.size[1]*t[3];return[t[0],t[1],e,s]}{const e=null==t[1]?null:this.size[0]*t[1],s=null==t[2]?null:this.size[1]*t[2];return[t[0],e,s,t[3]]}}call(t,e){return h.tidy((()=>{let e=$r(t);const s=e.shape;if("channelsFirst"===this.dataFormat){e=h.transpose(e,[0,2,3,1]);const t=this.size[0]*s[2],n=this.size[1]*s[3],i="nearest"===this.interpolation?h.image.resizeNearestNeighbor(e,[t,n]):h.image.resizeBilinear(e,[t,n]);return h.transpose(i,[0,3,1,2])}{const t=this.size[0]*s[1],n=this.size[1]*s[2];return"nearest"===this.interpolation?h.image.resizeNearestNeighbor(e,[t,n]):h.image.resizeBilinear(e,[t,n])}}))}getConfig(){const t={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}}Xl.className="UpSampling2D",h.serialization.registerClass(Xl);class Ql extends Ul{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=Fr(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=da(t.depthwiseConstraint),this.depthwiseRegularizer=Cl(t.depthwiseRegularizer)}build(t){if((t=Mr(t)).length<4)throw new ei(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e="channelsFirst"===this.dataFormat?1:3;if(null==t[e]||t[e]<0)throw new ei(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const s=t[e],n=[this.kernelSize[0],this.kernelSize[1],s,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",n,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[s*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return(0,h.tidy)((()=>{let e=function(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[1,1],n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"valid",i=arguments.length>4?arguments[4]:void 0,r=arguments.length>5?arguments[5]:void 0;return(0,h.tidy)((()=>{null==i&&(i="channelsLast"),Ri(i);let a=Ol(t,i);if(4!==t.rank)throw new ei(`Input for depthwiseConv2d is required to be 4-D, but is instead ${t.rank}-D`);if(4!==e.rank)throw new ei(`depthwiseKernel is required to be 4-D, but is instead ${e.rank}-D`);return a=h.depthwiseConv2d(a,e,s,"same"===n?"same":"valid","NHWC",r),"channelsFirst"===i&&(a=h.transpose(a,[0,3,1,2])),a}))}(t=$r(t),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(e=lr(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),e}))}computeOutputShape(t){t=Mr(t);const e="channelsFirst"===this.dataFormat?t[2]:t[1],s="channelsFirst"===this.dataFormat?t[3]:t[2],n="channelsFirst"===this.dataFormat?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,i=$l(e,this.kernelSize[0],this.padding,this.strides[0]),r=$l(s,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[t[0],n,i,r]:[t[0],i,r,n]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=Er(this.depthwiseInitializer),t.depthwiseRegularizer=zl(this.depthwiseRegularizer),t.depthwiseConstraint=ca(this.depthwiseRegularizer),t}}function tu(t,e,s,n){if(Array.isArray(t)){if(null!=e||null!=s)throw new ei("When inputs is an array, neither initialState or constants should be provided");null!=n&&(s=t.slice(t.length-n,t.length),t=t.slice(0,t.length-n)),t.length>1&&(e=t.slice(1,t.length)),t=t[0]}function i(t){return null==t||Array.isArray(t)?t:[t]}return{inputs:t,initialState:e=i(e),constants:s=i(s)}}function eu(t,e,s){let n=arguments.length>3&&void 0!==arguments[3]&&arguments[3],i=arguments.length>4?arguments[4]:void 0,r=arguments.length>5?arguments[5]:void 0,a=arguments.length>6&&void 0!==arguments[6]&&arguments[6],o=arguments.length>7&&void 0!==arguments[7]&&arguments[7];return h.tidy((()=>{const l=e.shape.length;if(l<3)throw new ei(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(Gi(2,l));if(e=h.transpose(e,u),null!=r)throw new si("The rnn() functoin of the deeplearn.js backend does not support constants yet.");a&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=i&&(i=h.cast(h.cast(i,"bool"),"float32"),i.rank===l-1&&(i=h.expandDims(i,-1)),i=h.transpose(i,u)),n&&(e=h.reverse(e,0),null!=i&&(i=h.reverse(i,0)));const c=[];let p,d=s;const f=e.shape[0],g=h.unstack(e);let m,y;null!=i&&(m=h.unstack(i));for(let e=0;e<f;++e){const s=g[e],n=h.tidy((()=>t(s,d)));if(null==i)p=n[0],d=n[1];else{const t=h.tidy((()=>{const t=m[e],s=h.sub(h.onesLike(t),t);return{output:h.add(h.mul(n[0],t),h.mul(d[0],s)),newStates:d.map(((e,i)=>h.add(h.mul(n[1][i],t),h.mul(e,s))))}}));p=t.output,d=t.newStates}o&&c.push(p)}if(o){const t=1;y=h.stack(c,t)}return[p,y,d]}))}Ql.className="DepthwiseConv2D",h.serialization.registerClass(Ql);class su extends Hr{constructor(t){let e;if(super(t),null==t.cell)throw new ei("cell property is missing for the constructor of RNN.");if(e=Array.isArray(t.cell)?new hu({cells:t.cell}):t.cell,null==e.stateSize)throw new ei("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=null!=t.returnSequences&&t.returnSequences,this.returnState=null!=t.returnState&&t.returnState,this.goBackwards=null!=t.goBackwards&&t.goBackwards,this._stateful=null!=t.stateful&&t.stateful,this.unroll=null!=t.unroll&&t.unroll,this.supportsMasking=!0,this.inputSpec=[new Ur({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(null==this.states_){return Gi(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map((t=>null))}return this.states_}setStates(t){this.states_=t}computeOutputShape(t){Lr(t)&&(t=t[0]);let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const s=e[0];let n;if(n=this.returnSequences?[t[0],t[1],s]:[t[0],s],this.returnState){const s=[];for(const n of e)s.push([t[0],n]);return[n].concat(s)}return n}computeMask(t,e){return h.tidy((()=>{Array.isArray(e)&&(e=e[0]);const t=this.returnSequences?e:null;if(this.returnState){const e=this.states.map((t=>null));return[t].concat(e)}return t}))}get states(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let s=0;s<t;++s)e.push(null);return e}return this.states_}set states(t){this.states_=t}build(t){if(null!=this.numConstants)throw new si("Constants support is not implemented in RNN yet.");Lr(t)&&(t=t[0]);const e=this.stateful?t[0]:null,s=t.slice(2);this.inputSpec[0]=new Ur({shape:[e,null,...s]});const n=[t[0]].concat(t.slice(2));let i;if(this.cell.build(n),i=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!h.util.arraysEqual(this.stateSpec.map((t=>t.shape[t.shape.length-1])),i))throw new ei(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=i.map((t=>new Ur({shape:[null,t]})));this.stateful&&this.resetStates()}resetStates(t){let e=arguments.length>1&&void 0!==arguments[1]&&arguments[1];(0,h.tidy)((()=>{if(!this.stateful)throw new Qn("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape[0];if(null==s)throw new ei("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>h.zeros([s,t]))):this.states_=[h.zeros([s,this.cell.stateSize])];else if(null==t)h.dispose(this.states_),null!=this.keptStates&&(h.dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>h.zeros([s,t]))):this.states_[0]=h.zeros([s,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new ei(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);!0===e?this.keptStates.push(this.states_.slice()):h.dispose(this.states_);for(let e=0;e<this.states_.length;++e){const n=t[e],i=Array.isArray(this.cell.stateSize)?this.cell.stateSize[e]:this.cell.stateSize,r=[s,i];if(!h.util.arraysEqual(n.shape,r))throw new ei(`State ${e} is incompatible with layer ${this.name}: expected shape=${r}, received shape=${n.shape}`);this.states_[e]=n}}this.states_=this.states_.map((t=>h.keep(t.clone())))}))}apply(t,e){let s=null==e?null:e.initialState,n=null==e?null:e.constants;null==e&&(e={});const i=tu(t,s,n,this.numConstants);t=i.inputs,s=i.initialState,n=i.constants;let r=[],a=[];if(null!=s){e.initialState=s,r=r.concat(s),this.stateSpec=[];for(const t of s)this.stateSpec.push(new Ur({shape:t.shape}));a=a.concat(this.stateSpec)}null!=n&&(e.constants=n,r=r.concat(n),this.numConstants=n.length);if(r[0]instanceof jr){const s=[t].concat(r),n=this.inputSpec.concat(a),i=this.inputSpec;this.inputSpec=n;const o=super.apply(s,e);return this.inputSpec=i,o}return super.apply(t,e)}call(t,e){return(0,h.tidy)((()=>{const s=null==e?null:e.mask,n=null==e?null:e.training;let i=null==e?null:e.initialState;t=$r(t),null==i&&(i=this.stateful?this.states_:this.getInitialState(t));const r=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(i.length!==r)throw new ei(`RNN Layer has ${r} state(s) but was passed ${i.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const a={training:n},o=eu(((t,e)=>{const s=this.cell.call([t].concat(e),a);return[s[0],s.slice(1)]}),t,i,this.goBackwards,s,null,this.unroll,this.returnSequences),l=o[0],u=o[1],h=o[2];this.stateful&&this.resetStates(h,n);const c=this.returnSequences?u:l;return this.returnState?[c].concat(h):c}))}getInitialState(t){return(0,h.tidy)((()=>{let e=h.zeros(t.shape);return e=h.sum(e,[1,2]),e=Zi(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map((t=>t>1?sr(e,[1,t]):e)):this.cell.stateSize>1?[sr(e,[1,this.cell.stateSize])]:[e]}))}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(e.numConstants=this.numConstants);const s=this.cell.getConfig();return this.getClassName()===su.className&&(e.cell={className:this.cell.getClassName(),config:s}),Object.assign(Object.assign(Object.assign({},s),t),e)}static fromConfig(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};const n=Va(e.cell,s);return new t(Object.assign(e,{cell:n}))}}su.className="RNN",h.serialization.registerClass(su);class nu extends Hr{}class iu extends nu{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,ki(this.units,"units"),this.activation=vl(null==t.activation?this.DEFAULT_ACTIVATION:t.activation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=Fr(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=Fr(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=Fr(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=Cl(t.kernelRegularizer),this.recurrentRegularizer=Cl(t.recurrentRegularizer),this.biasRegularizer=Cl(t.biasRegularizer),this.kernelConstraint=da(t.kernelConstraint),this.recurrentConstraint=da(t.recurrentConstraint),this.biasConstraint=da(t.biasConstraint),this.dropout=Vi([1,qi([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=Vi([1,qi([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=Mr(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return(0,h.tidy)((()=>{if(2!==t.length)throw new ei(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let s=t[1];t=t[0];const n=null!=e.training&&e.training;let i;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=cu({ones:()=>h.onesLike(t),rate:this.dropout,training:n,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=cu({ones:()=>h.onesLike(s),rate:this.recurrentDropout,training:n,dropoutFunc:this.dropoutFunc}));const r=this.dropoutMask,a=this.recurrentDropoutMask;i=ir(null!=r?h.mul(t,r):t,this.kernel.read()),null!=this.bias&&(i=lr(i,this.bias.read())),null!=a&&(s=h.mul(s,a));let o=h.add(i,ir(s,this.recurrentKernel.read()));return null!=this.activation&&(o=this.activation.apply(o)),[o,o]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:wl(this.activation),useBias:this.useBias,kernelInitializer:Er(this.kernelInitializer),recurrentInitializer:Er(this.recurrentInitializer),biasInitializer:Er(this.biasInitializer),kernelRegularizer:zl(this.kernelRegularizer),recurrentRegularizer:zl(this.recurrentRegularizer),biasRegularizer:zl(this.biasRegularizer),activityRegularizer:zl(this.activityRegularizer),kernelConstraint:ca(this.kernelConstraint),recurrentConstraint:ca(this.recurrentConstraint),biasConstraint:ca(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign(Object.assign({},t),e)}}iu.className="SimpleRNNCell",h.serialization.registerClass(iu);class ru extends su{constructor(t){t.cell=new iu(t),super(t)}call(t,e){return(0,h.tidy)((()=>{null!=this.cell.dropoutMask&&(h.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(h.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const s=null==e?null:e.mask,n=null==e?null:e.training,i=null==e?null:e.initialState;return super.call(t,{mask:s,training:n,initialState:i})}))}static fromConfig(t,e){return new t(e)}}ru.className="SimpleRNN",h.serialization.registerClass(ru);class au extends nu{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new ei("GRUCell does not support reset_after parameter set to true.");this.units=t.units,ki(this.units,"units"),this.activation=vl(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=vl(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=Fr(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=Fr(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=Fr(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=Cl(t.kernelRegularizer),this.recurrentRegularizer=Cl(t.recurrentRegularizer),this.biasRegularizer=Cl(t.biasRegularizer),this.kernelConstraint=da(t.kernelConstraint),this.recurrentConstraint=da(t.recurrentConstraint),this.biasConstraint=da(t.biasConstraint),this.dropout=Vi([1,qi([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=Vi([1,qi([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){const e=(t=Mr(t))[t.length-1];this.kernel=this.addWeight("kernel",[e,3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return(0,h.tidy)((()=>{if(2!==t.length)throw new ei(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);const s=null!=e.training&&e.training;let n=t[1];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=cu({ones:()=>h.onesLike(t),rate:this.dropout,training:s,count:3,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=cu({ones:()=>h.onesLike(n),rate:this.recurrentDropout,training:s,count:3,dropoutFunc:this.dropoutFunc}));const i=this.dropoutMask,r=this.recurrentDropoutMask;let a,o,l;0<this.dropout&&this.dropout<1&&(t=h.mul(t,i[0]));let u=ir(t,this.kernel.read());this.useBias&&(u=lr(u,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(n=h.mul(n,r[0]));const c=this.recurrentKernel.read(),[p,d]=h.split(c,[2*this.units,this.units],c.rank-1),f=ir(n,p),[g,m,y]=h.split(u,3,u.rank-1),[w,b]=h.split(f,2,f.rank-1);a=this.recurrentActivation.apply(h.add(g,w)),o=this.recurrentActivation.apply(h.add(m,b));const v=ir(h.mul(o,n),d);l=this.activation.apply(h.add(y,v));const k=h.add(h.mul(a,n),h.mul(h.add(1,h.neg(a)),l));return[k,k]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:wl(this.activation),recurrentActivation:wl(this.recurrentActivation),useBias:this.useBias,kernelInitializer:Er(this.kernelInitializer),recurrentInitializer:Er(this.recurrentInitializer),biasInitializer:Er(this.biasInitializer),kernelRegularizer:zl(this.kernelRegularizer),recurrentRegularizer:zl(this.recurrentRegularizer),biasRegularizer:zl(this.biasRegularizer),activityRegularizer:zl(this.activityRegularizer),kernelConstraint:ca(this.kernelConstraint),recurrentConstraint:ca(this.recurrentConstraint),biasConstraint:ca(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign(Object.assign({},t),e)}}au.className="GRUCell",h.serialization.registerClass(au);class ou extends su{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new au(t),super(t)}call(t,e){return(0,h.tidy)((()=>{null!=this.cell.dropoutMask&&(h.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(h.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const s=null==e?null:e.mask,n=null==e?null:e.training,i=null==e?null:e.initialState;return super.call(t,{mask:s,training:n,initialState:i})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}ou.className="GRU",h.serialization.registerClass(ou);class lu extends nu{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,ki(this.units,"units"),this.activation=vl(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=vl(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=Fr(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=Fr(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=Fr(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=Cl(t.kernelRegularizer),this.recurrentRegularizer=Cl(t.recurrentRegularizer),this.biasRegularizer=Cl(t.biasRegularizer),this.kernelConstraint=da(t.kernelConstraint),this.recurrentConstraint=da(t.recurrentConstraint),this.biasConstraint=da(t.biasConstraint),this.dropout=Vi([1,qi([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=Vi([1,qi([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;const s=(t=Mr(t))[t.length-1];let n;if(this.kernel=this.addWeight("kernel",[s,4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const t=this.biasInitializer,s=this.units;n=new((e=class extends dr{apply(e,n){const i=t.apply([s]),r=(new gr).apply([s]),a=t.apply([2*s]);return er(er(i,r),a)}}).className="CustomInit",e)}else n=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,n,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return(0,h.tidy)((()=>{const s=null!=e.training&&e.training;if(3!==t.length)throw new ei(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);let n=t[1];const i=t[2];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=cu({ones:()=>h.onesLike(t),rate:this.dropout,training:s,count:4,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=cu({ones:()=>h.onesLike(n),rate:this.recurrentDropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const r=this.dropoutMask,a=this.recurrentDropoutMask;let o,l,u,c;0<this.dropout&&this.dropout<1&&(t=h.mul(t,r[0]));let p=ir(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(n=h.mul(n,a[0])),p=h.add(p,ir(n,this.recurrentKernel.read())),this.useBias&&(p=lr(p,this.bias.read()));const[d,f,g,m]=h.split(p,4,p.rank-1);o=this.recurrentActivation.apply(d),l=this.recurrentActivation.apply(f),u=h.add(h.mul(l,i),h.mul(o,this.activation.apply(g))),c=this.recurrentActivation.apply(m);const y=h.mul(c,this.activation.apply(u));return[y,y,u]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:wl(this.activation),recurrentActivation:wl(this.recurrentActivation),useBias:this.useBias,kernelInitializer:Er(this.kernelInitializer),recurrentInitializer:Er(this.recurrentInitializer),biasInitializer:Er(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:zl(this.kernelRegularizer),recurrentRegularizer:zl(this.recurrentRegularizer),biasRegularizer:zl(this.biasRegularizer),activityRegularizer:zl(this.activityRegularizer),kernelConstraint:ca(this.kernelConstraint),recurrentConstraint:ca(this.recurrentConstraint),biasConstraint:ca(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign(Object.assign({},t),e)}}lu.className="LSTMCell",h.serialization.registerClass(lu);class uu extends su{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new lu(t),super(t)}call(t,e){return(0,h.tidy)((()=>{null!=this.cell.dropoutMask&&(h.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(h.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const s=null==e?null:e.mask,n=null==e?null:e.training,i=null==e?null:e.initialState;return super.call(t,{mask:s,training:n,initialState:i})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}uu.className="LSTM",h.serialization.registerClass(uu);class hu extends nu{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return(0,h.tidy)((()=>{let s=t.slice(1);const n=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?n.push(s.splice(0,t.stateSize.length)):n.push(s.splice(0,1));n.reverse();const i=[];let r;for(let a=0;a<this.cells.length;++a){const o=this.cells[a];s=n[a],r=0===a?[t[0]].concat(s):[r[0]].concat(s),r=o.call(r,e),i.push(r.slice(1))}s=[];for(const t of i.slice().reverse())s.push(...t);return[r[0]].concat(s)}))}build(t){let e;Lr(t)&&(t=t[0]),this.cells.forEach(((s,n)=>{_i(`RNNCell_${n}`,(()=>{s.build(t),e=Array.isArray(s.stateSize)?s.stateSize[0]:s.stateSize,t=[t[0],e]}))})),this.built=!0}getConfig(){const t=super.getConfig(),e={cells:this.cells.map((t=>({className:t.getClassName(),config:t.getConfig()})))};return Object.assign(Object.assign({},t),e)}static fromConfig(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};const n=[];for(const i of e.cells)n.push(Va(i,s));return new t({cells:n})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return Pr(t)}setWeights(t){const e=[];for(const s of this.cells){const n=s.weights.length,i=t.splice(n);for(let t=0;t<s.weights.length;++t)e.push([s.weights[t],i[t]])}Wr(e)}}function cu(t){const{ones:e,rate:s,training:n=!1,count:i=1,dropoutFunc:r}=t,a=()=>null!=r?r(e(),s):ur(e(),s),o=()=>hr(a,e,n);if(!i||i<=1)return h.keep(o().clone());return Array(i).fill(void 0).map(o).map((t=>h.keep(t.clone())))}hu.className="StackedRNNCells",h.serialization.registerClass(hu);var pu=function(t,e){var s={};for(var n in t)Object.prototype.hasOwnProperty.call(t,n)&&e.indexOf(n)<0&&(s[n]=t[n]);if(null!=t&&"function"===typeof Object.getOwnPropertySymbols){var i=0;for(n=Object.getOwnPropertySymbols(t);i<n.length;i++)e.indexOf(n[i])<0&&Object.prototype.propertyIsEnumerable.call(t,n[i])&&(s[n[i]]=t[n[i]])}return s};class du extends su{constructor(t){if(t.unroll)throw new si("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new si("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new Ur({ndim:5})]}call(t,e){return h.tidy((()=>{if(null!=this.cell.dropoutMask&&(h.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(h.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new ei("ConvRNN2D cell does not support constants");const s=null==e?null:e.mask,n=null==e?null:e.training,i=null==e?null:e.initialState;return super.call(t,{mask:s,training:n,initialState:i})}))}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return h.tidy((()=>{const{stateSize:e}=this.cell,s=t.shape,n=this.computeSingleOutputShape(s),i=[n[0],...n.slice(2)],r=h.zeros(i);return Array.isArray(e)?Array(e.length).fill(r):[r]}))}resetStates(t){let e=arguments.length>1&&void 0!==arguments[1]&&arguments[1];h.tidy((()=>{if(!this.stateful)throw new Qn("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape,n=this.computeSingleOutputShape(s),i=[n[0],...n.slice(2)];if(null==s[0])throw new ei("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>h.zeros(i))):this.states_=[h.zeros(i)];else if(null==t)h.dispose(this.states_),null!=this.keptStates&&(h.dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>h.zeros(i))):this.states_[0]=h.zeros(i);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new ei(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e?this.keptStates.push(this.states_.slice()):h.dispose(this.states_);for(let e=0;e<this.states_.length;++e){const s=t[e],n=i;if(!h.util.arraysEqual(s.shape,n))throw new ei(`State ${e} is incompatible with layer ${this.name}: expected shape=${n}, received shape=${s.shape}`);this.states_[e]=s}}this.states_=this.states_.map((t=>h.keep(t.clone())))}))}computeSingleOutputShape(t){const{dataFormat:e,filters:s,kernelSize:n,padding:i,strides:r,dilationRate:a}=this.cell,o="channelsFirst"===e,l=t[o?3:2],u=t[o?4:3],h=$l(l,n[0],i,r[0],a[0]),c=$l(u,n[1],i,r[1],a[1]);return[...t.slice(0,2),...o?[s,h,c]:[h,c,s]]}}du.className="ConvRNN2D";class fu extends lu{constructor(t){const{filters:e,kernelSize:s,strides:n,padding:i,dataFormat:r,dilationRate:a}=t;super(Object.assign(Object.assign({},t),{units:e})),this.filters=e,ki(this.filters,"filters"),this.kernelSize=Rl(s,2,"kernelSize"),this.kernelSize.forEach((t=>ki(t,"kernelSize"))),this.strides=Rl(n||1,2,"strides"),this.strides.forEach((t=>ki(t,"strides"))),this.padding=i||"valid",$i(this.padding),this.dataFormat=r||"channelsLast",Ri(this.dataFormat),this.dilationRate=Rl(a||1,2,"dilationRate"),this.dilationRate.forEach((t=>ki(t,"dilationRate")))}build(t){var e;t=Mr(t);const s="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[s])throw new ei(`The channel dimension of the input should be defined. Found ${t[s]}`);const n=t[s],i=this.kernelSize.concat([n,4*this.filters]);this.kernel=this.addWeight("kernel",i,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const r=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",r,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let t;if(this.unitForgetBias){const s=this.biasInitializer,n=this.filters;t=new((e=class extends dr{apply(t,e){return tr([s.apply([n]),h.ones([n]),s.apply([2*n])])}}).className="CustomInit",e)}else t=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,t,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return h.tidy((()=>{if(3!==t.length)throw new ei(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const s=e.training||!1,n=t[0],i=t[1],r=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=cu({ones:()=>h.onesLike(n),rate:this.dropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const a=this.dropoutMask,o=(t,e,s)=>e&&e[s]?h.mul(e[s],t):t;let l=o(n,a,0),u=o(n,a,1),c=o(n,a,2),p=o(n,a,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=cu({ones:()=>h.onesLike(i),rate:this.recurrentDropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const d=this.recurrentDropoutMask;let f=o(i,d,0),g=o(i,d,1),m=o(i,d,2),y=o(i,d,3);const[w,b,v,k]=h.split(this.kernel.read(),4,3),[S,x,N,z]=this.useBias?h.split(this.bias.read(),4):[null,null,null,null];l=this.inputConv(l,w,S,this.padding),u=this.inputConv(u,b,x,this.padding),c=this.inputConv(c,v,N,this.padding),p=this.inputConv(p,k,z,this.padding);const[A,C,I,T]=h.split(this.recurrentKernel.read(),4,3);f=this.recurrentConv(f,A),g=this.recurrentConv(g,C),m=this.recurrentConv(m,I),y=this.recurrentConv(y,T);const D=this.recurrentActivation.apply(h.add(l,f)),E=this.recurrentActivation.apply(h.add(u,g)),F=h.add(h.mul(E,r),h.mul(D,this.activation.apply(h.add(c,m)))),L=h.mul(this.recurrentActivation.apply(h.add(p,y)),this.activation.apply(F));return[L,L,F]}))}getConfig(){const t=super.getConfig(),{units:e}=t,s=pu(t,["units"]),n={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},s),n)}inputConv(t,e,s,n){const i=h.conv2d(t,e,this.strides,n||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return s?lr(i,s,this.dataFormat):i}recurrentConv(t,e){return h.conv2d(t,e,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}fu.className="ConvLSTM2DCell",h.serialization.registerClass(fu);class gu extends du{constructor(t){const e=new fu(t);super(Object.assign(Object.assign({},t),{cell:e}))}static fromConfig(t,e){return new t(e)}}gu.className="ConvLSTM2D",h.serialization.registerClass(gu);class mu extends Hr{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(null==this.noiseShape)return this.noiseShape;const e=t.shape,s=[];for(let n=0;n<this.noiseShape.length;++n)s.push(null==this.noiseShape[n]?e[n]:this.noiseShape[n]);return s}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t);if(0<this.rate&&this.rate<1){const t=null!=e.training&&e.training,n=this.getNoiseShape(s);return hr((()=>ur(s,this.rate,n,this.seed)),(()=>s),t)}return t}))}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},e=super.getConfig();return Object.assign(t,e),t}dispose(){return super.dispose()}}mu.className="Dropout",h.serialization.registerClass(mu);class yu extends mu{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}yu.className="SpatialDropout1D",h.serialization.registerClass(yu);class wu extends Hr{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==t.batchInputShape&&null==t.inputShape&&null!=t.inputDim){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,ki(this.units,"units"),this.activation=vl(t.activation),null!=t.useBias&&(this.useBias=t.useBias),this.kernelInitializer=Fr(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=Fr(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=da(t.kernelConstraint),this.biasConstraint=da(t.biasConstraint),this.kernelRegularizer=Cl(t.kernelRegularizer),this.biasRegularizer=Cl(t.biasRegularizer),this.activityRegularizer=Cl(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){const e=(t=Mr(t))[t.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){const e=(t=Mr(t)).slice();return e[e.length-1]=this.units,e}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t),n=xi(this.activation.getClassName());let i;return null!=n?i=ir(s,this.kernel.read(),n,this.bias?this.bias.read():null):(i=ir(s,this.kernel.read()),null!=this.bias&&(i=lr(i,this.bias.read())),null!=this.activation&&(i=this.activation.apply(i))),i}))}getConfig(){const t={units:this.units,activation:wl(this.activation),useBias:this.useBias,kernelInitializer:Er(this.kernelInitializer),biasInitializer:Er(this.biasInitializer),kernelRegularizer:zl(this.kernelRegularizer),biasRegularizer:zl(this.biasRegularizer),activityRegularizer:zl(this.activityRegularizer),kernelConstraint:ca(this.kernelConstraint),biasConstraint:ca(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}wu.className="Dense",h.serialization.registerClass(wu);class bu extends Hr{constructor(t){super(t=t||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=Mr(t);for(const e of t.slice(1))if(null==e)throw new ei(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],ji(t,1)]}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);let s=$r(t);if("channelsFirst"===this.dataFormat&&s.rank>1){const t=[0];for(let e=2;e<s.rank;++e)t.push(e);t.push(1),s=(0,h.transpose)(s,t)}return function(t){if(t.rank<=1)throw new ei(`batchFlatten requires a minimum rank of 2. Got rank: ${t.rank}.`);const e=[t.shape[0],ji(t.shape,1)];return h.reshape(t,e)}(s)}))}getConfig(){const t={};null!=this.dataFormat&&(t.dataFormat=this.dataFormat);const e=super.getConfig();return Object.assign(t,e),t}}bu.className="Flatten",h.serialization.registerClass(bu);class vu extends Hr{constructor(t){super(t),this.supportsMasking=!0,this.activation=vl(t.activation)}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t);return this.activation.apply(s)}))}getConfig(){const t={activation:wl(this.activation)},e=super.getConfig();return Object.assign(t,e),t}}vu.className="Activation",h.serialization.registerClass(vu);class ku extends Hr{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return(0,h.tidy)((()=>{return t=$r(t),e=t,s=this.n,(0,h.tidy)((()=>{if(2!==e.shape.length)throw new ei(`repeat() expects a rank-2 tensor, but received a rank-${e.shape.length} tensor.`);return sr(Zi(e,1),[1,s,1])}));var e,s}))}getConfig(){const t={n:this.n},e=super.getConfig();return Object.assign(t,e),t}}ku.className="RepeatVector",h.serialization.registerClass(ku);class Su extends Hr{constructor(t){super(t),this.targetShape=t.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(t){return t<0||null==t}fixUnknownDimension(t,e){const s="Total size of new array must be unchanged.",n=e.slice();let i=1,r=null;for(let o=0;o<n.length;++o){const t=n[o];if(this.isUnknown(t)){if(null!==r)throw new ei("Can only specifiy one unknown dimension.");r=o}else i*=t}const a=ji(t);if(null!==r){if(0===i||a%i!==0)throw new ei(s);n[r]=a/i}else if(a!==i)throw new ei(s);return n}computeOutputShape(t){let e=!1;for(let s=0;s<t.length;++s)if(this.isUnknown(t[s])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t),n=s.shape,i=n.slice(0,1).concat(this.fixUnknownDimension(n.slice(1),this.targetShape));return(0,h.reshape)(s,i)}))}getConfig(){const t={targetShape:this.targetShape},e=super.getConfig();return Object.assign(t,e),t}}Su.className="Reshape",h.serialization.registerClass(Su);class xu extends Hr{constructor(t){if(super(t),null==t.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);const e=Gi(1,t.dims.length+1);if(!h.util.arraysEqual(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new Ur({ndim:this.dims.length+1})]}computeOutputShape(t){const e=(t=Mr(t)).slice();return this.dims.forEach(((s,n)=>{e[n+1]=t[s]})),e}call(t,e){return(0,h.transpose)($r(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},e=super.getConfig();return Object.assign(t,e),t}}xu.className="Permute",h.serialization.registerClass(xu);class Nu extends Hr{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,this.maskValue=null!=t?null==t.maskValue?0:t.maskValue:0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return Object.assign(e,t),e}computeMask(t,e){const s=$r(t);return(0,h.any)((0,h.notEqual)(s,this.maskValue),-1)}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t),n=(0,h.any)((0,h.notEqual)(s,this.maskValue),-1,!0);return(0,h.mul)(s,(0,h.cast)(n,s.dtype))}))}}Nu.className="Masking",h.serialization.registerClass(Nu);class zu extends Hr{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==t.batchInputShape&&null==t.inputShape){let e=null;null!=t.batchSize&&(e=t.batchSize),null==t.inputLength?this.batchInputShape=[e,null]:this.batchInputShape=[e].concat(ui(t.inputLength))}this.inputDim=t.inputDim,ki(this.inputDim,"inputDim"),this.outputDim=t.outputDim,ki(this.outputDim,"outputDim"),this.embeddingsInitializer=Fr(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=Cl(t.embeddingsRegularizer),this.activityRegularizer=Cl(t.activityRegularizer),this.embeddingsConstraint=da(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return(0,h.tidy)((()=>this.maskZero?(t=$r(t),(0,h.notEqual)(t,(0,h.zerosLike)(t))):null))}computeOutputShape(t){if(t=Mr(t),null==this.inputLength)return[...t,this.outputDim];const e=ui(this.inputLength);if(e.length!==t.length-1)throw new ei(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);{let s=0;for(let n=0;n<e.length;++n){const i=e[n],r=t[n+1];if(null!=i&&null!=r&&i!==r)throw new ei(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);null==i&&(e[s]=r),s++}}return[t[0],...e,this.outputDim]}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);let s=$r(t);"int32"!==s.dtype&&(s=Ji(s,"int32"));const n=rr(this.embeddings.read(),(0,h.reshape)(s,[s.size]));return(0,h.reshape)(n,Mr(this.computeOutputShape(s.shape)))}))}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:Er(this.embeddingsInitializer),embeddingsRegularizer:zl(this.embeddingsRegularizer),activityRegularizer:zl(this.activityRegularizer),embeddingsConstraint:ca(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}zu.className="Embedding",h.serialization.registerClass(zu);class Au extends Hr{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new si}computeElementwiseOpOutputShape(t,e){if(null==t||null==e)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(0===e.length)return t;const s=t.slice(0,t.length-e.length);for(let n=0;n<e.length;++n){const i=t[t.length-e.length+n],r=e[n];if(null==i||null==r||i<0||r<0)s.push(null);else if(1===i)s.push(r);else if(1===r)s.push(i);else{if(i!==r)throw new ei("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));s.push(i)}}return s}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[Mr(t)]),t.length<2)throw new ei(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const i of t)null!=i&&null!==i[0]&&e.push(i[0]);if(e=yi(e),e.length>1)throw new ei(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let s=null==t[0]?null:t[0].slice(1);for(let i=1;i<t.length;++i){const e=null==t[i]?null:t[i].slice(1);s=this.computeElementwiseOpOutputShape(s,e)}const n=t.map((t=>t.length));-1===t.indexOf(null)&&1===yi(n).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(t,e){return(0,h.tidy)((()=>{if(this.reshapeRequired){const e=[],s=t.map((t=>t.rank));if(-1===s.indexOf(null)){const n=qi(s);for(let s of t){const t=s.rank;for(let e=0;e<n-t;++e)s=Zi(s,1);e.push(s)}return this.mergeFunction(e)}{let s=!1;for(const r of t){const t=r.rank;if(null==t){const t=r.shape,n=t[0],i=t.slice(1).concat([n]);let a=h.reshape(r,[n].concat(ji(t.slice(1))));a=h.transpose(a,[1,0]),a=h.reshape(a,i),e.push(a),s=!0}else if(t>1){const n=Gi(1,t).concat([0]);e.push(h.transpose(r,n)),s=!0}else e.push(r)}let n=this.mergeFunction(e);const i=n.rank;if(s)if(null==i){const t=n.shape,e=t[t.length-1],s=[e].concat(t.slice(0,t.length-1));n=h.reshape(h.transpose(h.reshape(n,[-1,e]),[1,0]),s)}else if(i>1){const t=[i-1].concat(Gi(0,i-1));n=h.transpose(n,t)}return n}}return this.mergeFunction(t)}))}computeOutputShape(t){let e;e=null==t[0]?null:t[0].slice(1);for(let n=1;n<t.length;++n){const s=null==t[n]?null:t[n].slice(1);e=this.computeElementwiseOpOutputShape(e,s)}let s=[];for(const n of t)null!=n&&null!==n[0]&&s.push(n[0]);return s=yi(s),e=1===s.length?s.concat(e):[null].concat(e),e}computeMask(t,e){return h.tidy((()=>{if(null==e)return null;if(!Array.isArray(e))throw new ei("`mask` should be an Array");if(!Array.isArray(t))throw new ei("`inputs` should be an Array");if(e.length!==t.length)throw new ei(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every((t=>null==t)))return null;let s=(e=e.map((t=>null==t?t:h.expandDims(t,0))))[0];for(let t=1;t<e.length-1;++t)s=h.logicalAnd(s,e[t]);return s}))}}class Cu extends Au{constructor(t){super(t)}mergeFunction(t){return(0,h.tidy)((()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=h.add(e,t[s]);return e}))}}Cu.className="Add",h.serialization.registerClass(Cu);class Iu extends Au{constructor(t){super(t)}mergeFunction(t){return(0,h.tidy)((()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=h.mul(e,t[s]);return e}))}}Iu.className="Multiply",h.serialization.registerClass(Iu);class Tu extends Au{constructor(t){super(t)}mergeFunction(t){return(0,h.tidy)((()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=h.add(e,t[s]);return h.mul(1/t.length,e)}))}}Tu.className="Average",h.serialization.registerClass(Tu);class Du extends Au{constructor(t){super(t)}mergeFunction(t){return(0,h.tidy)((()=>{let e=t[0];for(let s=1;s<t.length;++s)e=h.maximum(e,t[s]);return e}))}}Du.className="Maximum",h.serialization.registerClass(Du);class Eu extends Au{constructor(t){super(t)}mergeFunction(t){return(0,h.tidy)((()=>{let e=t[0];for(let s=1;s<t.length;++s)e=h.minimum(e,t[s]);return e}))}}Eu.className="Minimum",h.serialization.registerClass(Eu);class Fu extends Au{constructor(t){super(t),this.DEFAULT_AXIS=-1,null==t&&(t={}),this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new ei("A `Concatenate` layer should be called on a list of at least 2 inputs");let e=!0;for(const n of t)if(null!=n){e=!1;break}if(e)return;const s=[];for(let n=0;n<t.length;++n){const e=t[n].slice();e.splice(this.axis,1);let i=!1;for(const t of s)if(h.util.arraysEqual(t,e)){i=!0;break}i||s.push(e)}if(s.length>1)throw new ei("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return(0,h.tidy)((()=>tr(t,this.axis)))}computeOutputShape(t){if(!Array.isArray(t)||!Array.isArray(t[0]))throw new ei("A `Concatenate` layer should be called on a list of inputs.");const e=t,s=e[0].slice(),n=this.axis<0?s.length+this.axis:this.axis;for(const i of e.slice(1)){if(null==s[n]||null==i[n]){s[n]=null;break}s[n]+=i[n]}return s}computeMask(t,e){if(null==e)return null;if(!Array.isArray(e))throw new ei("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new ei("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new ei(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return h.tidy((()=>{let s=!0;if(e.forEach((t=>{null==t||(s=!1)})),s)return null;const n=[];for(let r=0;r<t.length;++r)null==e[r]?n.push(h.cast(h.onesLike(t[r]),"bool")):e[r].rank<t[r].rank?n.push(h.expandDims(e[r],-1)):n.push(e[r]);const i=h.concat(n,this.axis);return h.all(i,-1,!1)}))}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function Lu(t,e){for(;t<0;)t+=e;return t}Fu.className="Concatenate",h.serialization.registerClass(Fu);class Ru extends Au{constructor(t){super(t),this.axes=t.axes,this.normalize=null!=t.normalize&&t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){h.util.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0],s=t[1];if(e.length>3||s.length>3)throw new si("Dot layer does not support tensors of 4D or higher rank yet.");const n=this.interpretAxes(e,s);if(e[n[0]]!==s[n[1]])throw new ei(`Dimension incompatibility: ${e[n[0]]} !== ${s[n[1]]}`)}mergeFunction(t){if(2!==t.length)throw new ei(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e,s=t[0],n=t[1];return e=Array.isArray(this.axes)?this.axes.map(((e,s)=>Lu(e,t[s].shape.length))):[Lu(this.axes,s.shape.length),Lu(this.axes,n.shape.length)],this.normalize&&(s=qa(s,e[0]),n=qa(n,e[1])),function(t,e,s){if(t.shape.length>3||e.shape.length>3)throw new si("batchDot is not implemented for tensors of 4D or higher rank yet");if(h.util.assert(t.shape.length>=2,(()=>`batchDot requires the rank of x to be >= 2, but got ${t.shape.length}`)),h.util.assert(t.shape.length>=2,(()=>`batchDot requires the rank of y to be >= 2, but got ${e.shape.length}`)),"number"===typeof s&&(s=[s,s]),"complex64"===t.dtype||"complex64"===e.dtype)throw new si("batchDot is not implemented for complex64-type Tensors yet.");const n=t.shape.length,i=e.shape.length;null==s&&(s=[n-1,i-2]);const r=s;return h.tidy((()=>{let s,a;if(n>i){s=n-i;const t=[];for(let e=0;e<s;++e)t.push(1);e=h.reshape(e,e.shape.concat(t))}else if(i>n){s=i-n;const e=[];for(let t=0;t<s;++t)e.push(1);t=h.reshape(t,t.shape.concat(e))}else s=0;if(2===t.shape.length&&2===e.shape.length)a=r[0]===r[1]?h.sum(h.mul(t,e),r[0]):h.sum(h.mul(h.transpose(t,[1,0]),e),r[1]);else{const s=r[0]!==t.shape.length-1,n=r[1]===e.shape.length-1;a=h.matMul(t,e,s,n)}if(s>0){let t;t=n>i?n+i-3:n-1;const e=[];for(let n=t;n<t+s;++n)e.push(n);a=h.squeeze(a,e)}return 1===a.shape.length&&(a=h.expandDims(a,1)),a}))}(s,n,e)}interpretAxes(t,e){let s;return s=Array.isArray(this.axes)?this.axes:[Lu(this.axes,t.length),Lu(this.axes,e.length)],s}computeOutputShape(t){h.util.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0].slice(),s=t[1].slice();if(e.length>3||s.length>3)throw new si("Dot layer does not support tensors of 4D or higher rank yet.");const n=this.interpretAxes(e,s);e.splice(n[0],1),s.splice(n[1],1),s.splice(0,1);const i=e.concat(s);return 1===i.length&&i.push(1),i}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}Ru.className="Dot",h.serialization.registerClass(Ru);class $u extends Hr{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t);return hr((()=>(0,h.add)(nr(s.shape,0,this.stddev),s)),(()=>s),e.training||!1)}))}}$u.className="GaussianNoise",h.serialization.registerClass($u);class Mu extends Hr{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e);const s=$r(t);if(this.rate>0&&this.rate<1){return hr((()=>{const t=Math.sqrt(this.rate/(1-this.rate));return(0,h.mul)(s,nr(s.shape,1,t))}),(()=>s),e.training||!1)}return s}))}}Mu.className="GaussianDropout",h.serialization.registerClass(Mu);class Ou extends Hr{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||$r(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return(0,h.tidy)((()=>{if(this.rate<1&&this.rate>0){const s=this._getNoiseShape(t),n=()=>{const e=$r(t),n=-1.7580993408473766;let i=(0,h.greaterEqual)((0,h.randomUniform)(s),this.rate);i=Ji(i,"float32");const r=((1-this.rate)*(1+this.rate*n**2))**-.5,a=-r*n*this.rate,o=(0,h.add)((0,h.mul)(e,i),(0,h.mul)((0,h.add)(i,-1),n));return(0,h.add)((0,h.mul)(o,r),a)};return hr(n,(()=>$r(t)),e.training||!1)}return t}))}}function _u(t,e,s,n,i){let r,a=arguments.length>5&&void 0!==arguments[5]?arguments[5]:.001;if(2===t.rank)r=h.batchNorm2d(t,e,s,n,i,a);else if(3===t.rank)r=h.batchNorm3d(t,e,s,n,i,a);else{if(4!==t.rank)throw new si(`batchNormalization is not implemented for array of rank ${t.rank} yet`);r=h.batchNorm4d(t,e,s,n,i,a)}return r}function Bu(t,e,s,n){let i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:.001;return h.util.arraysEqual(n.slice().sort(),Gi(0,t.rank-1))?function(t,e,s,n){let i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:.001;return(0,h.tidy)((()=>{const r=h.moments(t,n),a=r.mean,o=r.variance;return[_u(t,a,o,s,e,i),a,o]}))}(t,e,s,n,i):function(t,e,s,n){let i=arguments.length>4&&void 0!==arguments[4]?arguments[4]:.001;return(0,h.tidy)((()=>{const r=h.moments(t,n),a=r.mean,o=r.variance,l=[];for(const e of Gi(0,t.rank))-1!==n.indexOf(e)?l.push(1):l.push(t.shape[e]);const u=(0,h.reshape)(a,l),c=(0,h.reshape)(o,l),p=null==e?null:(0,h.reshape)(e,l),d=null==s?null:(0,h.reshape)(s,l);return[_u(t,u,c,d,p,i),a,o]}))}(t,e,s,n,i)}Ou.className="AlphaDropout",h.serialization.registerClass(Ou);class Pu extends Hr{constructor(t){null==t&&(t={}),super(t),this.supportsMasking=!0,this.axis=null==t.axis?-1:t.axis,this.momentum=null==t.momentum?.99:t.momentum,this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=Fr(t.betaInitializer||"zeros"),this.gammaInitializer=Fr(t.gammaInitializer||"ones"),this.movingMeanInitializer=Fr(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=Fr(t.movingVarianceInitializer||"ones"),this.betaConstraint=da(t.betaConstraint),this.gammaConstraint=da(t.gammaConstraint),this.betaRegularizer=Cl(t.betaRegularizer),this.gammaRegularizer=Cl(t.gammaRegularizer)}build(t){t=Mr(t);const e=this.axis>=0?this.axis:this.axis+t.length,s=t[e];if(null==s)throw new ei(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);this.inputSpec=[new Ur({ndim:t.length,axes:{[e]:s}})];const n=[s];this.scale&&(this.gamma=this.addWeight("gamma",n,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",n,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",n,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",n,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return(0,h.tidy)((()=>{const s=null!=e.training&&e.training,n=$r(t),i=n.shape,r=i.length,a=Gi(0,r),o=this.axis>=0?this.axis:this.axis+r;a.splice(o,1);const l=ri(1,r);l[o]=i[o];const u=a.slice();u.sort();const c=!h.util.arraysEqual(u,Gi(0,r).slice(0,r-1));if(!s)return(()=>{if(c){const t=(0,h.reshape)(this.movingMean.read(),l),e=(0,h.reshape)(this.movingVariance.read(),l),s=this.center?(0,h.reshape)(this.beta.read(),l):null,i=this.scale?(0,h.reshape)(this.gamma.read(),l):null;return _u(n,t,e,s,i,this.epsilon)}return _u(n,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[p,d,f]=Bu(n,this.gamma.read(),this.beta.read(),a,this.epsilon),g=(t,e,s)=>{h.tidy((()=>{const n=1-s,i=t.read(),r=h.mul(h.sub(i,e),n);t.write(h.sub(i,r))}))};return(()=>{g(this.movingMean,d,this.momentum),g(this.movingVariance,f,this.momentum)})(),p}))}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:Er(this.betaInitializer),gammaInitializer:Er(this.gammaInitializer),movingMeanInitializer:Er(this.movingMeanInitializer),movingVarianceInitializer:Er(this.movingVarianceInitializer),betaRegularizer:zl(this.betaRegularizer),gammaRegularizer:zl(this.gammaRegularizer),betaConstraint:ca(this.betaConstraint),gammaConstraint:ca(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}Pu.className="BatchNormalization",h.serialization.registerClass(Pu);class Wu extends Hr{constructor(t){if(null==t&&(t={}),super(t),this.axis=null==t.axis?-1:t.axis,"number"===typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const t of this.axis)if(!Number.isInteger(t))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=Fr(t.betaInitializer||"zeros"),this.gammaInitializer=Fr(t.gammaInitializer||"ones"),this.betaRegularizer=Cl(t.betaRegularizer),this.gammaRegularizer=Cl(t.gammaRegularizer),this.supportsMasking=!0}build(t){const e=(t=Mr(t)).length;"number"===typeof this.axis&&(this.axis=[this.axis]);for(let i=0;i<this.axis.length;++i)this.axis[i]<0&&(this.axis[i]+=e);for(const i of this.axis)if(i<0||i>=e)throw new Error(`Invalid axis: ${i}`);if(this.axis.length!==yi(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const s=this.axis.map((e=>t[e])),n=!0;this.scale?this.gamma=this.addWeight("gamma",s,"float32",this.gammaInitializer,this.gammaRegularizer,n):this.gamma=null,this.center?this.beta=this.addWeight("beta",s,"float32",this.betaInitializer,this.betaRegularizer,n):this.beta=null,this.built=!0}call(t,e){const s=$r(t),n=s.shape,i=n.length;return(0,h.tidy)((()=>{let{mean:t,variance:e}=(0,h.moments)(s,this.axis,!0);const r=ri(1,i);for(const s of this.axis)r[s]=n[s];const a=t=>null!=t&&t.shape.length!==i?h.reshape(t,r):t;let o=this.scale?a(this.gamma.read()):null,l=this.center?a(this.beta.read()):null;const u=[],c=[];for(let s=0;s<i;++s)-1!==this.axis.indexOf(s)?(u.push(n[s]),c.push(1)):(u.push(1),c.push(n[s]));return t=h.tile(t,u),e=h.tile(e,u),null!=o&&(o=h.tile(o,c)),null!=l&&(l=h.tile(l,c)),_u(s,t,e,l,o,this.epsilon)}))}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:Er(this.betaInitializer),gammaInitializer:Er(this.gammaInitializer),betaRegularizer:zl(this.betaRegularizer),gammaRegularizer:zl(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}Wu.className="LayerNormalization",h.serialization.registerClass(Wu);class Uu extends Hr{constructor(t){if(null==t&&(t={}),super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,null==t.padding)this.padding=[[1,1],[1,1]];else if("number"===typeof t.padding)this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,2!==t.padding.length)throw new ei(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,s;if("number"===typeof t.padding[0])e=[t.padding[0],t.padding[0]],s=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,2!==t.padding[0].length)throw new ei(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],2!==t.padding[1].length)throw new ei(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);s=t.padding[1]}this.padding=[e,s]}this.inputSpec=[new Ur({ndim:4})]}computeOutputShape(t){let e,s;return t=Mr(t),"channelsFirst"===this.dataFormat?(e=null!=t[2]&&t[2]>=0?t[2]+this.padding[0][0]+this.padding[0][1]:null,s=null!=t[3]&&t[3]>=0?t[3]+this.padding[1][0]+this.padding[1][1]:null,[t[0],t[1],e,s]):(e=null!=t[1]&&t[1]>=0?t[1]+this.padding[0][0]+this.padding[0][1]:null,s=null!=t[2]&&t[2]>=0?t[2]+this.padding[1][0]+this.padding[1][1]:null,[t[0],e,s,t[3]])}call(t,e){return(0,h.tidy)((()=>{return e=$r(t),s=this.padding,n=this.dataFormat,(0,h.tidy)((()=>{if(4!==e.rank)throw new ei(`temporalPadding expects input tensor to be 4-D, but received a ${e.rank}-D tensor.`);if(null==s&&(s=[[1,1],[1,1]]),2!==s.length||2!==s[0].length||2!==s[1].length)throw new ei("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==n&&(n="channelsLast"),"channelsLast"!==n&&"channelsFirst"!==n)throw new ei(`Unknown data format: ${n}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let t;return t="channelsFirst"===n?[[0,0],[0,0],s[0],s[1]]:[[0,0],s[0],s[1],[0,0]],h.pad(e,t)}));var e,s,n}))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}function ju(t,e,s,n,i,r){return(0,h.tidy)((()=>{let a;Ri(i),Mi(r),$i(n),null==s&&(s=[1,1]),null==n&&(n="valid"),null==i&&(i="channelsLast"),null==r&&(r="max"),t=Ol(t,i);const o="same"===n?"same":"valid";return a="max"===r?h.maxPool(t,e,s,o):h.avgPool(t,e,s,o),"channelsFirst"===i&&(a=h.transpose(a,[0,3,1,2])),a}))}function Vu(t,e,s,n,i,r){return(0,h.tidy)((()=>{let a;Ri(i),Mi(r),$i(n),null==s&&(s=[1,1,1]),null==n&&(n="valid"),null==i&&(i="channelsLast"),null==r&&(r="max"),t=_l(t,i);const o="same"===n?"same":"valid";return a="max"===r?h.maxPool3d(t,e,s,o):h.avgPool3d(t,e,s,o),"channelsFirst"===i&&(a=h.transpose(a,[0,4,1,2,3])),a}))}Uu.className="ZeroPadding2D",h.serialization.registerClass(Uu);class qu extends Hr{constructor(t){if(null==t.poolSize&&(t.poolSize=2),super(t),"number"===typeof t.poolSize)this.poolSize=[t.poolSize];else{if(!Array.isArray(t.poolSize)||1!==t.poolSize.length||"number"!==typeof t.poolSize[0])throw new ei(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);this.poolSize=t.poolSize}if(ki(this.poolSize,"poolSize"),null==t.strides)this.strides=this.poolSize;else if("number"===typeof t.strides)this.strides=[t.strides];else{if(!Array.isArray(t.strides)||1!==t.strides.length||"number"!==typeof t.strides[0])throw new ei(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);this.strides=t.strides}ki(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,$i(this.padding),this.inputSpec=[new Ur({ndim:3})]}computeOutputShape(t){const e=$l((t=Mr(t))[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return(0,h.tidy)((()=>{this.invokeCallHook(t,e),t=Zi($r(t),2);const s=this.poolingFunction($r(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return h.squeeze(s,[2])}))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides},e=super.getConfig();return Object.assign(t,e),t}}class Gu extends qu{constructor(t){super(t)}poolingFunction(t,e,s,n,i){return Ri(i),$i(n),ju(t,e,s,n,i,"max")}}Gu.className="MaxPooling1D",h.serialization.registerClass(Gu);class Hu extends qu{constructor(t){super(t)}poolingFunction(t,e,s,n,i){return Ri(i),$i(n),ju(t,e,s,n,i,"avg")}}Hu.className="AveragePooling1D",h.serialization.registerClass(Hu);class Ku extends Hr{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(2!==t.strides.length)throw new ei(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides];ki(this.poolSize,"poolSize"),ki(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Ri(this.dataFormat),$i(this.padding),this.inputSpec=[new Ur({ndim:4})]}computeOutputShape(t){t=Mr(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],s="channelsFirst"===this.dataFormat?t[3]:t[2];return e=$l(e,this.poolSize[0],this.padding,this.strides[0]),s=$l(s,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,s]:[t[0],e,s,t[3]]}call(t,e){return(0,h.tidy)((()=>(this.invokeCallHook(t,e),this.poolingFunction($r(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Ju extends Ku{constructor(t){super(t)}poolingFunction(t,e,s,n,i){return Ri(i),$i(n),ju(t,e,s,n,i,"max")}}Ju.className="MaxPooling2D",h.serialization.registerClass(Ju);class Zu extends Ku{constructor(t){super(t)}poolingFunction(t,e,s,n,i){return Ri(i),$i(n),ju(t,e,s,n,i,"avg")}}Zu.className="AveragePooling2D",h.serialization.registerClass(Zu);class Yu extends Hr{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(3!==t.strides.length)throw new ei(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];ki(this.poolSize,"poolSize"),ki(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Ri(this.dataFormat),$i(this.padding),this.inputSpec=[new Ur({ndim:5})]}computeOutputShape(t){t=Mr(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],s="channelsFirst"===this.dataFormat?t[3]:t[2],n="channelsFirst"===this.dataFormat?t[4]:t[3];return e=$l(e,this.poolSize[0],this.padding,this.strides[0]),s=$l(s,this.poolSize[1],this.padding,this.strides[1]),n=$l(n,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,s,n]:[t[0],e,s,n,t[4]]}call(t,e){return(0,h.tidy)((()=>(this.invokeCallHook(t,e),this.poolingFunction($r(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Xu extends Yu{constructor(t){super(t)}poolingFunction(t,e,s,n,i){return Ri(i),$i(n),Vu(t,e,s,n,i,"max")}}Xu.className="MaxPooling3D",h.serialization.registerClass(Xu);class Qu extends Yu{constructor(t){super(t)}poolingFunction(t,e,s,n,i){return Ri(i),$i(n),Vu(t,e,s,n,i,"avg")}}Qu.className="AveragePooling3D",h.serialization.registerClass(Qu);class th extends Hr{constructor(t){super(t),this.inputSpec=[new Ur({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new si}}class eh extends th{constructor(t){super(t||{})}call(t,e){return(0,h.tidy)((()=>{const e=$r(t);return h.mean(e,1)}))}}eh.className="GlobalAveragePooling1D",h.serialization.registerClass(eh);class sh extends th{constructor(t){super(t||{})}call(t,e){return(0,h.tidy)((()=>{const e=$r(t);return h.max(e,1)}))}}sh.className="GlobalMaxPooling1D",h.serialization.registerClass(sh);class nh extends Hr{constructor(t){super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Ri(this.dataFormat),this.inputSpec=[new Ur({ndim:4})]}computeOutputShape(t){return"channelsLast"===this.dataFormat?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new si}getConfig(){const t={dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class ih extends nh{call(t,e){return(0,h.tidy)((()=>{const e=$r(t);return"channelsLast"===this.dataFormat?h.mean(e,[1,2]):h.mean(e,[2,3])}))}}ih.className="GlobalAveragePooling2D",h.serialization.registerClass(ih);class rh extends nh{call(t,e){return(0,h.tidy)((()=>{const e=$r(t);return"channelsLast"===this.dataFormat?h.max(e,[1,2]):h.max(e,[2,3])}))}}rh.className="GlobalMaxPooling2D",h.serialization.registerClass(rh);class ah extends Hr{constructor(t){super(t),this.layer=t.layer}build(t){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(t){null!=this.layer&&(this.layer.trainable=t)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(t){this.layer.setWeights(t)}getConfig(){const t={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},e=super.getConfig();return Object.assign(t,e),t}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(t)}static fromConfig(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};const n=Va(e.layer,s);delete e.layer;const i={layer:n};return Object.assign(i,e),new t(i)}}class oh extends ah{constructor(t){super(t),this.supportsMasking=!0}build(t){if((t=Mr(t)).length<3)throw new ei(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){const e=[(t=Mr(t))[0]].concat(t.slice(2)),s=this.layer.computeOutputShape(e),n=t[1];return[s[0],n].concat(s.slice(1))}call(t,e){return(0,h.tidy)((()=>eu(((t,s)=>[$r(this.layer.call(t,e)),[]]),t=$r(t),[],!1,null,null,!1,!0)[1]))}}oh.className="TimeDistributed",h.serialization.registerClass(oh);class lh extends ah{constructor(t){super(t);const e=t.layer.getConfig(),s={};s.className=t.layer.getClassName(),s.config=e,this.forwardLayer=Va(s),e.goBackwards=!0!==e.goBackwards;const n={};var i;if(n.className=t.layer.getClassName(),n.config=e,this.backwardLayer=Va(n),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===t.mergeMode?"concat":t.mergeMode,i=this.mergeMode,bi(Fi,"BidirectionalMergeMode",i),t.weights)throw new si("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,null!=this.forwardLayer&&(this.forwardLayer.trainable=t),null!=this.backwardLayer&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const e=t.length,s=Math.floor(e/2);this.forwardLayer.setWeights(t.slice(0,s)),this.backwardLayer.setWeights(t.slice(s))}computeOutputShape(t){let e,s,n,i=this.forwardLayer.computeOutputShape(t);return Array.isArray(i)&&Array.isArray(i[0])||(i=[i]),this.returnState?(n=i.slice(1),e=i[0]):e=i[0],"concat"===this.mergeMode?(e[e.length-1]*=2,s=[e]):s=null==this.mergeMode?[e,e.slice()]:[e],this.returnState?null==this.mergeMode?s.concat(n).concat(n.slice()):[e].concat(n).concat(n.slice()):li(s)}apply(t,e){let s=null==e?null:e.initialState,n=null==e?null:e.constants;null==e&&(e={});const i=tu(t,s,n,this.numConstants);if(t=i.inputs,s=i.initialState,n=i.constants,Array.isArray(t)&&(s=t.slice(1),t=t[0]),(null==s||0===s.length)&&null==n)return super.apply(t,e);const r=[],a=[];if(null!=s){const t=s.length;if(t%2>0)throw new ei("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=s,r.push(...s);const n=s.map((t=>new Ur({shape:t.shape})));this.forwardLayer.stateSpec=n.slice(0,t/2),this.backwardLayer.stateSpec=n.slice(t/2),a.push(...n)}if(null!=n)throw new si("Support for constants in Bidirectional layers is not implemented yet.");const o=r[0]instanceof jr;for(const l of r)if(l instanceof jr!==o)throw new ei("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(o){const s=[t].concat(r),n=this.inputSpec.concat(a),i=this.inputSpec;this.inputSpec=n;const o=super.apply(s,e);return this.inputSpec=i,o}return super.apply(t,e)}call(t,e){return(0,h.tidy)((()=>{const s=e.initialState;let n,i,r,a;if(null==s)n=this.forwardLayer.call(t,e),i=this.backwardLayer.call(t,e);else{const r=s.slice(0,s.length/2),a=s.slice(s.length/2);n=this.forwardLayer.call(t,Object.assign(e,{initialState:r})),i=this.backwardLayer.call(t,Object.assign(e,{initialState:a}))}return this.returnState&&(Array.isArray(n)&&(r=n.slice(1).concat(i.slice(1))),n=n[0],i=i[0]),this.returnSequences&&(i=h.reverse(i,1)),"concat"===this.mergeMode?a=tr([n,i]):"sum"===this.mergeMode?a=h.add(n,i):"ave"===this.mergeMode?a=h.mul(.5,h.add(n,i)):"mul"===this.mergeMode?a=h.mul(n,i):null==this.mergeMode&&(a=[n,i]),this.returnState?null==this.mergeMode?a.concat(r):[a].concat(r):a}))}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){_i(this.forwardLayer.name,(()=>{this.forwardLayer.build(t)})),_i(this.backwardLayer.name,(()=>{this.backwardLayer.build(t)})),this.built=!0}computeMask(t,e){let s;if(Array.isArray(e)&&(e=e[0]),s=this.returnSequences?null==this.mergeMode?[e,e]:e:null==this.mergeMode?[null,null]:null,this.returnState){const t=this.forwardLayer.states.map((t=>null));return Array.isArray(s)?s.concat(t).concat(t):[s].concat(t).concat(t)}return s}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(t),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode},e=super.getConfig();return Object.assign(t,e),t}static fromConfig(t,e){const s=Va(e.layer);if(delete e.layer,null!=e.numConstants)throw new si("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const n=e;return n.layer=s,new t(n)}}lh.className="Bidirectional",h.serialization.registerClass(lh);class uh extends Hr{constructor(t){super(t),this.scale=t.scale,t.offset?this.offset=t.offset:this.offset=0}getConfig(){const t={scale:this.scale,offset:this.offset},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return(0,h.tidy)((()=>("float32"!==(t=$r(t)).dtype&&(t=Ji(t,"float32")),(0,h.add)((0,h.mul)(t,this.scale),this.offset))))}}uh.className="Rescaling",h.serialization.registerClass(uh);const{resizeBilinear:hh,cropAndResize:ch}=h.image;class ph extends Hr{constructor(t){super(t),this.height=t.height,this.width=t.width}centerCrop(t,e,s,n,i,r,a,o){return(0,h.tidy)((()=>{let l,u=!1;const c=[e/r,s/a,(n+e)/r,(i+s)/a],p=[];3===t.rank?(u=!0,l=(0,h.stack)([t])):l=t;for(let t=0;t<l.shape[0];t++)p.push(c);const d=(0,h.tensor)(p,[p.length,4]),f=(0,h.range)(0,p.length,1,"int32"),g=ch(l,d,f,[n,i],"nearest");return Ji(u?$r((0,h.unstack)(g)):g,o)}))}upsize(t,e,s,n){return(0,h.tidy)((()=>Ji(hh(t,[e,s]),n)))}call(t,e){return(0,h.tidy)((()=>{const e=$r(t),s=e.dtype,n=e.shape,i=n[n.length-3],r=n[n.length-2];let a=0;i!==this.height&&(a=Math.floor((i-this.height)/2));let o=0;return r!==this.width&&(o=Math.floor((r-this.width)/2),0===o&&(o=1)),a>=0&&o>=0?this.centerCrop(e,a,o,this.height,this.width,i,r,s):this.upsize(t,this.height,this.width,s)}))}getConfig(){const t={height:this.height,width:this.width},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){const e=(t=Mr(t)).length-3,s=t.length-2;return t[e]=this.height,t[s]=this.width,t}}ph.className="CenterCrop",h.serialization.registerClass(ph);class dh extends Hr{constructor(t){super(t),this.numTokens=t.numTokens,t.outputMode?this.outputMode=t.outputMode:this.outputMode="multiHot"}getConfig(){const t={numTokens:this.numTokens,outputMode:this.outputMode},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){return null==(t=Mr(t))?[this.numTokens]:"oneHot"===this.outputMode&&1!==t[t.length-1]?(t.push(this.numTokens),t):(t[t.length-1]=this.numTokens,t)}call(t,e){return(0,h.tidy)((()=>{let s;if("int32"!==(t=$r(t)).dtype&&(t=Ji(t,"int32")),"undefined"!==typeof e.countWeights){if("count"!==this.outputMode)throw new ei(`countWeights is not used when outputMode !== count.\n              Received countWeights=${e.countWeights}`);s=$r(e.countWeights)}const n=(0,h.max)(t),i=(0,h.min)(t),r=(0,h.greater)(this.numTokens,n).bufferSync().get(0),a=(0,h.greaterEqual)(i,0).bufferSync().get(0);if(!r||!a)throw new ei(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);return function(t,e,s,n){let i=$r(t);if("int32"!==i.dtype&&(i=Ji(i,"int32")),"int"===e)return i;const r=i.shape;if(0===i.rank&&(i=(0,h.expandDims)(i,-1)),"oneHot"===e&&1!==i.shape[i.shape.length-1]&&(i=(0,h.expandDims)(i,-1)),i.rank>2)throw new ei(`When outputMode is not int, maximum output rank is 2 Received outputMode ${e} and input shape ${r} which would result in output rank ${i.rank}.`);const a=["multiHot","oneHot"].includes(e),o=i;let l;if(l="undefined"!==typeof n&&"count"===e?(0,h.denseBincount)(o,n,s,a):(0,h.denseBincount)(o,[],s,a),"tfIdf"!==e)return l;if(n)return(0,h.mul)(l,n);throw new ei("When outputMode is 'tfIdf', weights must be provided.")}(t,this.outputMode,this.numTokens,s)}))}}dh.className="CategoryEncoding",h.serialization.registerClass(dh);const fh=new Set(["bilinear","nearest"]);class gh extends Hr{constructor(t){if(super(t),this.height=t.height,this.width=t.width,t.interpolation){if(!fh.has(t.interpolation))throw new ei(`Invalid interpolation parameter: ${t.interpolation} is not implemented`);this.interpolation=t.interpolation}else this.interpolation="bilinear";this.cropToAspectRatio=Boolean(t.cropToAspectRatio)}computeOutputShape(t){const e=(t=Mr(t))[2];return[this.height,this.width,e]}getConfig(){const t={height:this.height,width:this.width,interpolation:this.interpolation,cropToAspectRatio:this.cropToAspectRatio},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return(0,h.tidy)((()=>{const e=[this.height,this.width];if("bilinear"===this.interpolation)return h.image.resizeBilinear(t,e,!this.cropToAspectRatio);if("nearest"===this.interpolation)return h.image.resizeNearestNeighbor(t,e,!this.cropToAspectRatio);throw new Error(`Interpolation is ${this.interpolation} but only ${[...fh]} are supported`)}))}}gh.className="Resizing",h.serialization.registerClass(gh);class mh{constructor(t){this.seed=t}next(){if(void 0!==this.seed)return this.seed++}}mh.className="RandomSeed";class yh extends Hr{constructor(t){super(t),this.randomGenerator=new mh(t.seed)}getConfig(){const t={seed:this.randomGenerator.seed},e=super.getConfig();return Object.assign(t,e),t}}yh.className="BaseRandomLayer";const wh=new Set(["bilinear","nearest"]);class bh extends yh{constructor(t){super(t);const{factor:e,interpolation:s="bilinear"}=t;if(this.factor=e,Array.isArray(this.factor)&&2===this.factor.length)this.widthLower=this.factor[0],this.widthUpper=this.factor[1];else{if(Array.isArray(this.factor)||!(this.factor>0))throw new ei(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);this.widthLower=-this.factor,this.widthUpper=this.factor}if(this.widthLower<-1||this.widthUpper<-1)throw new ei(`factor must have values larger than -1. Got: ${this.factor}`);if(this.widthUpper<this.widthLower)throw new ei(`factor cannot have upper bound less than lower bound.\n        Got upper bound: ${this.widthUpper}.\n        Got lower bound: ${this.widthLower}\n      `);if(s){if(!wh.has(s))throw new ei(`Invalid interpolation parameter: ${s} is not implemented`);this.interpolation=s}}getConfig(){const t={factor:this.factor,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){const e=(t=Mr(t))[2];return[this.imgHeight,-1,e]}call(t,e){return(0,h.tidy)((()=>{const e=$r(t);this.imgHeight=e.shape[e.shape.length-3];const s=e.shape[e.shape.length-2];this.widthFactor=(0,h.randomUniform)([1],1+this.widthLower,1+this.widthUpper,"float32",this.randomGenerator.next());let n=this.widthFactor.dataSync()[0]*s;n=Math.round(n);const i=[this.imgHeight,n];switch(this.interpolation){case"bilinear":return h.image.resizeBilinear(t,i);case"nearest":return h.image.resizeNearestNeighbor(t,i);default:throw new Error(`Interpolation is ${this.interpolation}\n          but only ${[...wh]} are supported`)}}))}}function vh(t){return new Jr(t)}function kh(t){return new El(t)}function Sh(t){return new Il(t)}function xh(t){return new Tl(t)}function Nh(t){return new Dl(t)}function zh(t){return new Ll(t)}function Ah(t){return new Fl(t)}function Ch(t){return new Zl(t)}function Ih(t){return new Vl(t)}function Th(t){return new Gl(t)}function Dh(t){return new ql(t)}function Eh(t){return new Hl(t)}function Fh(t){return new Jl(t)}function Lh(t){return new Yl(t)}function Rh(t){return new Xl(t)}function $h(t){return new Ql(t)}function Mh(t){return new vu(t)}function Oh(t){return new wu(t)}function _h(t){return new mu(t)}function Bh(t){return new yu(t)}function Ph(t){return new bu(t)}function Wh(t){return new ku(t)}function Uh(t){return new Su(t)}function jh(t){return new xu(t)}function Vh(t){return new zu(t)}function qh(t){return new Cu(t)}function Gh(t){return new Tu(t)}function Hh(t){return new Fu(t)}function Kh(t){return new Du(t)}function Jh(t){return new Eu(t)}function Zh(t){return new Iu(t)}function Yh(t){return new Ru(t)}function Xh(t){return new Pu(t)}function Qh(t){return new Wu(t)}function tc(t){return new Uu(t)}function ec(t){return new Hu(t)}function sc(t){return ec(t)}function nc(t){return ec(t)}function ic(t){return new Zu(t)}function rc(t){return ic(t)}function ac(t){return ic(t)}function oc(t){return new Qu(t)}function lc(t){return oc(t)}function uc(t){return oc(t)}function hc(t){return new eh(t)}function cc(t){return new ih(t)}function pc(t){return new sh(t)}function dc(t){return new rh(t)}function fc(t){return new Gu(t)}function gc(t){return new Ju(t)}function mc(t){return new Xu(t)}function yc(t){return new ou(t)}function wc(t){return new au(t)}function bc(t){return new uu(t)}function vc(t){return new lu(t)}function kc(t){return new ru(t)}function Sc(t){return new iu(t)}function xc(t){return new gu(t)}function Nc(t){return new fu(t)}function zc(t){return new su(t)}function Ac(t){return new hu(t)}function Cc(t){return new lh(t)}function Ic(t){return new oh(t)}bh.className="RandomWidth",h.serialization.registerClass(bh);const Tc=pc,Dc=dc,Ec=fc,Fc=gc;function Lc(t){return new $u(t)}function Rc(t){return new Mu(t)}function $c(t){return new Ou(t)}function Mc(t){return new Nu(t)}function Oc(t){return new uh(t)}function _c(t){return new ph(t)}function Bc(t){return new gh(t)}function Pc(t){return new dh(t)}function Wc(t){return new bh(t)}function Uc(t,e){return no(t,e)}function jc(t,e){return lo(t,e)}function Vc(t,e){return uo(t,e)}function qc(t,e){return io(t,e)}function Gc(t,e){return ho(t,e)}function Hc(t,e){return ao(t,e)}function Kc(t,e){return oo(t,e)}function Jc(t,e){return to(t,e)}function Zc(t,e){return Ha(t,e)}function Yc(t,e){return Ka(t,e)}function Xc(t,e){return Ka(t,e)}function Qc(t,e){return Ka(t,e)}function tp(t,e){return Ga(t,e)}function ep(t,e){return Ga(t,e)}function sp(t,e){return Ga(t,e)}function np(t,e){return function(t,e){return(0,h.tidy)((()=>{const s=t.sub(e).square().sum(),n=t.sub(t.mean()).square().sum();return h.scalar(1).sub(s.div(n))}))}(t,e)}function ip(t){return new xl(t)}function rp(t){return kl(e=t),new xl({l1:null!=e?e.l1:null,l2:0});var e}function ap(t){return kl(e=t),new xl({l2:null!=e?e.l2:null,l1:0});var e}class op extends Ma{constructor(){super(...arguments),this.model=null}setModel(t){if(!(t instanceof Go))throw new Error("model must be a LayersModel, not some other Container");this.model=t}}function lp(t,e){return t<e}function up(t,e){return t>e}class hp extends op{constructor(t){if(super(),null==t&&(t={}),t.restoreBestWeights)throw new si("restoreBestWeights = True is not implemented in EarlyStopping yet.");this.monitor=t.monitor||"val_loss",this.minDelta=Math.abs(t.minDelta||0),this.patience=t.patience||0,this.verbose=t.verbose||0,this.mode=t.mode||"auto",this.baseline=t.baseline,-1===["auto","min","max"].indexOf(this.mode)&&(console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`),this.mode="auto"),"min"===this.mode?this.monitorFunc=lp:"max"===this.mode||-1!==this.monitor.indexOf("acc")?this.monitorFunc=up:this.monitorFunc=lp,this.monitorFunc===lp&&(this.minDelta*=-1)}async onTrainBegin(t){this.wait=0,this.stoppedEpoch=0,null!=this.baseline?this.best=this.baseline:this.best=this.monitorFunc===lp?1/0:-1/0}async onEpochEnd(t,e){await La(e);const s=this.getMonitorValue(e);null!=s&&(this.monitorFunc(s-this.minDelta,this.best)?(this.best=s,this.wait=0):(this.wait++,this.wait>=this.patience&&(this.stoppedEpoch=t,this.model.stopTraining=!0)))}async onTrainEnd(t){this.stoppedEpoch>0&&this.verbose&&console.log(`Epoch ${this.stoppedEpoch}: early stopping.`)}getMonitorValue(t){null==t&&(t={});const e=t[this.monitor];return null==e&&console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(t)}`),e}}const cp={earlyStopping:function(t){return new hp(t)}};var pp,dp=s(5452),fp=s(4334);function gp(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:new Map,n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:new Set;if(null==t)return null;if("function"===typeof Blob&&t instanceof Blob)return t.slice();if(n.has(t))throw new Error("Circular references are not supported.");if(s.has(t))return s.get(t);const i=e(t);if(i.recurse&&null!==i.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(i.recurse){if(vp(t)){const i=Array.isArray(t)?[]:{};n.add(t);for(const r in t){const a=gp(t[r],e,s,n);i[r]=a}return n.delete(t),t.__proto__&&(i.__proto__=t.__proto__),i}throw new Error(`Can't recurse into non-iterable type: ${t}`)}return s.set(t,i.value),i.value}function mp(t){return yp(t,arguments.length>1&&void 0!==arguments[1]?arguments[1]:wp)}function yp(t,e){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:new Set;const n=t[0];if(s.has(n))throw new Error("Circular references are not supported.");const i=e(t);if(i.recurse&&null!==i.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(i.recurse){if(vp(n)){const i=Array.isArray(n)?[]:{};s.add(n);for(const r in n){const n=yp(t.map((t=>t[r])),e,s);i[r]=n}return s.delete(n),i}throw new Error(`Can't recurse into non-iterable type: ${n}`)}return i.value}function wp(t){return null===t?null:vp(t[0])?{value:null,recurse:!0}:{value:t,recurse:!1}}async function bp(t,e){const s=new Map;gp(t,e,s);for(const n of Array.from(s.keys())){const t=s.get(n);if(h.util.isPromise(t)){const e=await t;s.set(n,e)}}return gp(t,e,s)}function vp(t){let e=!1;if(h.env().get("IS_BROWSER"))e=t instanceof TextDecoder;else{const{StringDecoder:n}=s(551);e=t instanceof n}return null!=t&&!ArrayBuffer.isView(t)&&(Array.isArray(t)||"object"===typeof t&&!(t instanceof h.Tensor)&&!(t instanceof Promise)&&!e)}function kp(t){return function(t,e){return gp(t,e)}(t,Sp)}function Sp(t){return t instanceof h.Tensor?{value:t.clone(),recurse:!1}:vp(t)?{value:null,recurse:!0}:{value:t,recurse:!1}}class xp{constructor(t){if(this.capacity=t,this.begin=0,this.end=0,null==t)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(t<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(t),this.doubledCapacity=2*t}wrap(t){for(;t<0;)t+=this.doubledCapacity;return t%this.doubledCapacity}get(t){if(t<0)throw new RangeError("Can't get item at a negative index.");return this.data[t%this.capacity]}set(t,e){if(t<0)throw new RangeError("Can't set item at a negative index.");this.data[t%this.capacity]=e}length(){let t=this.end-this.begin;return t<0&&(t=this.doubledCapacity+t),t}isFull(){return this.length()===this.capacity}isEmpty(){return 0===this.length()}push(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,t),this.end=this.wrap(this.end+1)}pushAll(t){for(const e of t)this.push(e)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const t=this.get(this.end);return this.set(this.end,void 0),t}unshift(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,t)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const t=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),t}shuffleExcise(t){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const e=this.wrap(this.begin+t),s=this.get(e);return this.set(e,this.pop()),s}}class Np extends xp{constructor(){super(Np.INITIAL_CAPACITY)}isFull(){return!1}push(t){super.isFull()&&this.expand(),super.push(t)}unshift(t){super.isFull()&&this.expand(),super.unshift(t)}expand(){const t=2*this.capacity,e=new Array(t),s=this.length();for(let n=0;n<s;n++)e[n]=this.get(this.wrap(this.begin+n));this.data=e,this.capacity=t,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=s}}function zp(t){return new Tp(t)}function Ap(t){return new Dp(t)}function Cp(t,e){return new Wp(t,e)}Np.INITIAL_CAPACITY=32;class Ip{async toArray(){const t=[];let e=await this.next();for(;!e.done;)t.push(e.value),e=await this.next();return t}async toArrayForTest(){const t=this.prefetch(100),e=[];let s=await t.next();for(;!s.done;)e.push(s.value),s=await t.next();return e}async resolveFully(){let t=await this.next();for(;!t.done;)t=await this.next()}async resolveWhile(t){let e=await this.next(),s=t(e.value);for(;!e.done&&s;)e=await this.next(),s=t(e.value)}handleErrors(t){return new Op(this,t)}filter(t){return new $p(this,t)}map(t){return new Mp(this,t)}mapAsync(t){return new _p(this,t)}serialMapAsync(t){return new _p(this,t).serial()}flatmap(t){return new Pp(this,t)}async forEachAsync(t){return this.map(t).resolveFully()}async serialForEach(t){return this.serialMapAsync(t).resolveWhile((t=>!0===t))}rowMajorBatch(t){return new Rp(this,t,!(arguments.length>1&&void 0!==arguments[1])||arguments[1])}columnMajorBatch(t){let e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1],s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:wp;return this.rowMajorBatch(t,e).map((t=>mp(t,s)))}concatenate(t,e){return new Wp(zp([this,t]),e)}take(t){return t<0||null==t?this:new Lp(this,t)}skip(t){return t<0||null==t?this:new Fp(this,t)}prefetch(t){return new jp(this,t)}shuffle(t,e){return new Vp(this,t,e)}serial(){return new Ep(this)}}class Tp extends Ip{constructor(t){super(),this.items=t,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const t=this.items[this.trav];return this.trav++,{value:kp(t),done:!1}}}class Dp extends Ip{constructor(t){super(),this.nextFn=t}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(t){throw t.message=`Error thrown while iterating through a dataset: ${t.message}`,t}}}class Ep extends Ip{constructor(t){super(),this.upstream=t,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Serial`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){return this.upstream.next()}}class Fp extends Ip{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Skip`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const t=await this.upstream.next();if(t.done)return t;h.dispose(t.value)}return this.upstream.next()}}class Lp extends Ip{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0}summary(){return`${this.upstream.summary()} -> Take`}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class Rp extends Ip{constructor(t,e){let s=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];super(),this.upstream=t,this.batchSize=e,this.enableSmallLastBatch=s,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> RowMajorBatch`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){const t=[];for(;t.length<this.batchSize;){const e=await this.upstream.next();if(e.done)return this.enableSmallLastBatch&&t.length>0?{value:t,done:!1}:{value:null,done:!0};t.push(e.value)}return{value:t,done:!1}}}class $p extends Ip{constructor(t,e){super(),this.upstream=t,this.predicate=e,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Filter`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;;){const t=await this.upstream.next();if(t.done||this.predicate(t.value))return t;h.dispose(t.value)}}}class Mp extends Ip{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return`${this.upstream.summary()} -> Map`}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=h.tensor_util.getTensorsInContainer(t.value),s=this.transform(t.value),n=h.tensor_util.getTensorsInContainer(s);for(const i of e)h.tensor_util.isTensorInList(i,n)||i.dispose();return{value:s,done:!1}}}class Op extends Ip{constructor(t,e){super(),this.upstream=t,this.handler=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> handleErrors`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(t){if(!this.handler(t))return{value:null,done:!0}}}}class _p extends Ip{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return`${this.upstream.summary()} -> AsyncMap`}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=h.tensor_util.getTensorsInContainer(t.value),s=await this.transform(t.value),n=h.tensor_util.getTensorsInContainer(s);for(const i of e)h.tensor_util.isTensorInList(i,n)||i.dispose();return{value:s,done:!1}}}class Bp extends Ip{constructor(){super(),this.outputQueue=new Np,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;0===this.outputQueue.length();)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class Pp extends Bp{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return`${this.upstream.summary()} -> Flatmap`}async pump(){const t=await this.upstream.next();if(t.done)return!1;const e=h.tensor_util.getTensorsInContainer(t.value),s=this.transform(t.value),n=h.tensor_util.getTensorsInContainer(s);this.outputQueue.pushAll(s);for(const i of e)h.tensor_util.isTensorInList(i,n)||i.dispose();return!0}}class Wp extends Ip{constructor(t,e){super(),this.baseErrorHandler=e,this.lastRead=null,this.iterator=null,this.moreIterators=t}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(t){if(await t,null==this.iterator){const t=await this.moreIterators.next();if(t.done)return{value:null,done:!0};this.iterator=t.value,null!=this.baseErrorHandler&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const e=await this.iterator.next();return e.done?(this.iterator=null,this.readFromChain(t)):e}}!function(t){t[t.FAIL=0]="FAIL",t[t.SHORTEST=1]="SHORTEST",t[t.LONGEST=2]="LONGEST"}(pp||(pp={}));class Up extends Ip{constructor(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:pp.FAIL;super(),this.iterators=t,this.mismatchMode=e,this.count=0,this.currentPromise=null}summary(){return"{TODO: fill in upstream of zip summaries} -> Zip"}async nextState(t){await t;let e=0,s=0;const n=await bp(this.iterators,(function(t){if(t instanceof Ip){return{value:t.next().then((t=>(e++,t.done&&s++,t.value))),recurse:!1}}return{value:null,recurse:!0}}));if(e===s)return{value:null,done:!0};if(s>0)switch(this.mismatchMode){case pp.FAIL:throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);case pp.SHORTEST:return{value:null,done:!0};case pp.LONGEST:}return this.count++,{value:n,done:!1}}async next(){return this.currentPromise=this.nextState(this.currentPromise),this.currentPromise}}class jp extends Ip{constructor(t,e){super(),this.upstream=t,this.bufferSize=e,this.buffer=new xp(e)}summary(){return`${this.upstream.summary()} -> Prefetch`}refill(){for(;!this.buffer.isFull();){const t=this.upstream.next();this.buffer.push(t)}}next(){return this.refill(),this.buffer.shift()}}class Vp extends jp{constructor(t,e,s){super(t,e),this.upstream=t,this.windowSize=e,this.upstreamExhausted=!1,this.random=fp.alea(s||h.util.now().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}randomInt(t){return Math.floor(this.random()*t)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const t=this.chooseIndex(),e=await this.buffer.shuffleExcise(t);if(!e.done)return this.refill(),e;this.upstreamExhausted=!0}return{value:null,done:!0}}}class qp{constructor(){this.size=null}batch(t){let e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];const s=this;let n;return h.util.assert(t>0,(()=>`batchSize needs to be positive, but it is\n      ${t}`)),n=this.size===1/0||null==this.size?this.size:e?Math.ceil(this.size/t):Math.floor(this.size/t),Gp((async()=>(await s.iterator()).columnMajorBatch(t,e,Jp)),n)}concatenate(t){const e=this;let s;return s=this.size===1/0||t.size===1/0?1/0:null!=this.size&&null!=t.size?this.size+t.size:null,Gp((async()=>(await e.iterator()).concatenate(await t.iterator())),s)}filter(t){const e=this;let s;return s=this.size===1/0?1/0:null,Gp((async()=>(await e.iterator()).filter((e=>h.tidy((()=>t(e)))))),s)}async forEachAsync(t){return(await this.iterator()).forEachAsync(t)}map(t){const e=this;return Gp((async()=>(await e.iterator()).map((e=>h.tidy((()=>t(e)))))),this.size)}mapAsync(t){const e=this;return Gp((async()=>(await e.iterator()).mapAsync(t)),this.size)}prefetch(t){if(null==t)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const e=this;return Gp((async()=>(await e.iterator()).prefetch(t)),this.size)}repeat(t){const e=this;let s;return s=null!=this.size&&t>0?this.size*t:0===t?0:null!=this.size&&(void 0===t||t<0)?1/0:null,Gp((async()=>Cp(Ap((async()=>({value:await e.iterator(),done:!1}))).take(t))),s)}skip(t){const e=this;let s;return s=null!=this.size&&t>=0&&this.size>=t?this.size-t:null!=this.size&&(this.size<t||void 0===t||t<0)?0:null,Gp((async()=>(await e.iterator()).skip(t)),s)}shuffle(t,e){let s=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];if(null==t||t<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const n=this,i=fp.alea(e||h.util.now().toString());return Gp((async()=>{let e=i.int32();return s&&(e+=i.int32()),(await n.iterator()).shuffle(t,e.toString())}),this.size)}take(t){const e=this;let s;return s=null!=this.size&&this.size>t?t:null!=this.size&&this.size<=t?this.size:null,Gp((async()=>(await e.iterator()).take(t)),s)}async toArray(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}function Gp(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null;return new class extends qp{constructor(){super(...arguments),this.size=e}async iterator(){return t()}}}function Hp(t){return Gp((async()=>zp(t)),t.length)}function Kp(t){if(!vp(t))throw new Error("The argument to zip() must be an object or array.");let e;if(Array.isArray(t))for(let s=0;s<t.length;s++)e=null==e?t[s].size:Math.min(e,t[s].size);else if(t instanceof Object)for(const s in t)e=null==e?t[s].size:Math.min(e,t[s].size);return Gp((async()=>function(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:pp.FAIL;return new Up(t,e)}(await bp(t,(t=>{if(t instanceof qp)return{value:t.iterator(),recurse:!1};if(vp(t))return{value:null,recurse:!0};throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.")})),pp.SHORTEST)),e)}function Jp(t){if(null===t)return null;if(function(t){return null==t||null===(e=t)||"object"!==typeof e&&"function"!==typeof e||Array.isArray(t)||"object"===typeof t&&t instanceof h.Tensor||h.util.isTypedArray(t);var e}(t[0])){return{value:function(t){if(0===t.length)throw new Error("Can't make a batch of zero elements.");return t[0]instanceof h.Tensor?h.stack(t):h.tensor(t)}(t),recurse:!1}}return{value:null,recurse:!0}}qp.MAX_BUFFER_SIZE=1e4;class Zp extends qp{constructor(t){super(),this.input=t}async iterator(){return(await this.input.iterator()).decodeUTF8().split("\n").map((t=>(t.endsWith("\r")&&(t=t.slice(0,-1)),t)))}}const Yp='"',Xp=Symbol("out"),Qp=Symbol("field"),td=Symbol("quote"),ed=Symbol("quoteafterquote"),sd=Symbol("quoteinquote");class nd extends qp{async columnNames(){return this.columnNamesValidated||await this.setColumnNames(),this.configuredColumnsOnly?Object.keys(this.columnConfigs):this.fullColumnNames}async setColumnNames(){const t=await this.maybeReadHeaderLine();if(!this.fullColumnNames&&!t)throw new Error("Column names must be provided if there is no header line.");this.fullColumnNames&&t&&h.util.assert(t.length===this.fullColumnNames.length,(()=>"The length of provided columnNames ("+this.fullColumnNames.length.toString()+") does not match the length of the header line read from file ("+t.length.toString()+").")),this.fullColumnNames||(this.fullColumnNames=t);const e=this.fullColumnNames.reduce(((t,e)=>(t[e]=t[e]+1||1,t)),{}),s=Object.keys(e).filter((t=>e[t]>1));if(h.util.assert(0===s.length,(()=>"Duplicate column names found: "+s.toString())),this.columnConfigs)for(const n of Object.keys(this.columnConfigs)){if(-1===this.fullColumnNames.indexOf(n))throw new Error('The key "'+n+'" provided in columnConfigs does not match any of the column names ('+this.fullColumnNames.toString()+").")}this.columnNamesValidated=!0}async maybeReadHeaderLine(){if(this.hasHeader){const t=await this.base.iterator(),e=await t.next();if(e.done)throw new Error("No data was found for CSV parsing.");const s=e.value;return this.parseRow(s,!1)}return null}constructor(t,e){super(),this.input=t,this.hasHeader=!0,this.fullColumnNames=null,this.columnNamesValidated=!1,this.columnConfigs=null,this.configuredColumnsOnly=!1,this.delimiter=",",this.delimWhitespace=!1,this.base=new Zp(t),e||(e={}),this.hasHeader=!1!==e.hasHeader,this.fullColumnNames=e.columnNames,this.columnConfigs=e.columnConfigs,this.configuredColumnsOnly=e.configuredColumnsOnly,e.delimWhitespace?(h.util.assert(null==e.delimiter,(()=>"Delimiter should not be provided when delimWhitespace is true.")),this.delimWhitespace=!0,this.delimiter=" "):this.delimiter=e.delimiter?e.delimiter:","}async iterator(){this.columnNamesValidated||await this.setColumnNames();let t=await this.base.iterator();return this.hasHeader&&(t=t.skip(1)),t.map((t=>this.makeDataElement(t)))}makeDataElement(t){const e=this.parseRow(t),s={},n={};for(let i=0;i<this.fullColumnNames.length;i++){const r=this.fullColumnNames[i],a=this.columnConfigs?this.columnConfigs[r]:null;if(!this.configuredColumnsOnly||a){const o=e[i];let l=null;if(""===o)if(a&&void 0!==a.default)l=a.default;else{if(a&&(a.required||a.isLabel))throw new Error(`Required column ${r} is empty in this line: ${t}`);l=void 0}else{const t=Number(o);if(isNaN(t))l=a&&"bool"===a.dtype?this.getBoolean(o):o;else if(a&&a.dtype)switch(a.dtype){case"float32":default:l=t;break;case"int32":l=Math.floor(t);break;case"bool":l=this.getBoolean(o)}else l=t}a&&a.isLabel?n[r]=l:s[r]=l}}return 0===Object.keys(n).length?s:{xs:s,ys:n}}getBoolean(t){return"1"===t||"true"===t.toLowerCase()?1:0}parseRow(t){let e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];const s=[];let n=0;const i=t.length;let r=Xp;for(let a=0;a<i;a++)switch(r){case Xp:switch(t.charAt(a)){case Yp:n=a+1,r=td;break;case this.delimiter:if(n=a+1," "===this.delimiter&&this.delimWhitespace)break;s.push(""),r=Xp;break;default:r=Qp,n=a}break;case Qp:if(t.charAt(a)===this.delimiter)s.push(t.substring(n,a)),r=Xp,n=a+1;break;case td:if(t.charAt(a)===Yp)r=ed;break;case ed:switch(t.charAt(a)){case this.delimiter:s.push(t.substring(n,a-1)),r=Xp,n=a+1;break;case Yp:r=td;break;default:r=sd}break;case sd:if(t.charAt(a)===Yp)r=td}if(r===ed?s.push(t.substring(n,i-1)):s.push(t.substring(n)),e&&s.length!==this.fullColumnNames.length)throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${s}`);return s}}class id extends Ip{constructor(t){super(),this.microphoneConfig=t,this.isClosed=!1,this.fftSize=t.fftSize||1024;const e=Math.log2(this.fftSize);if(this.fftSize<0||e<4||e>14||!Number.isInteger(e))throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);if(this.numFrames=t.numFramesPerSpectrogram||43,this.sampleRateHz=t.sampleRateHz,this.columnTruncateLength=t.columnTruncateLength||this.fftSize,this.audioTrackConstraints=t.audioTrackConstraints,this.smoothingTimeConstant=t.smoothingTimeConstant||0,this.includeSpectrogram=!1!==t.includeSpectrogram,this.includeWaveform=!0===t.includeWaveform,!this.includeSpectrogram&&!this.includeWaveform)throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.")}summary(){return"microphone"}static async create(){let t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};if(!(0,h.env)().get("IS_BROWSER"))throw new Error("microphone API is only supported in browser environment.");const e=new id(t);return await e.start(),e}async start(){try{this.stream=await navigator.mediaDevices.getUserMedia({audio:null==this.audioTrackConstraints||this.audioTrackConstraints,video:!1})}catch(s){throw new Error(`Error thrown while initializing video stream: ${s.message}`)}if(!this.stream)throw new Error("Could not obtain audio from microphone.");const t=window.AudioContext||window.webkitAudioContext;if(this.audioContext=new t,this.sampleRateHz){if(this.audioContext.sampleRate!==this.sampleRateHz)throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`)}else this.sampleRateHz=this.audioContext.sampleRate;const e=this.audioContext.createMediaStreamSource(this.stream);this.analyser=this.audioContext.createAnalyser(),this.analyser.fftSize=2*this.fftSize,this.analyser.smoothingTimeConstant=this.smoothingTimeConstant,e.connect(this.analyser),this.freqData=new Float32Array(this.fftSize),this.timeData=new Float32Array(this.fftSize)}async next(){if(this.isClosed)return{value:null,done:!0};let t,e;const s=await this.getAudioData();if(this.includeSpectrogram){const e=this.flattenQueue(s.freqDataQueue);t=this.getTensorFromAudioDataArray(e,[this.numFrames,this.columnTruncateLength,1])}if(this.includeWaveform){const t=this.flattenQueue(s.timeDataQueue);e=this.getTensorFromAudioDataArray(t,[this.numFrames*this.fftSize,1])}return{value:{spectrogram:t,waveform:e},done:!1}}async capture(){return(await this.next()).value}async getAudioData(){const t=[],e=[];let s=0;return new Promise((n=>{const i=setInterval((()=>{this.includeSpectrogram&&(this.analyser.getFloatFrequencyData(this.freqData),this.freqData[0]===-1/0&&n({freqDataQueue:t,timeDataQueue:e}),t.push(this.freqData.slice(0,this.columnTruncateLength))),this.includeWaveform&&(this.analyser.getFloatTimeDomainData(this.timeData),e.push(this.timeData.slice())),++s===this.numFrames&&(clearInterval(i),n({freqDataQueue:t,timeDataQueue:e}))}),this.fftSize/this.sampleRateHz*1e3)}))}stop(){this.isClosed||(this.isClosed=!0,this.analyser.disconnect(),this.audioContext.close(),null!=this.stream&&this.stream.getTracks().length>0&&this.stream.getTracks()[0].stop())}toArray(){throw new Error("Can not convert infinite audio stream to array.")}getSampleRate(){return this.sampleRateHz}flattenQueue(t){const e=t[0].length,s=new Float32Array(t.length*e);return t.forEach(((t,n)=>s.set(t,n*e))),s}getTensorFromAudioDataArray(t,e){const s=new Float32Array(h.util.sizeFromShape(e));return s.set(t,s.length-t.length),(0,h.tensor)(s,e)}}class rd extends Ip{constructor(t,e){if(super(),this.webcamVideoElement=t,this.webcamConfig=e,this.isClosed=!0,this.resize=!1,this.needToResize())if(this.resize=!0,this.cropSize=[this.webcamConfig.resizeHeight,this.webcamConfig.resizeWidth],this.cropBoxInd=(0,h.tensor1d)([0],"int32"),this.webcamConfig.centerCrop){const t=1*this.webcamConfig.resizeWidth/this.webcamVideoElement.width,e=1*this.webcamConfig.resizeHeight/this.webcamVideoElement.height,s=(1-t)/2,n=(1-e)/2,i=s+t,r=e+n;this.cropBox=(0,h.tensor2d)([n,s,r,i],[1,4])}else this.cropBox=(0,h.tensor2d)([0,0,1,1],[1,4])}summary(){return"webcam"}static async create(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};if(!(0,h.env)().get("IS_BROWSER"))throw new Error("tf.data.webcam is only supported in browser environment.");if(!t){if(t=document.createElement("video"),!e.resizeWidth||!e.resizeHeight)throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");t.width=e.resizeWidth,t.height=e.resizeHeight}const s=new rd(t,e);return await s.start(),s}async start(){this.webcamConfig.facingMode&&h.util.assert("user"===this.webcamConfig.facingMode||"environment"===this.webcamConfig.facingMode,(()=>`Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`));try{this.stream=await navigator.mediaDevices.getUserMedia({video:{deviceId:this.webcamConfig.deviceId,facingMode:this.webcamConfig.facingMode?this.webcamConfig.facingMode:"user",width:this.webcamVideoElement.width,height:this.webcamVideoElement.height}})}catch(t){throw t.message=`Error thrown while initializing video stream: ${t.message}`,t}if(!this.stream)throw new Error("Could not obtain video from webcam.");try{this.webcamVideoElement.srcObject=this.stream}catch(e){console.log(e),this.webcamVideoElement.src=window.URL.createObjectURL(this.stream)}return this.webcamVideoElement.play(),this.isClosed=!1,new Promise((t=>{this.webcamVideoElement.onloadedmetadata=()=>{t()}}))}async next(){if(this.isClosed)return{value:null,done:!0};let t;try{t=h.browser.fromPixels(this.webcamVideoElement)}catch(e){throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(e)}`)}if(!this.resize)return{value:t,done:!1};try{return{value:this.cropAndResizeFrame(t),done:!1}}catch(e){throw new Error(`Error thrown cropping the video: ${e.message}`)}finally{t.dispose()}}needToResize(){return!(!this.webcamConfig.resizeWidth||!this.webcamConfig.resizeHeight||this.webcamVideoElement.width===this.webcamConfig.resizeWidth&&this.webcamVideoElement.height===this.webcamConfig.resizeHeight)}cropAndResizeFrame(t){return(0,h.tidy)((()=>{const e=(0,h.expandDims)((0,h.cast)(t,"float32"),0);let s;s=h.image.cropAndResize(e,this.cropBox,this.cropBoxInd,this.cropSize,"bilinear");const n=s.shape;return(0,h.reshape)(s,n.slice(1))}))}async capture(){return(await this.next()).value}stop(){this.stream.getTracks().forEach((t=>t.stop()));try{this.webcamVideoElement.srcObject=null}catch(t){console.log(t),this.webcamVideoElement.src=null}this.isClosed=!0}toArray(){throw new Error("Can not convert infinite video stream to array.")}}class ad{}class od extends Ip{split(t){return new ld(this,t)}}class ld extends od{constructor(t,e){super(),this.upstream=t,this.impl=new ud(t,e)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class ud extends Bp{constructor(t,e){super(),this.upstream=t,this.separator=e,this.carryover=""}summary(){return`${this.upstream.summary()} -> Split('${this.separator}')`}async pump(){const t=await this.upstream.next();if(t.done)return""!==this.carryover&&(this.outputQueue.push(this.carryover),this.carryover="",!0);const e=t.value.split(this.separator);e[0]=this.carryover+e[0];for(const s of e.slice(0,-1))this.outputQueue.push(s);return this.carryover=e[e.length-1],!0}}class hd extends Ip{decodeUTF8(){return new cd(this)}}class cd extends od{constructor(t){super(),this.upstream=t,this.impl=new pd(t)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class pd extends Bp{constructor(t){if(super(),this.upstream=t,(0,h.env)().get("IS_BROWSER"))this.decoder=new TextDecoder("utf-8");else{const{StringDecoder:t}=s(4530);this.decoder=new t("utf8")}}summary(){return`${this.upstream.summary()} -> Utf8`}async pump(){const t=await this.upstream.next();let e,s;return!t.done&&(e=t.value,s=(0,h.env)().get("IS_BROWSER")?this.decoder.decode(e,{stream:!0}):this.decoder.write(Buffer.from(e.buffer)),this.outputQueue.push(s),!0)}}class dd extends hd{constructor(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};super(),this.file=t,this.options=e,h.util.assert(t instanceof Uint8Array||!!(0,h.env)().get("IS_BROWSER")&&(t instanceof File||t instanceof Blob),(()=>"FileChunkIterator only supports File, Blob and Uint8Array right now.")),this.offset=e.offset||0,this.chunkSize=e.chunkSize||1048576}summary(){return`FileChunks ${this.file}`}async next(){if(this.offset>=(this.file instanceof Uint8Array?this.file.byteLength:this.file.size))return{value:null,done:!0};const t=new Promise(((t,e)=>{const s=this.offset+this.chunkSize;if(this.file instanceof Uint8Array)t(new Uint8Array(this.file.slice(this.offset,s)));else{const n=new FileReader;n.onload=s=>{let i=n.result;if(i instanceof ArrayBuffer&&(i=new Uint8Array(i)),!(i instanceof Uint8Array))return e(new TypeError("FileReader returned unknown type."));t(i)},n.onabort=t=>e(new Error("Aborted")),n.onerror=t=>e(new Error(t.type));const i=this.file.slice(this.offset,s);n.readAsArrayBuffer(i)}this.offset=s}));return{value:await t,done:!1}}}const fd=t=>({method:t.method,headers:t.headers,body:t.body,mode:t.mode,credentials:t.credentials,cache:t.cache,redirect:t.redirect,referrer:t.referrer,integrity:t.integrity});function gd(t){return"string"===typeof t&&"file://"===t.slice(0,7)}class md extends ad{constructor(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};super(),this.input=t,this.options=e}async iterator(){if(gd(this.input)&&(0,h.env)().get("IS_NODE")){const t=s(8108);this.input=t.readFileSync(this.input.slice(7))}return new dd(this.input,this.options)}}class yd extends ad{constructor(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};super(),this.url=t,this.fileOptions=e}async iterator(){return gd(this.url)?new md(this.url,this.fileOptions).iterator():async function(t){let e,s,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},i=arguments.length>2?arguments[2]:void 0;"string"===typeof t?e=t:(e=t.url,s=fd(t));const r=await(i||h.util.fetch)(e,s);if(r.ok){const t=new Uint8Array(await r.arrayBuffer());return new dd(t,n)}throw new Error(r.statusText)}(this.url,this.fileOptions)}}function wd(t){let e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return new nd(new yd(t),e)}function bd(t){const e=Ap(t);return Gp((async()=>e))}function vd(t){return Gp((async()=>{const e=await t();return Ap((()=>e.next()))}))}async function kd(t,e){return rd.create(t,e)}async function Sd(t){return id.create(t)}const xd="4.22.0";var Nd=s(5284),zd=s(5954);const Ad={"tfjs-core":h.version_core,"tfjs-backend-cpu":Nd.version_cpu,"tfjs-backend-webgl":zd.version_webgl,"tfjs-data":xd,"tfjs-layers":Ao,"tfjs-converter":dp.version_converter,tfjs:"4.22.0"}}}]);
//# sourceMappingURL=773.00c87c83.chunk.js.map